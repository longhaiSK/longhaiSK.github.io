{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341c23fe-78ff-4705-88ed-df1a16e863a1",
      "metadata": {
        "editable": true,
        "tags": [
          "remove"
        ],
        "id": "341c23fe-78ff-4705-88ed-df1a16e863a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#os.system('jupyter nbconvert --to script extract_abbrev_regex.ipynb --TagRemovePreprocessor.remove_cell_tags=\"remove\"')\n",
        "#os.system('jupytext extract_abbrev_regex.ipynb --to py\")\n",
        "\n",
        "# I made this change in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b736e5f0-26b8-42e4-9f4a-db61fa2d0f81",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "b736e5f0-26b8-42e4-9f4a-db61fa2d0f81"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import re\n",
        "from datetime import datetime # Import datetime for current date example\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f657e848-b933-4135-90ba-78a55409c24c",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "f657e848-b933-4135-90ba-78a55409c24c"
      },
      "outputs": [],
      "source": [
        "# Functions for normalizing and extracting abbrs\n",
        "\n",
        "# Code block prepared on Thursday, April 3, 2025 at 12:38:43 AM CST in Saskatoon, Saskatchewan, Canada.\n",
        "# Optional import for error display if using Streamlit\n",
        "# try:\n",
        "#     import streamlit as st\n",
        "# except ImportError:\n",
        "#     st = None # Define st as None if not available\n",
        "\n",
        "# This list is used by normalize_latex_math\n",
        "upper_greek_cmds = [\n",
        "    'Gamma', 'Delta', 'Theta', 'Lambda', 'Xi', 'Pi',\n",
        "    'Sigma', 'Upsilon', 'Phi', 'Psi', 'Omega'\n",
        "]\n",
        "\n",
        "# --- Normalization Function ---\n",
        "def normalize_latex_math(text):\n",
        "    \"\"\"\n",
        "    Preprocesses LaTeX text:\n",
        "    1. Converts LaTeX inline math \\( ... \\) to $ ... $.\n",
        "    2. Removes LaTeX comments (% to end of line), respecting \\%.\n",
        "    3. Removes preamble/end tags if \\begin{document} is found.\n",
        "    4a. Adds space BEFORE and AFTER opening curly braces ({).\n",
        "    4b. Adds space BEFORE and AFTER closing curly braces (}).\n",
        "    5. Adds space after specific uppercase Greek commands (\\Cmd) if not present. (Note: Using corrected pattern)\n",
        "    6. Adds space after lowercase LaTeX commands (\\cmd) if not already present. (Note: Pattern may be restrictive)\n",
        "    7. Removes whitespace immediately following $. (Moved Step)\n",
        "    8. Cleans up extra blank lines and trims whitespace.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        print(\"Warning: Input to normalize_latex_math was not a string.\")\n",
        "        return text\n",
        "\n",
        "    processed_text = text\n",
        "    try:\n",
        "        # 1. Normalize math \\(...\\) to $...$\n",
        "        processed_text = re.sub(\n",
        "            r'\\\\\\(\\s*(.*?)\\s*\\\\\\)',\n",
        "            lambda match: f\"${match.group(1).strip()}$\",\n",
        "            processed_text\n",
        "        )\n",
        "\n",
        "        # 2. Remove LaTeX comment lines (respects \\%)\n",
        "        processed_text = re.sub(r'(?<!\\\\)%.*$', '', processed_text, flags=re.MULTILINE)\n",
        "\n",
        "        # 3. Remove preamble IF \\begin{document} exists\n",
        "        begin_doc_marker = r'\\begin{document}'\n",
        "        begin_doc_index = processed_text.find(begin_doc_marker)\n",
        "        if begin_doc_index != -1:\n",
        "            processed_text = processed_text[begin_doc_index + len(begin_doc_marker):]\n",
        "        # 3b. Remove \\end{document} if present near the end\n",
        "        end_doc_marker = r'\\end{document}'\n",
        "        end_doc_index = processed_text.rfind(end_doc_marker)\n",
        "        if end_doc_index != -1 and len(processed_text) - end_doc_index < 30: # Heuristic check\n",
        "            processed_text = processed_text[:end_doc_index]\n",
        "\n",
        "        # --- Spacing Adjustments ---\n",
        "        # 4a. Add space BEFORE and AFTER { (handles existing spaces robustly)\n",
        "        processed_text = re.sub(r'\\s*\\{\\s*', r' { ', processed_text)\n",
        "\n",
        "        # 4b. Add space BEFORE and AFTER } (handles existing spaces robustly)\n",
        "        processed_text = re.sub(r'\\s*\\}\\s*', r' } ', processed_text)\n",
        "\n",
        "        # 5. Add space after specific uppercase Greek commands (\\Cmd) if not followed by space\n",
        "        pattern_part = '|'.join(upper_greek_cmds)\n",
        "        # Using corrected pattern (no space after \\\\)\n",
        "        pattern_upper = rf'(\\\\({pattern_part}))(?!\\s)'\n",
        "        processed_text = re.sub(pattern_upper, r'\\1 ', processed_text)\n",
        "\n",
        "        # 6. Add space after lowercase commands (\\cmd) if not followed by specific pattern\n",
        "        # !!! Note: This pattern (?=[A-Z][^a-z]) might be too restrictive.\n",
        "        processed_text = re.sub(r'(\\\\[a-z]+)(?=[A-Z][^a-z])', r'\\1 ', processed_text)\n",
        "\n",
        "        # 7. Remove one or more whitespace characters (\\s+) immediately after a dollar sign ($) (Moved Step)\n",
        "        processed_text = re.sub(r'\\$\\s+', '$', processed_text)\n",
        "\n",
        "        # 8. Clean up potential excessive blank lines and trim overall whitespace\n",
        "        processed_text = re.sub(r'(\\n\\s*){2,}', '\\n', processed_text) # Collapse blank lines\n",
        "        #processed_text = processed_text.strip() # Trim leading/trailing whitespace\n",
        "\n",
        "        # 9. Join non-empty newline to the previous line\n",
        "        #processed_text = re.sub(r'(\\r\\n|\\r|\\n)', ' ', processed_text)       # Optional final step: Collapse multiple spaces into one IF NEEDED\n",
        "        # processed_text = re.sub(r' +', ' ', processed_text)\n",
        "\n",
        "        return processed_text\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during LaTeX text preprocessing: {e}\"\n",
        "        try:\n",
        "            # Attempt to use streamlit for error display if available\n",
        "            import streamlit as st\n",
        "            st.error(error_message)\n",
        "        except ImportError:\n",
        "            # Fallback to print if streamlit is not available\n",
        "            print(error_message)\n",
        "        return text # Return original text on error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wpt8GiDkbLct"
      },
      "id": "wpt8GiDkbLct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1381c44-7aeb-4691-aa1c-058eeea37777",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "b1381c44-7aeb-4691-aa1c-058eeea37777"
      },
      "outputs": [],
      "source": [
        "## convert the abbreviation into a lower case letter for comparison\n",
        "def get_abbr_repr_items(abbr_string):\n",
        "    \"\"\"\n",
        "    Parses abbreviation string, returns list of representative items WITHOUT Greek mapping.\n",
        "    - Keeps ALL LaTeX commands (like \\frac, \\gamma) as strings.\n",
        "    - Takes the uppercase letter from sequences like 'Cp' or 'CPs', ignoring trailing lowercase.\n",
        "    - Includes standalone lowercase letters.\n",
        "    \"\"\"\n",
        "    representative_items = []\n",
        "    # Regex captures: \\cmd | Upper | OptionalLowerSuffix | StandaloneLower\n",
        "    findings = re.findall(r'(\\\\[a-zA-Z]+)|([A-Z])([a-z]+)?|([a-z])', abbr_string)\n",
        "\n",
        "    # The tuple returned by findall will have 4 elements corresponding to the groups\n",
        "    for command, upper, trailing_lower, standalone_lower in findings:\n",
        "        if command:  # Group 1: \\command\n",
        "            # Keep the original command string (no mapping)\n",
        "            representative_items.append(command)\n",
        "        elif upper:  # Group 2: An uppercase letter was found\n",
        "            # Use the uppercase letter, ignore trailing lowercase (group 3)\n",
        "            representative_items.append(upper.lower())\n",
        "        elif standalone_lower: # Group 4: A standalone lowercase letter\n",
        "            representative_items.append(standalone_lower)\n",
        "    return representative_items\n",
        "\n",
        "## capturing the first letter of the words for comparison\n",
        "def get_effective_char(word: str, debug: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Tries to derive the effective matching character from a LaTeX-style word\n",
        "    by stripping common leading markup and finding the first letter.\n",
        "    \"\"\"\n",
        "    original = word\n",
        "    word_to_check = word\n",
        "    try:\n",
        "        # Heuristically strip leading commands/braces to find the first actual letter.\n",
        "        m1 = re.match(r'^\\s*\\\\[a-zA-Z]+\\s*\\{(.*)', word_to_check)\n",
        "        if m1:\n",
        "            word_to_check = m1.group(1)\n",
        "            # Removed internal debug print for brevity in final code\n",
        "        else:\n",
        "            m2 = re.match(r'^\\s*\\{\\s*\\\\[a-zA-Z]+\\s+(.*)', word_to_check)\n",
        "            if m2:\n",
        "                content = m2.group(1)\n",
        "                if content.endswith('}'): content = content[:-1].rstrip()\n",
        "                word_to_check = content\n",
        "            else:\n",
        "                m3 = re.match(r'^\\s*\\\\[a-zA-Z]+(\\s+.*)', word_to_check)\n",
        "                if m3:\n",
        "                     if m3.group(1) and m3.group(1).strip():\n",
        "                         word_to_check = m3.group(1).lstrip()\n",
        "\n",
        "        if word_to_check.startswith('{'):\n",
        "            word_to_check = word_to_check[1:].lstrip()\n",
        "\n",
        "        match = re.search(r'[a-zA-Z]', word_to_check)\n",
        "        if match:\n",
        "             return match.group(0).lower()\n",
        "\n",
        "        if word_to_check is not original:\n",
        "             match_orig = re.search(r'[a-zA-Z]', original)\n",
        "             if match_orig:\n",
        "                  return match_orig.group(0).lower()\n",
        "\n",
        "        return ''\n",
        "\n",
        "    except Exception as e:\n",
        "        # Keep error print if helper function itself fails when its debug is on\n",
        "        if debug: print(f\"      Error in get_effective_char for '{original}': {e}\")\n",
        "        match = re.search(r'[a-zA-Z]', original)\n",
        "        return match.group(0).lower() if match else ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b2ab12-5fd9-4397-9bfb-b522db6f3a66",
      "metadata": {
        "id": "87b2ab12-5fd9-4397-9bfb-b522db6f3a66"
      },
      "outputs": [],
      "source": [
        "def find_abbreviation_matches(words_ahead, abbr_items, debug=True):\n",
        "    \"\"\"\n",
        "    Performs backward matching between definition words (words_ahead) and\n",
        "    abbreviation items (abbr_items). Uses V3 comparison logic.\n",
        "    If debug=True, prints cumulative matching DataFrame (requires pandas\n",
        "    to be imported globally as pd) and final indices map.\n",
        "    NOTE: Enabling debug=True can significantly slow down execution due to\n",
        "          DataFrame creation/printing in the loop.\n",
        "\n",
        "    Args:\n",
        "        words_ahead (list): List of word tokens from the definition part.\n",
        "        abbr_items (list): List of representative items from the abbreviation part.\n",
        "        debug (bool): Flag to enable cumulative DataFrame printing.\n",
        "\n",
        "    Returns:\n",
        "        list: A list where index `i` contains the index from `words_ahead`\n",
        "              that matches `abbr_items[i]`, or -1 if no match was found.\n",
        "    \"\"\"\n",
        "    num_abbr_items = len(abbr_items)\n",
        "    num_words = len(words_ahead)\n",
        "    match_indices = [-1] * num_abbr_items\n",
        "\n",
        "    # Initialize structures for pandas debug output if needed\n",
        "    words_line = words_ahead[:]\n",
        "    abbr_line = [''] * num_words\n",
        "\n",
        "    last_matched_index = num_words\n",
        "\n",
        "    # Outer loop iterates through Abbr Items in reverse\n",
        "    for abbr_idx in range(num_abbr_items - 1, -1, -1):\n",
        "        target_abbr = abbr_items[abbr_idx]\n",
        "        match_found_for_abbr = False # Renamed for clarity\n",
        "\n",
        "        # Inner loop iterates through Words in reverse\n",
        "        for i in range(last_matched_index - 1, -1, -1):\n",
        "            word = words_ahead[i]\n",
        "            # Call helper with debug=False unless you want its prints too\n",
        "            effective_char = get_effective_char(word, debug=False)\n",
        "\n",
        "            current_match_found = False\n",
        "            # --- V3 COMPARISON LOGIC ---\n",
        "            if target_abbr.startswith('\\\\'):\n",
        "                word_to_compare = word\n",
        "                if word_to_compare.startswith('$'):\n",
        "                    word_to_compare = word_to_compare[1:]\n",
        "                if word_to_compare.startswith(target_abbr):\n",
        "                    current_match_found = True\n",
        "            elif effective_char:\n",
        "                if effective_char == target_abbr:\n",
        "                    current_match_found = True\n",
        "            # --- END V3 COMPARISON LOGIC ---\n",
        "\n",
        "            if current_match_found:\n",
        "                match_indices[abbr_idx] = i\n",
        "                abbr_line[i] = target_abbr # Update debug line\n",
        "                last_matched_index = i\n",
        "                match_found_for_abbr = True\n",
        "                break # Found match for this abbr_idx\n",
        "\n",
        "        # --- Cumulative Debug Output ---\n",
        "        # This block now assumes 'pd' is available if debug is True\n",
        "        if debug:\n",
        "             try:\n",
        "                 # Create DataFrame using the globally imported pd\n",
        "                 df_data = {'Words before': words_line, 'Abb matched': abbr_line}\n",
        "                 df = pd.DataFrame(df_data)\n",
        "                 print(f\"\\nMatching result after item '{target_abbr}' (abbr_idx {abbr_idx}):\")\n",
        "                 print(df.T.to_string())\n",
        "             except NameError: # Catch error if pd wasn't imported globally\n",
        "                 print(\"(NameError: 'pd' not defined. Cannot print DataFrame. \"\n",
        "                       \"Import pandas as pd globally for DataFrame debug output.)\")\n",
        "                 print(f\"Abb matched line state: {abbr_line}\") # Fallback\n",
        "             except Exception as df_err:\n",
        "                 print(f\"(Error creating/printing DataFrame: {df_err})\")\n",
        "                 print(f\"Abb matched line state: {abbr_line}\") # Fallback\n",
        "        # --- End Cumulative Debug Output ---\n",
        "\n",
        "    # --- Final Debug Output ---\n",
        "    if debug:\n",
        "        print(f\"\\nFinal Abbreviation Match Indices: {match_indices}\")\n",
        "    # --- End Final Debug Output ---\n",
        "\n",
        "    return match_indices\n",
        "\n",
        "import re\n",
        "# Assume find_abbreviation_matches, get_abbr_repr_items, and get_effective_char\n",
        "# are defined as previously provided.\n",
        "# Assume normalize_latex_math is also available if you use it beforehand.\n",
        "\n",
        "# --- Updated Extraction function with Threshold Validation & Reduced Debug ---\n",
        "\n",
        "def extract_abbreviations(text, match_threshold=0.6, debug=True):\n",
        "    \"\"\"\n",
        "    Extracts abbreviations defined as (Abbr) following their definition.\n",
        "    Validates match if a certain threshold of abbreviation items are matched\n",
        "    to corresponding words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text potentially containing definitions.\n",
        "        match_threshold (float): The minimum fraction (e.g., 0.7 for 70%) of\n",
        "                                 abbreviation items that must be successfully\n",
        "                                 matched to words for the definition to be\n",
        "                                 considered valid.\n",
        "        debug (bool): Flag to enable extensive debug printing.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping abbreviation strings to their extracted full definitions.\n",
        "    \"\"\"\n",
        "    # Main pattern (same as before - restricted to same line)\n",
        "    pattern = re.compile(\n",
        "        r'('                      # Start Group 1: Preceding words\n",
        "         r'(?:[\\w\\-\\$\\\\\\{\\}]+[ \\t]?){1,10}' # Words separated by space/tab on same line\n",
        "        r')'                      # End Group 1\n",
        "        r'\\(\\s*'                  # Literal opening parenthesis\n",
        "        r'('                      # Start Group 2: Abbreviation\n",
        "         r'(?=.*[A-Z\\\\\\$])'       # Positive lookahead\n",
        "         r'[\\w\\s\\$\\-\\\\\\{\\}]+'   # Allowed characters\n",
        "        r')'                      # End Group 2 capture\n",
        "        r'\\s*\\)'                  # Literal closing parenthesis\n",
        "    )\n",
        "    matches = pattern.findall(text)\n",
        "    abbreviation_dict = {}\n",
        "\n",
        "    # Get current time and location context for potential use\n",
        "    current_time_str = \"Thursday, April 3, 2025 at 5:42:20 PM CST\" # Replace with dynamic time if needed\n",
        "    current_location = \"Saskatoon, Saskatchewan, Canada\"\n",
        "\n",
        "    if debug: print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
        "    if debug: print(f\"(Context: {current_time_str}, {current_location})\")\n",
        "\n",
        "\n",
        "    for match in matches:\n",
        "        words_before_abbr_text = match[0].strip()\n",
        "        abbr_string = match[1].strip()\n",
        "        abbr_items = get_abbr_repr_items(abbr_string)\n",
        "\n",
        "        # Split preceding text using space/hyphen, retaining delimiters\n",
        "        words_ahead = [item for item in re.split(r'([ -]+)', words_before_abbr_text) if item]\n",
        "\n",
        "        if debug:\n",
        "            # Debug printing for candidate\n",
        "            print(f\"\\n---\\nCandidate Found:\")\n",
        "            print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
        "            print(f\"  Generated abbr_items: {abbr_items}\")\n",
        "            print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
        "            # --- BLOCK REMOVED ---\n",
        "            # print(f\"  Split words_ahead (elements - includes separators):\")\n",
        "            # if words_ahead:\n",
        "            #     for i, word in enumerate(words_ahead):\n",
        "            #         print(f\"    [{i}]: '{word}'\")\n",
        "            # else:\n",
        "            #     print(\"    (list is empty)\")\n",
        "            # --- END BLOCK REMOVED ---\n",
        "            # You could optionally print the whole list if needed, e.g.:\n",
        "            # print(f\"  Split words_ahead list: {words_ahead}\")\n",
        "\n",
        "\n",
        "        # Initial check: Need words and abbreviation items to proceed\n",
        "        if not words_ahead or not abbr_items:\n",
        "             if debug: print(f\"  Skipping: No words ahead ({bool(words_ahead)}) or no abbr items found ({bool(abbr_items)}).\")\n",
        "             continue\n",
        "\n",
        "        # Call the matching function (assuming it's defined)\n",
        "        # Ensure find_abbreviation_matches is defined elsewhere using the latest logic\n",
        "        match_indices = find_abbreviation_matches(words_ahead, abbr_items, debug)\n",
        "\n",
        "        # Post-match checks and reconstruction\n",
        "        successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
        "        count_matched = len(successful_match_indices)\n",
        "        num_abbr_items = len(abbr_items)\n",
        "\n",
        "        if debug:\n",
        "             # Keep these summary debug prints\n",
        "             print(f\"  Successful match indices for words: {successful_match_indices}\")\n",
        "             print(f\"  Final match_indices map (abbr_idx -> word_idx): {match_indices}\")\n",
        "             print(f\"  Items matched: {count_matched} out of {num_abbr_items}\")\n",
        "\n",
        "        # Validation Logic (using threshold)\n",
        "        valid_match = False\n",
        "        if num_abbr_items > 0:\n",
        "             ratio_matched = count_matched / num_abbr_items\n",
        "             if ratio_matched >= match_threshold:\n",
        "                 valid_match = True\n",
        "             elif debug:\n",
        "                 print(f\"  Validation Failed: Match ratio {ratio_matched:.2f} \"\n",
        "                       f\"is less than threshold {match_threshold:.2f}\")\n",
        "        elif debug:\n",
        "             print(\"  Validation Failed: No abbreviation items were generated.\")\n",
        "\n",
        "        # Reconstruction Logic\n",
        "        if valid_match:\n",
        "            if not successful_match_indices:\n",
        "                 if debug: print(\"  Skipping: Match deemed valid by ratio, but no word indices found?\")\n",
        "                 continue\n",
        "\n",
        "            min_idx_py = min(successful_match_indices)\n",
        "            max_idx_py = max(successful_match_indices)\n",
        "\n",
        "            if min_idx_py <= max_idx_py:\n",
        "                full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
        "                full_name = ''.join(full_phrase_words_slice)\n",
        "\n",
        "                if debug: print(f\"  Validation Passed (Ratio >= {match_threshold:.2f}). Storing: '{abbr_string}': '{full_name}'\")\n",
        "                abbreviation_dict[abbr_string] = full_name\n",
        "            elif debug: print(f\"  Skipping: min_idx ({min_idx_py}) > max_idx ({max_idx_py}) issue.\")\n",
        "\n",
        "\n",
        "    if debug: print(f\"--- Debugging End ---\\nFinal Dict: {abbreviation_dict}\")\n",
        "    return abbreviation_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48d8618-3d25-4f3a-8b46-a4d3079d1605",
      "metadata": {
        "editable": true,
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "f48d8618-3d25-4f3a-8b46-a4d3079d1605"
      },
      "outputs": [],
      "source": [
        "# Functions for formatting abbrs\n",
        "\n",
        "def format_abbreviations(abbreviations_dict, format_type):\n",
        "    \"\"\"Formats the extracted abbreviations based on the specified type.\n",
        "       Sorts abbreviations alphabetically, handling LaTeX commands in keys.\n",
        "       ASSUMES extracted abbr and full_name are valid LaTeX snippets\n",
        "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
        "    \"\"\"\n",
        "    if not abbreviations_dict:\n",
        "        return \"No abbreviations found.\"\n",
        "\n",
        "    # --- ADD SORTING STEP HERE ---\n",
        "    try:\n",
        "        # Sort the dictionary items alphabetically based on the abbreviation (item[0])\n",
        "        sorted_items = sorted(\n",
        "            abbreviations_dict.items(),\n",
        "            key=lambda item: get_sort_key_from_abbr(item[0])\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Error handling for sorting, fallback to unsorted\n",
        "        st.error(f\"Error during abbreviation sorting: {e}. Displaying unsorted.\")\n",
        "        sorted_items = abbreviations_dict.items()\n",
        "    # --- END SORTING STEP ---\n",
        "\n",
        "    if format_type == \"nomenclature\":\n",
        "        # LaTeX nomenclature package format\n",
        "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
        "        latex_output += \"\\\\makenomenclature\\n\"\n",
        "        for abbr, full_name in sorted_items:\n",
        "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
        "        return latex_output\n",
        "\n",
        "    elif format_type == \"tabular\":\n",
        "        # LaTeX tabular format for a table\n",
        "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        for abbr, full_name in sorted_items:\n",
        "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        latex_output += \"\\\\end{tabular}\\n\"\n",
        "        return latex_output\n",
        "\n",
        "    else:\n",
        "        # Default format: plain list of abbreviations and full names\n",
        "        output = \"\"\n",
        "        items_list = list(sorted_items)  # Convert to list for index access if needed\n",
        "        for i, (abbr, full_name) in enumerate(items_list):\n",
        "            output += f\"{abbr}: {full_name}\"\n",
        "            if i < len(items_list) - 1:\n",
        "                output += \"; \\n\"  # Adds a semicolon between items\n",
        "        return output\n",
        "\n",
        "\n",
        "def get_sort_key_from_abbr(abbr_string):\n",
        "    \"\"\"Generates a lowercase string key for sorting abbreviations.\"\"\"\n",
        "    repr_letters = get_abbr_repr_items(abbr_string)\n",
        "    sort_key = \"\".join(repr_letters).lower()\n",
        "    if not sort_key:\n",
        "         fallback_key = re.sub(r\"^[^\\w]+\", \"\", abbr_string.lower())\n",
        "         return fallback_key\n",
        "    return sort_key\n",
        "\n",
        "#print( r\"\\begin{tabular}{ll} \\hline \\textbf{Abbreviation} & \\textbf{Full Name} \\\\ \\hline AFT & accelerated failure time \\\\ $\\alpha Z$R & $\\alpha$-$Z$-residuals \\\\ $\\beta$$Z$R & $\\beta$-$Z$-residuals \\\\ $frac{ \\gamma}{ Z}-R & $\\frac{ \\gamma}{ Z}$-residuals \\\\ $\\gamma Z$R & $\\gamma$-$Z$-residuals \\\\ LT & \\LaTex text \\\\ RSP & randomized survival probabilities \\\\ TC & Time-Constant \\\\ \\hline \\end{tabular}\")\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26d6e3c-6372-45d3-a2dc-3c21262aeeaf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d26d6e3c-6372-45d3-a2dc-3c21262aeeaf",
        "outputId": "61334b69-e9f5-43ee-b97a-3988a86b8266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'LT': '\\\\LaTex text',\n",
              " 'RSP': 'randomized survival probabilities',\n",
              " 'AFT': 'accelerated failure time',\n",
              " 'TC': '{Time-Constant',\n",
              " '$\\\\alpha Z$R': '$\\\\alpha$-$Z$-residuals',\n",
              " '$\\\\frac {\\\\gamma} {Z} $-R': '$\\\\frac {\\\\gamma} {Z} $-residuals'}"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example_text\n",
        "example_text = r\"\"\"Paste your \\LaTex text (LT) and enjoy the app.\n",
        "\n",
        "The abbreviations like randomized survival probabilities (RSP) and  accelerated failure time(AFT), or \\textbf{Time-Constant (TC) Data} will be caught.\n",
        "\n",
        "The citations and explanations in brackets will be omitted, for example, this one (Wu et al. 2024), regression coeficcient ($\\beta$). This is not an abbreviation (acronym) either.\n",
        "\n",
        "%The comment text (CT) or line will be omitted.\n",
        "\n",
        "The full name and abbrievation can contain greek symbols, for example,  $\\alpha$-\\( Z \\)-residuals($\\alpha Z$R), $\\frac{\\gamma}{Z}$-residuals($\\frac{\\gamma}{Z}$-R)\n",
        "\"\"\"\n",
        "#print(example_text)\n",
        "#extract_abbreviations(normalize_latex_math(example_text),debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df50c561-69c2-485b-b7b0-c4d559268dc7",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "df50c561-69c2-485b-b7b0-c4d559268dc7",
        "outputId": "a1b8872d-9ffd-413b-fdfe-1d3a63e82801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Paste your \\LaTex text (LT) and enjoy the app. \n",
            "The abbreviations like randomized survival probabilities (RSP) and  accelerated failure time (AFT), \n",
            "or \\textbf {Time-Constant (TC) Data} will be caught. \n",
            "The citations and explanations in brackets will be omitted, for example, this one (Wu et al. 2024), \n",
            "regression coeficcient ($\\beta$). This is not an abbreviation (acronym) either. \n",
            "The full name and abbrievation can contain greek symbols, for example, \n",
            "$\\alpha$-$Z$-residuals ($\\alpha Z$R),\n",
            "$\\frac {\\gamma} {Z} $-residuals ($\\frac {\\gamma} {Z} $-R)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# normalize_latex_math Example with example_text\n",
        "#normtext = normalize_latex_math(example_text)\n",
        "#print(normtext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e23265f-6775-4cdc-ba9c-89c51cebf8f6",
      "metadata": {
        "id": "3e23265f-6775-4cdc-ba9c-89c51cebf8f6",
        "outputId": "2377ff10-d6f6-47af-e02e-936777c4ac51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'RSP': 'randomized survival probabilities',\n",
              " 'AFT': 'accelerated failure time',\n",
              " 'TC': '{Time-Constant',\n",
              " '$\\\\alpha Z$R': '$\\\\alpha$-$Z$-residuals',\n",
              " '$\\\\frac {\\\\gamma} {Z} $-R': '$\\\\frac {\\\\gamma} {Z} $-residuals'}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#extract_abbreviations(normalize_latex_math(example_text),debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7dfa4d-df12-4923-8154-3da60db28f34",
      "metadata": {
        "editable": true,
        "jupyter": {
          "source_hidden": true
        },
        "tags": [
          "remove"
        ],
        "id": "0e7dfa4d-df12-4923-8154-3da60db28f34"
      },
      "outputs": [],
      "source": [
        "# This cell is removed\n",
        "from IPython.display import HTML, display\n",
        "import html # Used for escaping, though might not be strictly needed depending on content\n",
        "\n",
        "def render_dataframe_with_latex(df):\n",
        "    \"\"\"\n",
        "    Generates an IPython HTML object to display a Pandas DataFrame\n",
        "    with LaTeX rendering via MathJax. Corrected f-string syntax (v3).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The Pandas DataFrame to render. Assumes LaTeX\n",
        "                           is enclosed in $...$ or \\(...\\).\n",
        "\n",
        "    Returns:\n",
        "        IPython.display.HTML: An HTML object ready for display in notebooks.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert DataFrame to HTML, ensuring LaTeX characters are not escaped\n",
        "    # Also add some basic Bootstrap classes for better table styling\n",
        "    table_html = df.to_html(escape=False, classes=['table', 'table-striped', 'table-bordered'], border=0, index=False)\n",
        "\n",
        "    # Full HTML document including MathJax configuration - with corrected f-string syntax\n",
        "    full_html = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>DataFrame with LaTeX</title>\n",
        "    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\">\n",
        "    <script>\n",
        "      MathJax = {{{{ // Start Escaped Braces for JS Object\n",
        "        tex: {{{{\n",
        "          inlineMath: [['$', '$'], ['\\\\(', '\\\\)']], // Recognize $...$ and \\(...\\)\n",
        "          displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']], // Recognize $$...$$ and \\[...\\]\n",
        "          processEscapes: true\n",
        "        }}}}, // End tex config\n",
        "        svg: {{{{\n",
        "          fontCache: 'global'\n",
        "        }}}} // End svg config\n",
        "      }}}}; // End MathJax config\n",
        "    </script>\n",
        "    <script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
        "    <style>\n",
        "        /* Optional: Add some padding */\n",
        "        .dataframe {{{{ margin: 20px; }}}} /* Escaped braces for CSS */\n",
        "        th, td {{{{ text-align: left; padding: 8px; }}}} /* Escaped braces for CSS */\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"container-fluid\">\n",
        "{table_html}\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "    \"\"\"\n",
        "    return HTML(full_html)\n",
        "\n",
        "def extract_abbreviations(text, require_first_last_match=True, debug=True):\n",
        "    \"\"\"\n",
        "    Extracts abbreviations defined as (Abbr) following their definition.\n",
        "    Attempts to handle various LaTeX math/command formats, including stripping\n",
        "    leading formatting locally when determining the matching character.\n",
        "    Matches abbreviation command strings (like \\frac) if they appear in the words.\n",
        "    \"\"\"\n",
        "    # Pattern allows spaces inside abbr, requires lookahead for uppercase/$/\\\n",
        "    # Allows {} in preceding words and abbreviation content\n",
        "    pattern = re.compile(\n",
        "        r'('                      # Start Group 1: Preceding words\n",
        "         r'(?:[\\w\\-\\$\\\\\\{\\}]+\\s+){1,10}' # Word pattern\n",
        "        r')'                      # End Group 1\n",
        "        r'\\(\\s*'                  # Literal opening parenthesis, optional space\n",
        "        # --- Group 2: Abbreviation ---\n",
        "        r'('                      # Start Group 2 capture\n",
        "         r'(?=.*[A-Z\\\\\\$])'       # Positive lookahead: Must contain uppercase, \\ or $\n",
        "         r'[\\w\\s\\$\\-\\\\\\{\\}]+'   # Match allowed characters (incl. space, {})\n",
        "        r')'                      # End Group 2 capture\n",
        "        # --- End Group 2 ---\n",
        "        r'\\s*\\)'                  # Optional space, literal closing parenthesis\n",
        "    )\n",
        "    matches = pattern.findall(text)\n",
        "    abbreviation_dict = {}\n",
        "\n",
        "    if debug: print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
        "\n",
        "    for match in matches:\n",
        "        words_before_abbr_text = match[0].strip()\n",
        "        # Use the split that handles hyphens between letters\n",
        "        words_ahead = [word for word in re.split(r'\\s+|(?<=-)(?=[A-Za-z])', words_before_abbr_text) if word]\n",
        "        abbr_string = match[1].strip() # Strip leading/trailing space from captured abbr\n",
        "        # Use the version that keeps command strings\n",
        "        abbr_letters = get_abbr_repr_letters_v2(abbr_string)\n",
        "\n",
        "        if debug: # Print statements if needed\n",
        "            print(f\"\\n---\\nCandidate Found:\")\n",
        "            print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
        "            print(f\"  Generated abbr_letters: {abbr_letters}\")\n",
        "            print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
        "            print(f\"  Split words_ahead (elements):\")\n",
        "            if words_ahead:\n",
        "                for i, word in enumerate(words_ahead):\n",
        "                    print(f\"    [{i}]: '{word}'\")\n",
        "            else:\n",
        "                print(\"    (list is empty)\")\n",
        "\n",
        "        # Check if words_ahead list exists and if abbr_letters has at least 2 items\n",
        "        if not words_ahead or len(abbr_letters) < 2:\n",
        "            if debug: print(f\"  Skipping: Not enough words ahead ({bool(words_ahead)}) or less than 2 abbr items found ({len(abbr_letters)}).\")\n",
        "            continue\n",
        "\n",
        "        # If we passed the check, we know we have at least 2 items\n",
        "        num_abbr_letters = len(abbr_letters)\n",
        "        match_indices = [-1] * num_abbr_letters\n",
        "        unmatched_abbr_indices = set(range(num_abbr_letters))\n",
        "\n",
        "        # Backward matching logic\n",
        "        for i, word in enumerate(reversed(words_ahead)):\n",
        "            original_idx = len(words_ahead) - 1 - i\n",
        "            if not unmatched_abbr_indices: break\n",
        "\n",
        "            # --- REVISED effective_char Logic v3 (as provided before) ---\n",
        "            effective_char = None\n",
        "            word_to_check = word # Start with the original token\n",
        "\n",
        "            # 1. Attempt to strip ONLY LEADING markup heuristically\n",
        "            try:\n",
        "                stripped_something = False # Flag to track if changes were made\n",
        "                m1 = re.match(r'^\\s*\\\\([a-zA-Z]+)\\s*\\{(.*)', word_to_check)\n",
        "                if m1:\n",
        "                    word_to_check = m1.group(2)\n",
        "                    stripped_something = True\n",
        "                    if debug: print(f\"    Stripped '\\\\cmd{{' prefix -> CheckAs: '{word_to_check}'\")\n",
        "                else:\n",
        "                    m2 = re.match(r'^\\s*\\{\\s*\\\\([a-zA-Z]+)\\s+(.*)', word_to_check)\n",
        "                    if m2:\n",
        "                        content = m2.group(2)\n",
        "                        if content.endswith('}'): content = content[:-1].rstrip()\n",
        "                        word_to_check = content\n",
        "                        stripped_something = True\n",
        "                        if debug: print(f\"    Stripped '{{\\\\cmd ' prefix -> CheckAs: '{word_to_check}'\")\n",
        "                    else:\n",
        "                        m3 = re.match(r'^\\s*\\\\([a-zA-Z]+)(\\s+.*)', word_to_check)\n",
        "                        if m3:\n",
        "                            cmd_name = m3.group(1)\n",
        "                            # Only strip if it's NOT a mapped greek command we need later\n",
        "                            # Check existence of greek_map defensively\n",
        "                            if 'greek_map' in globals() and cmd_name not in greek_map:\n",
        "                                word_to_check = m3.group(2).lstrip()\n",
        "                                stripped_something = True\n",
        "                                if debug: print(f\"    Stripped '\\\\cmd ' prefix -> CheckAs: '{word_to_check}'\")\n",
        "\n",
        "                if word_to_check.startswith('{'):\n",
        "                    word_to_check = word_to_check[1:].lstrip()\n",
        "                    stripped_something = True\n",
        "                    if debug: print(f\"    Stripped leading '{{' -> CheckAs: '{word_to_check}'\")\n",
        "\n",
        "                if stripped_something and not word_to_check.strip():\n",
        "                    word_to_check = word\n",
        "                    if debug: print(f\"    Reverted stripping as it resulted in empty string.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if debug: print(f\"    Error during word stripping: {e}\")\n",
        "                word_to_check = word\n",
        "\n",
        "            # 2. Now find effective char using the potentially cleaned word_to_check\n",
        "            m_dollar = re.match(r'\\$\\\\([a-zA-Z]+)', word_to_check)\n",
        "            # Check existence of greek_map defensively\n",
        "            if 'greek_map' in globals() and m_dollar and m_dollar.group(1) in greek_map:\n",
        "                effective_char = greek_map[m_dollar.group(1)]\n",
        "            else:\n",
        "                m_slash = re.match(r'\\\\([a-zA-Z]+)', word_to_check)\n",
        "                if 'greek_map' in globals() and m_slash and m_slash.group(1) in greek_map:\n",
        "                    effective_char = greek_map[m_slash.group(1)]\n",
        "                else:\n",
        "                    m_first_letter = re.search(r'[a-zA-Z]', word_to_check)\n",
        "                    if m_first_letter:\n",
        "                        effective_char = m_first_letter.group(0).lower()\n",
        "            # --- END REVISED effective_char Logic v3 ---\n",
        "\n",
        "            if debug: print(f\"  Word: '{word}' (CheckAs: '{word_to_check}'), Effective Char: '{effective_char}'\")\n",
        "\n",
        "            # --- MODIFIED COMPARISON LOGIC ---\n",
        "            # Compare effective char OR command string with remaining abbreviation items\n",
        "            # Check if word could potentially match either via effective char or command prefix\n",
        "            if effective_char is not None or word.startswith('\\\\'):\n",
        "                best_match_abbr_idx = -1\n",
        "                # Iterate through remaining unmatched abbr indices, highest first\n",
        "                for abbr_idx in sorted(list(unmatched_abbr_indices), reverse=True):\n",
        "                    target_abbr = abbr_letters[abbr_idx]\n",
        "                    match_found = False\n",
        "\n",
        "                    if target_abbr.startswith('\\\\'):\n",
        "                        # If abbr item is a command, check if the original word starts with it\n",
        "                        if word.startswith(target_abbr):\n",
        "                            match_found = True\n",
        "                            if debug: print(f\"    -> Matched command '{target_abbr}' by prefix in word '{word}'\")\n",
        "                    elif effective_char is not None:\n",
        "                        # If abbr item is a letter, use effective_char comparison\n",
        "                        if effective_char == target_abbr:\n",
        "                            match_found = True\n",
        "                            if debug: print(f\"    -> Matched letter '{target_abbr}' via effective_char '{effective_char}' in word '{word}'\")\n",
        "\n",
        "                    if match_found:\n",
        "                        best_match_abbr_idx = abbr_idx\n",
        "                        break # Found best match for this word, move to next word\n",
        "\n",
        "                if best_match_abbr_idx != -1:\n",
        "                    # Store the original index of the matched word\n",
        "                    match_indices[best_match_abbr_idx] = original_idx\n",
        "                    # Remove the matched index from the set of those needing matches\n",
        "                    unmatched_abbr_indices.remove(best_match_abbr_idx)\n",
        "            # --- END MODIFIED COMPARISON LOGIC ---\n",
        "\n",
        "\n",
        "        # --- Post-loop checks and reconstruction ---\n",
        "        successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
        "        if debug: print(f\"  Successful match indices for words: {successful_match_indices}\")\n",
        "        if debug: print(f\"  Final match_indices map (abbr_idx -> word_idx): {match_indices}\")\n",
        "\n",
        "\n",
        "        if not successful_match_indices:\n",
        "             if debug: print(\"  Skipping: No successful matches found during backward search.\")\n",
        "             continue\n",
        "\n",
        "        # Validation Step\n",
        "        valid_match = True\n",
        "        if require_first_last_match:\n",
        "            if match_indices[0] == -1 or match_indices[num_abbr_letters - 1] == -1:\n",
        "                valid_match = False\n",
        "                if debug: print(f\"  Validation Failed: First or last letter not matched (Indices map: {match_indices})\")\n",
        "\n",
        "        if valid_match:\n",
        "            min_idx_py = min(successful_match_indices)\n",
        "            max_idx_py = max(successful_match_indices)\n",
        "\n",
        "            if min_idx_py <= max_idx_py:\n",
        "                # Slice uses original words_ahead tokens\n",
        "                full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
        "                # Use the join logic that handles hyphens correctly\n",
        "                # Join words, adding space unless previous word ended with hyphen\n",
        "                full_name = ''.join(word if i == 0 else (' ' + word if not full_phrase_words_slice[i - 1].endswith('-') else word)\n",
        "                                    for i, word in enumerate(full_phrase_words_slice))\n",
        "\n",
        "\n",
        "                if debug: print(f\"  Validation Passed. Storing: '{abbr_string}': '{full_name}'\")\n",
        "                # Store original abbreviation string and reconstructed full name\n",
        "                abbreviation_dict[abbr_string] = full_name\n",
        "            elif debug: print(f\"  Skipping: min_idx ({min_idx_py}) > max_idx ({max_idx_py}) issue.\") # Should not happen if successful_match_indices not empty\n",
        "        elif debug: print(f\"  Skipping: Match deemed invalid by require_first_last_match.\")\n",
        "\n",
        "    #if debug: print(f\"--- Debugging End ---\\nFinal Dict: {abbreviation_dict}\")\n",
        "    return abbreviation_dict\n",
        "\n",
        "def extract_abbreviations(text, require_first_last_match=True, debug=True):\n",
        "    \"\"\"\n",
        "    Extracts abbreviations defined as (Abbr) following their definition.\n",
        "    Attempts to handle various LaTeX math/command formats, including stripping\n",
        "    leading formatting locally when determining the matching character.\n",
        "    \"\"\"\n",
        "    # Pattern allows spaces inside abbr, requires lookahead for uppercase/$/\\\n",
        "    # Allows {} in preceding words and abbreviation content\n",
        "    pattern = re.compile(\n",
        "        r'('                     # Start Group 1: Preceding words\n",
        "          r'(?:[\\w\\-\\$\\\\\\{\\}]+\\s+){1,10}' # Word pattern\n",
        "        r')'                     # End Group 1\n",
        "        r'\\(\\s*'                 # Literal opening parenthesis, optional space\n",
        "        # --- Group 2: Abbreviation ---\n",
        "        r'('                     # Start Group 2 capture\n",
        "          r'(?=.*[A-Z\\\\\\$])'     # Positive lookahead: Must contain uppercase, \\ or $\n",
        "          r'[\\w\\s\\$\\-\\\\\\{\\}]+'   # Match allowed characters (incl. space, {})\n",
        "        r')'                     # End Group 2 capture\n",
        "        # --- End Group 2 ---\n",
        "        r'\\s*\\)'                 # Optional space, literal closing parenthesis\n",
        "    )\n",
        "    matches = pattern.findall(text)\n",
        "    abbreviation_dict = {}\n",
        "\n",
        "    if debug: print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
        "\n",
        "    for match in matches:\n",
        "        words_before_abbr_text = match[0].strip()\n",
        "        # Use the split that handles hyphens between letters\n",
        "        words_ahead = [word for word in re.split(r'\\s+|(?<=-)(?=[A-Za-z])', words_before_abbr_text) if word]\n",
        "        abbr_string = match[1].strip() # Strip leading/trailing space from captured abbr\n",
        "        abbr_letters = get_abbr_repr_letters_v2(abbr_string)\n",
        "\n",
        "\n",
        "\n",
        "        # Handle LaTeX-style abbreviations correctly (raw string handling)\n",
        "        abbr_letters = get_abbr_repr_letters_v2(abbr_string)\n",
        "\n",
        "        if debug: # Print statements if needed\n",
        "            # print(text)\n",
        "            print(f\"\\n---\\nCandidate Found:\")\n",
        "            # print(match) # Raw match tuple if needed\n",
        "            print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
        "            print(f\"  Generated abbr_letters: {abbr_letters}\")\n",
        "            print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
        "\n",
        "            print(f\"  Split words_ahead (elements):\")\n",
        "            if words_ahead: # Avoid error if list is empty\n",
        "                for i, word in enumerate(words_ahead):\n",
        "                # Now 'word' is a string directly in the f-string, so it uses str()\n",
        "                    print(f\"    [{i}]: '{word}'\")\n",
        "                else:\n",
        "                    print(\"    (list is empty)\")\n",
        "\n",
        "        # Check if words_ahead list exists and if abbr_letters has at least 2 items\n",
        "        if not words_ahead or len(abbr_letters) < 2:\n",
        "            if debug: print(f\"  Skipping: Not enough words ahead ({bool(words_ahead)}) or less than 2 abbr letters found ({len(abbr_letters)}).\")\n",
        "            continue\n",
        "\n",
        "        # If we passed the check, we know we have at least 2 letters\n",
        "        num_abbr_letters = len(abbr_letters)\n",
        "        match_indices = [-1] * num_abbr_letters\n",
        "        unmatched_abbr_indices = set(range(num_abbr_letters))\n",
        "\n",
        "        # Backward matching logic\n",
        "        for i, word in enumerate(reversed(words_ahead)):\n",
        "\n",
        "            original_idx = len(words_ahead) - 1 - i\n",
        "            if not unmatched_abbr_indices: break\n",
        "\n",
        "            # --- REVISED effective_char Logic v3 ---\n",
        "            effective_char = None\n",
        "            word_to_check = word # Start with the original token\n",
        "\n",
        "            # 1. Attempt to strip ONLY LEADING markup heuristically\n",
        "            try:\n",
        "                stripped_something = False # Flag to track if changes were made\n",
        "                # Pattern: Optional whitespace, \\command, optional space, { ? -> Group 1 has cmd, Group 2 has content after {\n",
        "                m1 = re.match(r'^\\s*\\\\([a-zA-Z]+)\\s*\\{(.*)', word_to_check)\n",
        "                if m1:\n",
        "                    word_to_check = m1.group(2) # Use content starting after {\n",
        "                    stripped_something = True\n",
        "                    if debug: print(f\"    Stripped '\\\\cmd{{' prefix -> CheckAs: '{word_to_check}'\")\n",
        "                else:\n",
        "                    # Pattern: Optional whitespace, {\\command ... -> Group 1 has cmd, Group 2 has content after space\n",
        "                    m2 = re.match(r'^\\s*\\{\\s*\\\\([a-zA-Z]+)\\s+(.*)', word_to_check)\n",
        "                    if m2:\n",
        "                         content = m2.group(2)\n",
        "                         # Remove potential trailing brace from this pattern\n",
        "                         if content.endswith('}'): content = content[:-1].rstrip()\n",
        "                         word_to_check = content\n",
        "                         stripped_something = True\n",
        "                         if debug: print(f\"    Stripped '{{\\\\cmd ' prefix -> CheckAs: '{word_to_check}'\")\n",
        "                    else:\n",
        "                         # Pattern: \\command (not Greek) followed by space+content -> Group 1 is cmd, Group 2 is content after space\n",
        "                         m3 = re.match(r'^\\s*\\\\([a-zA-Z]+)(\\s+.*)', word_to_check)\n",
        "                         if m3:\n",
        "                             cmd_name = m3.group(1)\n",
        "                             # Only strip if it's NOT a mapped greek command we need later\n",
        "                             if cmd_name not in greek_map:\n",
        "                                 word_to_check = m3.group(2).lstrip() # Use content after command+space\n",
        "                                 stripped_something = True\n",
        "                                 if debug: print(f\"    Stripped '\\\\cmd ' prefix -> CheckAs: '{word_to_check}'\")\n",
        "\n",
        "                # Remove purely structural leading brace if it exists after other steps\n",
        "                if word_to_check.startswith('{'):\n",
        "                     word_to_check = word_to_check[1:].lstrip()\n",
        "                     stripped_something = True # Mark potentially changed\n",
        "                     if debug: print(f\"    Stripped leading '{{' -> CheckAs: '{word_to_check}'\")\n",
        "\n",
        "                # Revert if stripping resulted in empty string\n",
        "                if stripped_something and not word_to_check.strip():\n",
        "                     word_to_check = word # Use original word\n",
        "                     if debug: print(f\"    Reverted stripping as it resulted in empty string.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if debug: print(f\"    Error during word stripping: {e}\")\n",
        "                word_to_check = word # Use original word if stripping fails\n",
        "\n",
        "            # 2. Now find effective char using the potentially cleaned word_to_check\n",
        "            # Check for $\\command... first\n",
        "            m_dollar = re.match(r'\\$\\\\([a-zA-Z]+)', word_to_check)\n",
        "            if m_dollar and m_dollar.group(1) in greek_map:\n",
        "                effective_char = greek_map[m_dollar.group(1)]\n",
        "            else:\n",
        "                # Check for \\command... second (only if not stripped above and is greek)\n",
        "                m_slash = re.match(r'\\\\([a-zA-Z]+)', word_to_check)\n",
        "                # Only use if it's a known greek command we need for matching\n",
        "                if m_slash and m_slash.group(1) in greek_map:\n",
        "                     effective_char = greek_map[m_slash.group(1)]\n",
        "                else:\n",
        "                    # Standard word handling: find the first ASCII letter in potentially stripped word\n",
        "                    m_first_letter = re.search(r'[a-zA-Z]', word_to_check)\n",
        "                    if m_first_letter:\n",
        "                        effective_char = m_first_letter.group(0).lower()\n",
        "            # --- END REVISED effective_char Logic v3 ---\n",
        "\n",
        "\n",
        "            if debug: print(f\"  Word: '{word}' (CheckAs: '{word_to_check}'), Effective Char: '{effective_char}'\")\n",
        "\n",
        "            # Compare effective char with remaining abbreviation letters\n",
        "            if effective_char is not None:\n",
        "                best_match_abbr_idx = -1\n",
        "                for abbr_idx in sorted(list(unmatched_abbr_indices), reverse=True):\n",
        "                    if effective_char == abbr_letters[abbr_idx]:\n",
        "                        best_match_abbr_idx = abbr_idx\n",
        "                        break\n",
        "                if best_match_abbr_idx != -1:\n",
        "                    if debug: print(f\"    -> Matched letter '{abbr_letters[best_match_abbr_idx]}' at abbr_idx {best_match_abbr_idx}\")\n",
        "                    match_indices[best_match_abbr_idx] = original_idx\n",
        "                    unmatched_abbr_indices.remove(best_match_abbr_idx)\n",
        "\n",
        "        # --- Post-loop checks and reconstruction ---\n",
        "        successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
        "        if debug: print(f\"  Successful match indices: {successful_match_indices}\")\n",
        "\n",
        "        if not successful_match_indices:\n",
        "             if debug: print(\"  Skipping: No successful matches found during backward search.\")\n",
        "             continue\n",
        "\n",
        "        # Validation Step\n",
        "        valid_match = True\n",
        "        if require_first_last_match:\n",
        "            if match_indices[0] == -1 or match_indices[num_abbr_letters - 1] == -1:\n",
        "                valid_match = False\n",
        "                if debug: print(f\"  Validation Failed: First or last letter not matched (Indices: {match_indices})\")\n",
        "\n",
        "        if valid_match:\n",
        "            min_idx_py = min(successful_match_indices)\n",
        "            max_idx_py = max(successful_match_indices)\n",
        "\n",
        "            if min_idx_py <= max_idx_py:\n",
        "                # Slice uses original words_ahead tokens\n",
        "                full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
        "                # Use the join logic that handles hyphens correctly\n",
        "                full_name = ''.join(word if i == 0 else (' ' + word if not full_phrase_words_slice[i - 1].endswith('-') else word)\n",
        "                                    for i, word in enumerate(full_phrase_words_slice))\n",
        "\n",
        "                if debug: print(f\"  Validation Passed. Storing: '{abbr_string}': '{full_name}'\")\n",
        "                # Store original abbreviation string and reconstructed full name\n",
        "                abbreviation_dict[abbr_string] = full_name\n",
        "            elif debug: print(f\"  Skipping: min_idx > max_idx issue.\")\n",
        "        elif debug: print(f\"  Skipping: Match deemed invalid by require_first_last_match.\")\n",
        "\n",
        "    #if debug: print(f\"--- Debugging End ---\\nFinal Dict: {abbreviation_dict}\")\n",
        "    return abbreviation_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_sort_key_from_abbr(abbr_string):\n",
        "    \"\"\"\n",
        "    Generates a lowercase string key for sorting abbreviations,\n",
        "    handling common LaTeX math/greek commands via get_abbr_repr_letters.\n",
        "    e.g., '$\\alpha$-RM' -> 'arm', 'CPU' -> 'cpu'\n",
        "    \"\"\"\n",
        "    # Use the existing function to get representative letters\n",
        "    repr_letters = get_abbr_repr_letters(abbr_string)\n",
        "    sort_key = \"\".join(repr_letters).lower()\n",
        "\n",
        "    # If get_abbr_repr_letters returns empty (e.g., abbreviation has no letters/commands?)\n",
        "    # provide a fallback using the original string, lowercased, maybe stripped of leading symbols.\n",
        "    if not sort_key:\n",
        "         # Fallback: lowercase, remove non-alphanumeric start chars for sorting robustness\n",
        "         fallback_key = re.sub(r\"^[^\\w]+\", \"\", abbr_string.lower())\n",
        "         return fallback_key\n",
        "    return sort_key\n",
        "\n",
        "def format_abbreviations(abbreviations_dict, format_type):\n",
        "    \"\"\"Formats the extracted abbreviations based on the specified type.\n",
        "       Sorts abbreviations alphabetically, handling LaTeX commands in keys.\n",
        "       ASSUMES extracted abbr and full_name are valid LaTeX snippets\n",
        "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
        "    \"\"\"\n",
        "    if not abbreviations_dict:\n",
        "        return \"No abbreviations found.\"\n",
        "\n",
        "    # --- ADD SORTING STEP HERE ---\n",
        "    # Sort the dictionary items based on a generated key from the abbreviation (item[0])\n",
        "    try:\n",
        "        sorted_items = sorted(\n",
        "            abbreviations_dict.items(),\n",
        "            key=lambda item: get_sort_key_from_abbr(item[0])\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Basic error handling for sorting, fallback to unsorted\n",
        "        st.error(f\"Error during abbreviation sorting: {e}. Displaying unsorted.\")\n",
        "        sorted_items = abbreviations_dict.items()\n",
        "    # --- END SORTING STEP ---\n",
        "\n",
        "\n",
        "    if format_type == \"nomenclature\":\n",
        "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
        "        latex_output += \"\\\\makenomenclature\\n\"\n",
        "        # Loop through the SORTED items\n",
        "        for abbr, full_name in sorted_items:\n",
        "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
        "        return latex_output\n",
        "\n",
        "    elif format_type == \"tabular\":\n",
        "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        # Loop through the SORTED items\n",
        "        for abbr, full_name in sorted_items:\n",
        "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
        "        latex_output += \"\\\\hline\\n\"\n",
        "        latex_output += \"\\\\end{tabular}\\n\"\n",
        "        return latex_output\n",
        "\n",
        "    # Default is 'plain' format\n",
        "    else:\n",
        "        output = \"\"\n",
        "        # Loop through the SORTED items\n",
        "        items_list = list(sorted_items) # Convert to list for index access if needed\n",
        "        for i, (abbr, full_name) in enumerate(items_list):\n",
        "            output += f\"{abbr}: {full_name}\"\n",
        "            if i < len(items_list) - 1:\n",
        "                 output += \"; \\n\"\n",
        "        return output"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}