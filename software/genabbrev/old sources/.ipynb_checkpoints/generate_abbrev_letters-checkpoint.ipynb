{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39abbab8-5e18-4341-9e4d-2f93eb23070a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Converting .py and .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76551262",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "streamlit",
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate_abbrev_letters.ipynb to script\n",
      "[NbConvertApp] Writing 34203 bytes to generate_abbrev_letters.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.system('jupyter nbconvert --to script generate_abbrev_letters.ipynb --TagRemovePreprocessor.remove_cell_tags=\"remove\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8692cd6-6cb5-4dc5-997f-0233184e3662",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system(\"jupyter nbconvert --to notebook generate_abbrev.py --output generate_abbrev.ipynb2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c63296-15ce-4ee3-b2d7-0daf6b159243",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6ad76cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import re\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import textwrap\n",
    "\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "DEBUG = \"streamlit\" not in hostname.lower()  # Assume cloud has \"streamlit\" in hostname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7fe80-d0fb-47d6-9c79-b559e0c3b057",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Preprocessing Text with Space Inserted or Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e52da80",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Functions for normalizing and extracting abbrs\n",
    "\n",
    "# Code block prepared on Thursday, April 3, 2025 at 12:38:43 AM CST in Saskatoon, Saskatchewan, Canada.\n",
    "# Optional import for error display if using Streamlit\n",
    "# try:\n",
    "#     import streamlit as st\n",
    "# except ImportError:\n",
    "#     st = None # Define st as None if not available\n",
    "\n",
    "# This list is used by normalize_latex_math\n",
    "upper_greek_cmds = [\n",
    "    'Gamma', 'Delta', 'Theta', 'Lambda', 'Xi', 'Pi',\n",
    "    'Sigma', 'Upsilon', 'Phi', 'Psi', 'Omega'\n",
    "]\n",
    "\n",
    "#Here's a summary of the functions:\n",
    "\n",
    "# normalize_dollar_spacing(text) (from artifact normalize_dollar_spacing_code)\n",
    "\n",
    "# Purpose: This function cleans up LaTeX text strings. Specifically, it looks for the dollar signs ($) used for inline math. It removes any extra whitespace found immediately after an opening $ and immediately before a closing $. This helps standardize the formatting around inline math expressions.\n",
    "\n",
    "# render_dataframe_with_latex(df) (from artifact render_df_latex_code)\n",
    "\n",
    "# Purpose: This function takes a data table (specifically, a Pandas DataFrame) that contains text with LaTeX math code in its cells. It converts this table into HTML format. Importantly, it also includes the necessary setup for the MathJax library within that HTML. The result is an HTML object that, when displayed in a compatible environment (like a Jupyter notebook or a web browser), will show the table with the LaTeX code rendered as proper mathematical symbols and equations, rather than just the raw code.\n",
    "\n",
    "# In short, one function cleans up spacing around LaTeX math delimiters in text, and the other helps display a data table containing LaTeX math correctly rendered in environments that support HTML and JavaScript.\n",
    "\n",
    "\n",
    "\n",
    "def normalize_dollar_spacing(text):\n",
    "    \"\"\"\n",
    "    Removes whitespace immediately following an opening inline math '$' AND\n",
    "    whitespace immediately preceding a closing inline math '$'.\n",
    "    Handles escaped '\\$'.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string potentially containing LaTeX.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed string.\n",
    "    \"\"\"\n",
    "    processed_chars = []\n",
    "    in_math_mode = False\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while i < n:\n",
    "        char = text[i]\n",
    "\n",
    "        # Check for escaped dollar sign or backslash first\n",
    "        if char == '\\\\' and i + 1 < n:\n",
    "            # Keep backslash and the next character (e.g., '\\$' or '\\\\')\n",
    "            processed_chars.append(char)\n",
    "            processed_chars.append(text[i+1])\n",
    "            i += 2 # Skip both characters\n",
    "            continue\n",
    "\n",
    "        # Check for unescaped dollar sign\n",
    "        if char == '$':\n",
    "            if not in_math_mode:\n",
    "                # --- This is an OPENING dollar sign ---\n",
    "                processed_chars.append(char) # Keep the opening dollar\n",
    "                in_math_mode = True\n",
    "                # Check if the next characters are whitespace and skip them\n",
    "                j = i + 1\n",
    "                while j < n and text[j].isspace():\n",
    "                    j += 1\n",
    "                # Advance 'i' past the dollar and the skipped whitespace\n",
    "                i = j\n",
    "                continue # Continue to next iteration\n",
    "            else:\n",
    "                # --- This is a CLOSING dollar sign ---\n",
    "                in_math_mode = False\n",
    "                # Remove any trailing whitespace added just before this closing '$'\n",
    "                while processed_chars and processed_chars[-1].isspace():\n",
    "                    processed_chars.pop()\n",
    "                processed_chars.append(char) # Append the closing dollar\n",
    "                # Advance 'i' past the dollar for the next iteration\n",
    "                i += 1\n",
    "                continue # Continue to next iteration\n",
    "        else:\n",
    "            # Any other character\n",
    "            processed_chars.append(char)\n",
    "            i += 1 # Advance 'i' past the character\n",
    "\n",
    "    return \"\".join(processed_chars)\n",
    "\n",
    "# --- Normalization Function ---\n",
    "def normalize_latex_math(text):\n",
    "    \"\"\"\n",
    "    Preprocesses LaTeX text:\n",
    "    1. Converts LaTeX inline math \\( ... \\) to $ ... $.\n",
    "    2. Removes LaTeX comments (% to end of line), respecting \\%.\n",
    "    3. Removes preamble/end tags if \\begin{document} is found.\n",
    "    4a. Adds space BEFORE and AFTER opening curly braces ({).\n",
    "    4b. Adds space BEFORE and AFTER closing curly braces (}).\n",
    "    5. Adds space after specific uppercase Greek commands (\\Cmd) if not present. (Note: Using corrected pattern)\n",
    "    6. Adds space after lowercase LaTeX commands (\\cmd) if not already present. (Note: Pattern may be restrictive)\n",
    "    7. Removes whitespace immediately following $. (Moved Step)\n",
    "    8. Cleans up extra blank lines and trims whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        print(\"Warning: Input to normalize_latex_math was not a string.\")\n",
    "        return text\n",
    "\n",
    "    processed_text = text\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        # 0. Remove space inside $ $\n",
    "        processed_text =  normalize_dollar_spacing(processed_text)\n",
    "\n",
    "        # 1. Normalize math \\(...\\) to $...$\n",
    "        processed_text = re.sub(\n",
    "            r'\\\\\\(\\s*(.*?)\\s*\\\\\\)',\n",
    "            lambda match: f\"${match.group(1).strip()}$\",\n",
    "            processed_text\n",
    "        )\n",
    "\n",
    "        # 2. Remove LaTeX comment lines (respects \\%)\n",
    "        processed_text = re.sub(r'(?<!\\\\)%.*$', '', processed_text, flags=re.MULTILINE)\n",
    "\n",
    "        # 3. Remove preamble IF \\begin{document} exists\n",
    "        begin_doc_marker = r'\\begin{document}'\n",
    "        begin_doc_index = processed_text.find(begin_doc_marker)\n",
    "        if begin_doc_index != -1:\n",
    "            processed_text = processed_text[begin_doc_index + len(begin_doc_marker):]\n",
    "        # 3b. Remove \\end{document} if present near the end\n",
    "        end_doc_marker = r'\\end{document}'\n",
    "        end_doc_index = processed_text.rfind(end_doc_marker)\n",
    "        if end_doc_index != -1 and len(processed_text) - end_doc_index < 30: # Heuristic check\n",
    "            processed_text = processed_text[:end_doc_index]\n",
    "\n",
    "        # --- Spacing Adjustments ---\n",
    "        # 4a. Add space BEFORE and AFTER { (handles existing spaces robustly)\n",
    "        processed_text = re.sub(r'\\s*\\{\\s*', r' { ', processed_text)\n",
    "        # 4b. Add space BEFORE and AFTER } (handles existing spaces robustly)\n",
    "        processed_text = re.sub(r'\\s*\\}\\s*', r' } ', processed_text)\n",
    "        # 4c. Add space BEFORE ( (handles no space before ()\n",
    "        processed_text = re.sub(r'\\s*\\(', r' (', processed_text)\n",
    "        \n",
    "        # 5. Add space after specific uppercase Greek commands (\\Cmd) if not followed by space\n",
    "        pattern_part = '|'.join(upper_greek_cmds)\n",
    "        # Using corrected pattern (no space after \\\\)\n",
    "        pattern_upper = rf'(\\\\({pattern_part}))(?!\\s)'\n",
    "        processed_text = re.sub(pattern_upper, r'\\1 ', processed_text)\n",
    "\n",
    "        # 6. Add space after lowercase commands (\\cmd) if not followed by specific pattern\n",
    "        # !!! Note: This pattern (?=[A-Z][^a-z]) might be too restrictive.\n",
    "        processed_text = re.sub(r'(\\\\[a-z]+)(?=[A-Z][^a-z])', r'\\1 ', processed_text)\n",
    "\n",
    "\t\t# 7. Remove one or more whitespace characters (\\s+) immediately after a dollar sign ($) (Moved Step)\n",
    "        #processed_text = re.sub(r'\\$\\s+', '$', processed_text)\n",
    "\n",
    "        # 8. Clean up potential excessive blank lines and trim overall whitespace\n",
    "        processed_text = re.sub(r'(\\n\\s*){2,}', '\\n', processed_text) # Collapse blank lines\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text) # Collapse blank lines\n",
    "        \n",
    "\n",
    "        return processed_text\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during LaTeX text preprocessing: {e}\"\n",
    "        try:\n",
    "            # Attempt to use streamlit for error display if available\n",
    "            import streamlit as st\n",
    "            st.error(error_message)\n",
    "        except ImportError:\n",
    "            # Fallback to print if streamlit is not available\n",
    "            print(error_message)\n",
    "        return text # Return original text on error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a21706-10b7-4f2a-a417-e33d95a1f534",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Finding Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05a3252e-617a-42d1-bdbe-93174491100a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Find_abbreviation_matches for 'aTSN\\gamma_1':\n",
      "                                            0  1  2  3   4  5       6  7          8  9    10 11     12 13    14 15        16\n",
      "    Words Ahead          \\frac{\\alpha}{\\beta},     I     am     typing     something     non  -  sense     with     \\gamma_2\n",
      "    Words Ahead Letters                      f     i      a          t             s       n         s        w            g\n",
      "    Abbrs Letter                                          a          t             s       n                               g\n",
      "    Abbrs String                                          a          T             S       N                          \\gamma\n"
     ]
    }
   ],
   "source": [
    "# New Matching Functions\n",
    "import re\n",
    "import pandas as pd # Needed for debug DataFrame output\n",
    "import textwrap     # Needed for indented debug output\n",
    "\n",
    "# --- Helper Functions ---\n",
    "# Assume get_letters_abbrs and get_letters_words are defined as previously modified\n",
    "\n",
    "# RENAMED: get_abbr_repr_items -> get_letters_abbrs\n",
    "def get_letters_abbrs(abbr_string):\n",
    "    \"\"\"\n",
    "    Parses abbreviation string, returns list of single lowercase letters\n",
    "    (comparable units) AND list of corresponding original segments.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (representative_items, original_parts)\n",
    "               - representative_items: list of single lowercase letters\n",
    "               - original_parts: list of original strings (e.g., '\\\\gamma', 'Cp', 'a')\n",
    "    \"\"\"\n",
    "    representative_items = []\n",
    "    original_parts = []\n",
    "    # Use finditer to get match objects, making it easier to get original segment\n",
    "    for match_obj in re.finditer(r'(\\\\[a-zA-Z]+)|([A-Z])([a-z]+)?|([a-z])', abbr_string):\n",
    "         original_part = match_obj.group(0) # The whole substring matched by this iteration\n",
    "         command = match_obj.group(1)\n",
    "         upper = match_obj.group(2)\n",
    "         # trailing_lower = match_obj.group(3) # Not needed for logic below\n",
    "         standalone_lower = match_obj.group(4)\n",
    "\n",
    "         current_repr_item = ''\n",
    "         current_orig_part = ''\n",
    "\n",
    "         if command:\n",
    "             if len(command) > 1:\n",
    "                 current_repr_item = command[1].lower()\n",
    "                 current_orig_part = command # Store \\command\n",
    "         elif upper:\n",
    "             current_repr_item = upper.lower()\n",
    "             current_orig_part = original_part # Store Upper + optional lower e.g. \"Cp\"\n",
    "         elif standalone_lower:\n",
    "             current_repr_item = standalone_lower\n",
    "             current_orig_part = standalone_lower # Store lower\n",
    "\n",
    "         # Only append if we successfully identified a part\n",
    "         if current_repr_item:\n",
    "             representative_items.append(current_repr_item)\n",
    "             original_parts.append(current_orig_part)\n",
    "\n",
    "    return representative_items, original_parts # Return tuple\n",
    "\n",
    "# RENAMED: get_effective_char -> get_letters_words\n",
    "def get_letters_words(word: str, debug: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Derives the single effective first letter (lowercase) from a word token,\n",
    "    attempting to handle common LaTeX markup (including commands). Renamed from get_effective_char.\n",
    "    Returns an empty string for separators or if no letter is found.\n",
    "    \"\"\"\n",
    "    original_word = word\n",
    "    word = word.strip()\n",
    "    if not word: return ''\n",
    "    word_to_check = word\n",
    "    try:\n",
    "        # Logic attempts to find the first semantic letter, lowercased\n",
    "        m = re.match(r'\\s*\\\\([a-zA-Z]+)', word_to_check)\n",
    "        if m:\n",
    "             command_name = m.group(1)\n",
    "             if command_name: word_to_check = command_name # Use command name itself for first letter\n",
    "\n",
    "        # Strip leading non-alpha chars after potential cmd name extraction (simplistic)\n",
    "        word_to_check = re.sub(r'^[^a-zA-Z]+', '', word_to_check)\n",
    "        # Strip trailing brace if present\n",
    "        if word_to_check.endswith('}'): word_to_check = word_to_check[:-1].rstrip()\n",
    "\n",
    "        first_letter_match = re.search(r'[a-zA-Z]', word_to_check)\n",
    "        if first_letter_match: return first_letter_match.group(0).lower()\n",
    "\n",
    "        # Fallback if stripping might have removed the only letter\n",
    "        # (Consider simplifying this if initial logic becomes robust)\n",
    "        fallback_match_orig = re.search(r'[a-zA-Z]', original_word)\n",
    "        if fallback_match_orig: return fallback_match_orig.group(0).lower()\n",
    "\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        if debug: print(f\"      Error in get_letters_words for '{original_word}': {e}\") # Updated function name in error\n",
    "        # Fallback on error\n",
    "        fallback_match = re.search(r'[a-zA-Z]', original_word)\n",
    "        return fallback_match.group(0).lower() if fallback_match else ''\n",
    "\n",
    "\n",
    "# --- MODIFIED find_abbreviation_matches ---\n",
    "# Renamed variables and uses renamed functions\n",
    "# Removed one specific debug print statement inside inner loop\n",
    "def find_abbreviation_matches(words_ahead, abbr_string, debug=True):\n",
    "    \"\"\"\n",
    "    Performs backward matching. Takes original abbr string, calculates items internally.\n",
    "    Returns lists mapping word index to the matched original abbreviation part\n",
    "    and the matched comparable abbreviation letter.\n",
    "\n",
    "    Args:\n",
    "        words_ahead (list): List of word tokens from the definition part.\n",
    "        abbr_string (str): The original abbreviation string (e.g., \"GLM\", \"\\\\alpha\\\\beta C\").\n",
    "        debug (bool): Flag to enable console debug printing, including final DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (matched_abbrs_string, matched_abbrs_letters)\n",
    "               - matched_abbrs_string: List same len as words_ahead, contains original abbr part (e.g., 'G', '\\\\alpha') or ''\n",
    "               - matched_abbrs_letters: List same len as words_ahead, contains abbr letter (e.g., 'g', 'a') or ''\n",
    "               Returns (None, None) if abbreviation parsing fails.\n",
    "    \"\"\"\n",
    "    # --- Internal Calculation ---\n",
    "    try:\n",
    "        abbr_items, original_abbr_parts = get_letters_abbrs(abbr_string)\n",
    "        if not abbr_items:\n",
    "             if debug: print(f\"Warning: Abbreviation string '{abbr_string}' yielded no items to match.\")\n",
    "             num_words_fail = len(words_ahead)\n",
    "             return [''] * num_words_fail, [''] * num_words_fail\n",
    "    except Exception as e_parse:\n",
    "         if debug: print(f\"Error parsing abbreviation string '{abbr_string}' using get_letters_abbrs: {e_parse}\")\n",
    "         num_words_fail = len(words_ahead)\n",
    "         return [''] * num_words_fail, [''] * num_words_fail\n",
    "\n",
    "    num_abbr_items = len(abbr_items)\n",
    "    num_words = len(words_ahead)\n",
    "    # --- END Internal Calculation ---\n",
    "\n",
    "\n",
    "    # --- Initialization ---\n",
    "    match_indices = [-1] * num_abbr_items # Keep internal track of abbr->word index map\n",
    "    matched_abbrs_string = [''] * num_words      # Output: word_idx -> original_abbr_part\n",
    "    matched_abbrs_letters = [''] * num_words # Output: word_idx -> abbr_item_letter\n",
    "    # --- END Initialization ---\n",
    "\n",
    "    last_matched_index = num_words\n",
    "    words_ahead_letters = [get_letters_words(word, debug=False) for word in words_ahead]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\nFind_abbreviation_matches for '{abbr_string}':\")\n",
    "    if False:\n",
    "        print(f\"  Input Abbr String: '{abbr_string}'\")\n",
    "        print(f\"  Words Ahead ({num_words}): {words_ahead}\")\n",
    "        print(f\"  Words Ahead Letters ({len(words_ahead_letters)}): {words_ahead_letters}\")\n",
    "        print(f\"  Abbr Items (Letters) ({num_abbr_items}): {abbr_items}\")\n",
    "        print(f\"  Original Abbr Parts ({len(original_abbr_parts)}): {original_abbr_parts}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    # --- Matching Loop ---\n",
    "    for abbr_idx in range(num_abbr_items - 1, -1, -1):\n",
    "        target_comparable = abbr_items[abbr_idx]\n",
    "        match_found_for_abbr = False\n",
    "        if not target_comparable: continue\n",
    "\n",
    "        for word_idx in range(last_matched_index - 1, -1, -1):\n",
    "            word_comparable = words_ahead_letters[word_idx]\n",
    "            if not word_comparable: continue\n",
    "\n",
    "            current_match_found = (target_comparable == word_comparable)\n",
    "\n",
    "            # --- DEBUG PRINT BLOCK DELETED ---\n",
    "            # The following block was removed as requested:\n",
    "            # if debug:\n",
    "            #      original_word = words_ahead[word_idx]\n",
    "            #      print(f\"  Compare Abbr[{abbr_idx}]('{target_comparable}') vs Word[{word_idx}]('{original_word}' -> '{word_comparable}'): Match = {current_match_found}\")\n",
    "            # --- END DELETED BLOCK ---\n",
    "\n",
    "            if current_match_found:\n",
    "                match_indices[abbr_idx] = word_idx # Still track this internally\n",
    "                last_matched_index = word_idx\n",
    "                match_found_for_abbr = True\n",
    "                # This debug print remains if needed:\n",
    "                #if debug: print(f\"    >> Internal Match: Storing word index {word_idx} for abbr index {abbr_idx}.\")\n",
    "                break\n",
    "\n",
    "        # This debug print remains if needed:\n",
    "        if not match_found_for_abbr and debug:\n",
    "             print(f\"  No matching word found for Abbr[{abbr_idx}]('{target_comparable}')\")\n",
    "    # --- END Matching Loop ---\n",
    "\n",
    "    # --- Populate Output Lists ---\n",
    "    for abbr_idx, word_idx in enumerate(match_indices):\n",
    "        if word_idx != -1:\n",
    "            if 0 <= word_idx < num_words:\n",
    "                if 0 <= abbr_idx < len(abbr_items):\n",
    "                    matched_abbrs_letters[word_idx] = abbr_items[abbr_idx]\n",
    "                if 0 <= abbr_idx < len(original_abbr_parts):\n",
    "                    matched_abbrs_string[word_idx] = original_abbr_parts[abbr_idx]\n",
    "    # --- END Populate Output Lists ---\n",
    "\n",
    "\n",
    "    # --- Final Debugging Output (DataFrame) ---\n",
    "    if debug:\n",
    "        #print(\"-\" * 20)\n",
    "        #print(\"  Final Matching Result (Processing for Debug DataFrame):\")\n",
    "        try:\n",
    "            debug_data = {\n",
    "                'Words Ahead': words_ahead,\n",
    "                'Words Ahead Letters': words_ahead_letters,\n",
    "                'Abbrs Letter': matched_abbrs_letters,\n",
    "                'Abbrs String': matched_abbrs_string            \n",
    "            }\n",
    "            df_debug = pd.DataFrame(debug_data)\n",
    "\n",
    "            #print(f\"\\n  Matching Result (Rows: Words, Letters, Matched String, Matched Letter):\")\n",
    "            df_debug_string = df_debug.T.to_string()\n",
    "            indent_prefix = \"    \"\n",
    "            indented_output = textwrap.indent(df_debug_string, prefix=indent_prefix)\n",
    "            print(indented_output)\n",
    "\n",
    "        except Exception as e_debug:\n",
    "            print(f\"\\n  [DEBUG] Error creating or printing final debug DataFrame:\")\n",
    "            error_message = f\"    Error Type: {type(e_debug).__name__} - {e_debug}\"\n",
    "            print(error_message)\n",
    "        #print(\"--- Ending find_abbreviation_matches ---\\n\")\n",
    "    # --- END Debugging Output ---\n",
    "\n",
    "    # --- Return the two calculated lists ---\n",
    "    return matched_abbrs_string, matched_abbrs_letters\n",
    "\n",
    "\n",
    "# Testing the function\n",
    "words_string = r\"\\frac{\\alpha}{\\beta}, I am typing something non-sense with \\gamma_2\" # Example string\n",
    "# Use re.split - it will include the captured delimiters in the list\n",
    "test_words_ahead = re.split(r'([ -]+)', words_string)\n",
    "test_abbr_string = \"aTSN\\\\gamma_1\"\n",
    "\n",
    "# Call the function with debug=True\n",
    "matched_strings, matched_letters = find_abbreviation_matches(\n",
    "    test_words_ahead,\n",
    "    test_abbr_string,\n",
    "    debug=True # <<< DEBUG ENABLED\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598d4f-64fc-4a0c-b19b-329e0fba2700",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Extracting Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53df77a1-2dda-45f0-bec2-11fec4bd519b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified extract_abbreviations to address the changes of matching function output/input\n",
    "\n",
    "\n",
    "def get_sort_key_from_abbr(abbr_string):\n",
    "    \"\"\"Generates a lowercase string key for sorting abbreviations.\"\"\"\n",
    "    repr_letters = get_abbr_repr_items(abbr_string)\n",
    "    sort_key = \"\".join(repr_letters).lower()\n",
    "    if not sort_key:\n",
    "         fallback_key = re.sub(r\"^[^\\w]+\", \"\", abbr_string.lower())\n",
    "         return fallback_key\n",
    "    return sort_key\n",
    "\n",
    "\n",
    "# --- Assumed Helper Functions ---\n",
    "# Ensure the LATEST versions of these functions (as defined previously)\n",
    "# are available in the same scope or imported:\n",
    "#\n",
    "# def get_letters_abbrs(abbr_string) -> tuple[list, list]:\n",
    "#     # ... implementation returning (representative_items, original_parts) ...\n",
    "#\n",
    "# def get_letters_words(word: str, debug: bool = False) -> str:\n",
    "#     # ... implementation returning single lowercase letter or '' ...\n",
    "#\n",
    "# def find_abbreviation_matches(words_ahead, abbr_string, debug=True) -> tuple[list, list]:\n",
    "#     # ... implementation returning (matched_abbrs_string, matched_abbrs_letters) ...\n",
    "#     # And performing internal debug prints / DataFrame output if debug=True\n",
    "#\n",
    "# --- END Assumed Helper Functions ---\n",
    "\n",
    "\n",
    "# --- Updated Main Extraction Function ---\n",
    "def extract_abbreviations(text, match_threshold=0.7, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts abbreviations defined as (Abbr) following their definition.\n",
    "    Validates match based on ratio of matched components. Includes usage counts.\n",
    "    Uses updated helper functions and matching logic.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text potentially containing definitions.\n",
    "        match_threshold (float): The minimum fraction (e.g., 0.7) of abbreviation\n",
    "                                 components that must match preceding words.\n",
    "        debug (bool): Flag to enable detailed debug printing in this function\n",
    "                      and potentially called functions (find_abbreviation_matches).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'abbreviation', 'full_name', 'usage_count',\n",
    "                      sorted by usage_count (desc), then abbreviation (asc).\n",
    "                      Returns an empty DataFrame if no valid abbreviations found.\n",
    "    \"\"\"\n",
    "    # Define pattern to find Definition (Abbr) structure\n",
    "    pattern = r'((?:[\\w\\\\\\$\\{\\}]+[ -]+){1,10}(?:[\\w\\\\\\$\\{\\}]+)[ -]?)\\(([^\\(\\)]*[a-zA-Z0-9]{2,}[^\\(\\)]*)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    abbreviation_dict = {} # To store final validated {abbr_string: {details}}\n",
    "    abbr_usage_count = {}  # To store usage counts\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential definition candidates.\")\n",
    "\n",
    "    # --- Count Abbreviation Usages ---\n",
    "    all_potential_abbrs = [match[1].strip() for match in matches]\n",
    "    for abbr in set(all_potential_abbrs):\n",
    "        abbr_search_string = re.sub(r'[\\(\\)]', '', abbr)\n",
    "        abbr_usage_pattern = rf'(?<![a-zA-Z\\(\\)]){re.escape(abbr_search_string)}(?![a-zA-Z\\)\\)])' # Added spaces\n",
    "        try:\n",
    "            count = len(re.findall(abbr_usage_pattern, text))\n",
    "            abbr_usage_count[abbr] = count\n",
    "        except re.error as re_err:\n",
    "             if debug: print(f\"  Regex error counting usage for '{abbr}': {re_err}\")\n",
    "             abbr_usage_count[abbr] = 0\n",
    "    if debug:\n",
    "        print(f\"  Initial Abbreviation Usage Counts: {abbr_usage_count}\")\n",
    "    # --- END Usage Count ---\n",
    "\n",
    "\n",
    "    # --- Process Matches, Validate, and Reconstruct ---\n",
    "    for match_idx, match in enumerate(matches): # Use enumerate if index is needed for debug\n",
    "        words_before_abbr_text = match[0].strip()\n",
    "        abbr_string = match[1].strip() # The original abbreviation string\n",
    "        current_usage_count = abbr_usage_count.get(abbr_string, 0)\n",
    "\n",
    "        if debug:\n",
    "             print(f\"\\n--- Candidate {match_idx+1}: Abbr='{abbr_string}', Before='{words_before_abbr_text}' ---\")\n",
    "\n",
    "        # 1. Tokenize words before abbreviation\n",
    "        split_pattern = r'([ -]+)'\n",
    "        split_list = re.split(split_pattern, words_before_abbr_text)\n",
    "        words_ahead = [item for item in split_list if item]\n",
    "        if not words_ahead:\n",
    "             if debug: print(\"  Skipping: No words found before abbreviation.\")\n",
    "             continue\n",
    "\n",
    "        # 2. Get comparable letters AND original parts for the abbreviation\n",
    "        try:\n",
    "            # Use the function that returns two lists\n",
    "            abbr_items, original_abbr_parts = get_letters_abbrs(abbr_string)\n",
    "            if not abbr_items:\n",
    "                if debug: print(f\"  Skipping: Abbreviation '{abbr_string}' yielded no parsable items.\")\n",
    "                continue\n",
    "            num_abbr_items = len(abbr_items) # Needed for validation ratio\n",
    "        except Exception as e_parse:\n",
    "            if debug: print(f\"  Skipping: Error parsing abbreviation '{abbr_string}': {e_parse}\")\n",
    "            continue\n",
    "\n",
    "        # 3. Call the updated find_abbreviation_matches\n",
    "        #    Pass the original abbr_string; receive word -> mappings\n",
    "        #    Pass the main debug flag down to control find_abbreviation_matches' verbosity\n",
    "        matched_abbrs_string, matched_abbrs_letters = find_abbreviation_matches(\n",
    "            words_ahead,\n",
    "            abbr_string,\n",
    "            debug=debug # Pass the flag down\n",
    "        )\n",
    "\n",
    "        # 4. Perform Validation based on the results\n",
    "        #    Count how many words were successfully matched to an abbreviation letter\n",
    "        count_matched = sum(1 for letter in matched_abbrs_letters if letter)\n",
    "\n",
    "        valid_match = False\n",
    "        if num_abbr_items > 0:\n",
    "            ratio_matched = count_matched / num_abbr_items\n",
    "            if ratio_matched >= match_threshold:\n",
    "                valid_match = True\n",
    "            # Optionally print failure reason only if debug is high level\n",
    "            elif debug: # Only print failure if debug is on for extract_abbreviations\n",
    "                print(f\"  Validation Failed: Match ratio {ratio_matched:.2f} ({count_matched}/{num_abbr_items}) < threshold {match_threshold:.2f}\")\n",
    "        elif debug:\n",
    "            print(f\"  Validation Failed: num_abbr_items is 0 for '{abbr_string}'.\")\n",
    "\n",
    "\n",
    "        # 5. Reconstruct Full Name if Valid\n",
    "        if valid_match:\n",
    "            # Find the indices of the words that were matched by looking for non-empty letters\n",
    "            matched_word_indices = [idx for idx, letter in enumerate(matched_abbrs_letters) if letter]\n",
    "\n",
    "            if not matched_word_indices:\n",
    "                # This case should ideally not happen if count_matched > 0 and threshold >= 0\n",
    "                if debug: print(\"  Skipping: Match deemed valid, but no matched word indices found (Error?).\")\n",
    "                continue\n",
    "\n",
    "            min_idx_py = min(matched_word_indices)\n",
    "            max_idx_py = max(matched_word_indices)\n",
    "\n",
    "            # Ensure indices are valid for slicing words_ahead\n",
    "            if 0 <= min_idx_py <= max_idx_py < len(words_ahead):\n",
    "                # Slice using the found min/max indices of matched words\n",
    "                full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
    "                full_name = ''.join(full_phrase_words_slice)\n",
    "\n",
    "                # Store valid result in the dictionary\n",
    "                if debug:\n",
    "                     print(f\"  VALID MATCH FOUND: Storing '{abbr_string}' -> '{full_name}' (Usage: {current_usage_count})\")\n",
    "\n",
    "                abbreviation_dict[abbr_string] = {\n",
    "                    'full_name': full_name,\n",
    "                    'usage_count': current_usage_count\n",
    "                }\n",
    "            else:\n",
    "                 # This might happen if words_ahead list was unexpectedly short\n",
    "                 if debug: print(f\"  Skipping: Invalid index range [{min_idx_py}:{max_idx_py+1}] derived for words_ahead length {len(words_ahead)}.\")\n",
    "        # --- End Reconstruction ---\n",
    "    # --- End Main Loop Over Matches ---\n",
    "\n",
    "\n",
    "    # --- Final DataFrame Creation and Sorting (No changes needed here) ---\n",
    "    if not abbreviation_dict:\n",
    "        if debug: print(\"\\nNo valid abbreviations extracted meeting criteria.\")\n",
    "        return pd.DataFrame(columns=['abbreviation', 'full_name', 'usage_count'])\n",
    "\n",
    "    if debug: print(f\"\\nCreating final DataFrame from {len(abbreviation_dict)} valid abbreviations.\")\n",
    "\n",
    "    try:\n",
    "        final_df = pd.DataFrame.from_dict(abbreviation_dict, orient='index')\n",
    "        final_df = final_df.reset_index().rename(columns={'index': 'abbreviation'})\n",
    "        final_df = final_df.sort_values(\n",
    "            by=['usage_count', 'abbreviation'],\n",
    "            ascending=[False, True],\n",
    "            ignore_index=True # Keep this True - creates the 0-based index\n",
    "        )\n",
    "\n",
    "        # --- MODIFICATION: Add Row Number Column ---\n",
    "        # Add a 'Row No.' column starting from 1, inserting it at the beginning (index 0)\n",
    "        final_df.insert(0, 'Row No.', final_df.index + 1)\n",
    "        # --- END MODIFICATION ---\n",
    "\n",
    "        # Ensure column order, now including 'Row No.'\n",
    "        # MODIFICATION: Update column list\n",
    "        final_df = final_df[['Row No.', 'abbreviation', 'full_name', 'usage_count']]\n",
    "\n",
    "    except Exception as e_df:\n",
    "        if debug: print(f\"Error creating or sorting final DataFrame: {e_df}\")\n",
    "        # MODIFICATION: Add 'Row No.' column definition for error case\n",
    "        return pd.DataFrame(columns=['Row No.', 'abbreviation', 'full_name', 'usage_count'])\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b0656-b735-45ef-af7c-33fde94a3970",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Formatting abbrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d212994a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def format_abbreviations(sorted_items, format_type=\"plain\"):\n",
    "    \"\"\"Formats the extracted abbreviations based on the specified type.\n",
    "       Sorts abbreviations alphabetically, handling LaTeX commands in keys.\n",
    "       ASSUMES extracted abbr and full_name are valid LaTeX snippets\n",
    "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
    "    \"\"\"\n",
    "    if not sorted_items:\n",
    "        return \"No abbreviations found.\"\n",
    "\n",
    "    #sorted_items = abbreviations_dict.items()\n",
    "    if format_type == \"nomenclature\":\n",
    "        # LaTeX nomenclature package format\n",
    "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
    "        latex_output += \"\\\\makenomenclature\\n\"\n",
    "        for abbr, full_name in sorted_items:\n",
    "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    elif format_type == \"tabular\":\n",
    "        # LaTeX tabular format for a table\n",
    "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        for abbr, full_name in sorted_items:\n",
    "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\end{tabular}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    else:\n",
    "        # Default format: plain list of abbreviations and full names\n",
    "        output = \"\"\n",
    "        items_list = list(sorted_items)  # Convert to list for index access if needed\n",
    "        for i, (abbr, full_name) in enumerate(items_list):\n",
    "            output += f\"{abbr}: {full_name}\"\n",
    "            if i < len(items_list) - 1:\n",
    "                output += \"; \\n\"  # Adds a semicolon between items\n",
    "        return output\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d80636a-7888-407c-84b9-30abebd73873",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_abbreviations(abbr_df, format_type=\"plain\"):\n",
    "    \"\"\"Formats the extracted abbreviations DataFrame based on the specified type.\n",
    "       Assumes the input DataFrame is already sorted alphabetically by 'abbreviation'.\n",
    "       ASSUMES 'abbreviation' and 'full_name' columns contain valid LaTeX snippets\n",
    "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
    "\n",
    "    Args:\n",
    "        abbr_df (pd.DataFrame): DataFrame with at least 'abbreviation' and 'full_name' columns.\n",
    "                                Expected to be sorted by 'abbreviation'.\n",
    "        format_type (str): The desired output format ('nomenclature', 'tabular', or other for plain text).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the abbreviations, or a message if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    # Check if the input DataFrame is empty\n",
    "    if abbr_df.empty:\n",
    "        return \"No abbreviations found.\"\n",
    "\n",
    "    # NOTE: Sorting is assumed to have been done *before* this function is called.\n",
    "\n",
    "    if format_type == \"nomenclature\":\n",
    "        # LaTeX nomenclature package format\n",
    "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
    "        latex_output += \"\\\\makenomenclature\\n\"\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    elif format_type == \"tabular\":\n",
    "        # LaTeX tabular format for a table\n",
    "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\end{tabular}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    else:\n",
    "        # Default format: plain list of abbreviations and full names\n",
    "        output_parts = []\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            output_parts.append(f\"{abbr}: {full_name}\")\n",
    "\n",
    "        # Join the parts with \"; \\n\" separator\n",
    "        return \"; \\n\".join(output_parts)\n",
    "\n",
    "# Example Usage (assuming df_results is a DataFrame from extract_abbreviations):\n",
    "# df_results = pd.DataFrame({\n",
    "#    'abbreviation': ['CAD', 'FBI', 'USA'],\n",
    "#    'full_name': ['Canada', 'Federal Bureau of Investigation', 'United States of America'],\n",
    "#    'usage_count': [1, 2, 3] # usage_count is ignored by this function\n",
    "# })\n",
    "\n",
    "# print(\"--- Nomenclature Format ---\")\n",
    "# print(format_abbreviations(df_results, \"nomenclature\"))\n",
    "# print(\"\\n--- Tabular Format ---\")\n",
    "# print(format_abbreviations(df_results, \"tabular\"))\n",
    "# print(\"\\n--- Plain Text Format ---\")\n",
    "# print(format_abbreviations(df_results, \"plain\")) # Any format_type other than the two specific ones\n",
    "# print(\"\\n--- Empty DataFrame Test ---\")\n",
    "# print(format_abbreviations(pd.DataFrame(columns=['abbreviation', 'full_name']), \"tabular\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abc22e-6480-4a7a-a2a9-839c909e6940",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Example Text and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752387a-1d94-48ee-bb35-733254d2aca6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a2f758e",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "example_text = r\"\"\"Paste your latex text (LT)  and enjoy the app (ETA). There is no limitation of the length of text. \n",
    "\n",
    "What is regarded as abbreviations (RA):\n",
    "\n",
    "The abbreviations like randomized survival probabilities (RSP) and  accelerated failure time(AFT), or \\textbf{Time-Constant (TC) Data}. The full definitions and abbrievations can contain greek symbols, for example,  $\\alpha$-synclein protein ($\\alpha$-SP), $\\beta$-Z residual (BZR), $\\sigma$-Z residual ($\\sigma$-ZR), $\\frac{\\gamma}{Z}$-residuals ($\\frac{\\gamma}{Z}$-R). The first letters of latex commands will be used to compare against the abbreviation letters.\n",
    "\n",
    "What is desregarded as abbreviations (DA):\n",
    "\n",
    "Citations and explanations in brackets will be omitted, eg. this one (Li et al. 2025), and this ($\\beta$). The $T$ in $f(T)$ is not an abbreviation too.   %This abbreviation, comment text (CT) or the line starting with % will be omitted. \n",
    "\n",
    "The abbreviations used above include: AFT, BZR,  DA,  ETA, LT, RSP,  RA, TC, $\\alpha$-SP, $\\frac{\\gamma}{Z}$-R, $\\sigma$-ZR.  \n",
    "\n",
    "Note: the extraction is not perfect as it cannot accommodate all possible abbreviations and may include those you don't want. Modify the results as necessary.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e7358-57f6-484b-9878-44f65cc9e98b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f4a0a6b",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your latex text (LT) and enjoy the app (ETA). There is no limitation of the length of text. What is regarded as abbreviations (RA): The abbreviations like randomized survival probabilities (RSP) and accelerated failure time (AFT), or \\textbf { Time-Constant (TC) Data } . The full definitions and abbrievations can contain greek symbols, for example, $\\alpha$-synclein protein ($\\alpha$-SP), $\\beta$-Z residual (BZR), $\\sigma$-Z residual ($\\sigma$-ZR), $\\frac { \\gamma } { Z } $-residuals ($\\frac { \\gamma } { Z } $-R). The first letters of latex commands will be used to compare against the abbreviation letters. What is desregarded as abbreviations (DA): Citations and explanations in brackets will be omitted, eg. this one (Li et al. 2025), and this ($\\beta$). The $T$ in $f (T)$ is not an abbreviation too. The abbreviations used above include: AFT, BZR, DA, ETA, LT, RSP, RA, TC, $\\alpha$-SP, $\\frac { \\gamma } { Z } $-R, $\\sigma$-ZR. Note: the extraction is not perfect as it cannot accommodate all possible abbreviations and may include those you don't want. Modify the results as necessary. \n",
      "\n",
      "Debugging extract_abbreviations: Found 13 potential definition candidates.\n",
      "  Initial Abbreviation Usage Counts: {'$\\\\sigma$-ZR': 1, 'RA': 1, 'RSP': 1, '$\\\\frac { \\\\gamma } { Z } $-R': 1, 'Li et al. 2025': 0, '$\\\\beta$': 1, '$\\\\alpha$-SP': 1, 'TC': 1, 'LT': 1, 'AFT': 1, 'DA': 1, 'BZR': 1, 'ETA': 1}\n",
      "\n",
      "--- Candidate 1: Abbr='LT', Before='Paste your latex text' ---\n",
      "\n",
      "Find_abbreviation_matches for 'LT':\n",
      "                             0  1     2  3      4  5     6\n",
      "    Words Ahead          Paste     your     latex     text\n",
      "    Words Ahead Letters      p        y         l        t\n",
      "    Abbrs Letter                                l        t\n",
      "    Abbrs String                                L        T\n",
      "  VALID MATCH FOUND: Storing 'LT' -> 'latex text' (Usage: 1)\n",
      "\n",
      "--- Candidate 2: Abbr='ETA', Before='and enjoy the app' ---\n",
      "\n",
      "Find_abbreviation_matches for 'ETA':\n",
      "                           0  1      2  3    4  5    6\n",
      "    Words Ahead          and     enjoy     the     app\n",
      "    Words Ahead Letters    a         e       t       a\n",
      "    Abbrs Letter                     e       t       a\n",
      "    Abbrs String                     E       T       A\n",
      "  VALID MATCH FOUND: Storing 'ETA' -> 'enjoy the app' (Usage: 1)\n",
      "\n",
      "--- Candidate 3: Abbr='RA', Before='What is regarded as abbreviations' ---\n",
      "\n",
      "Find_abbreviation_matches for 'RA':\n",
      "                            0  1   2  3         4  5   6  7              8\n",
      "    Words Ahead          What     is     regarded     as     abbreviations\n",
      "    Words Ahead Letters     w      i            r      a                 a\n",
      "    Abbrs Letter                                r                        a\n",
      "    Abbrs String                                R                        A\n",
      "  VALID MATCH FOUND: Storing 'RA' -> 'regarded as abbreviations' (Usage: 1)\n",
      "\n",
      "--- Candidate 4: Abbr='RSP', Before='The abbreviations like randomized survival probabilities' ---\n",
      "\n",
      "Find_abbreviation_matches for 'RSP':\n",
      "                          0  1              2  3     4  5           6  7         8  9              10\n",
      "    Words Ahead          The     abbreviations     like     randomized     survival     probabilities\n",
      "    Words Ahead Letters    t                 a        l              r            s                 p\n",
      "    Abbrs Letter                                                     r            s                 p\n",
      "    Abbrs String                                                     R            S                 P\n",
      "  VALID MATCH FOUND: Storing 'RSP' -> 'randomized survival probabilities' (Usage: 1)\n",
      "\n",
      "--- Candidate 5: Abbr='AFT', Before='and accelerated failure time' ---\n",
      "\n",
      "Find_abbreviation_matches for 'AFT':\n",
      "                           0  1            2  3        4  5     6\n",
      "    Words Ahead          and     accelerated     failure     time\n",
      "    Words Ahead Letters    a               a           f        t\n",
      "    Abbrs Letter                           a           f        t\n",
      "    Abbrs String                           A           F        T\n",
      "  VALID MATCH FOUND: Storing 'AFT' -> 'accelerated failure time' (Usage: 1)\n",
      "\n",
      "--- Candidate 6: Abbr='TC', Before='or \\textbf { Time-Constant' ---\n",
      "\n",
      "Find_abbreviation_matches for 'TC':\n",
      "                          0  1        2  3  4  5     6  7         8\n",
      "    Words Ahead          or     \\textbf     {     Time  -  Constant\n",
      "    Words Ahead Letters   o           t              t            c\n",
      "    Abbrs Letter                                     t            c\n",
      "    Abbrs String                                     T            C\n",
      "  VALID MATCH FOUND: Storing 'TC' -> 'Time-Constant' (Usage: 1)\n",
      "\n",
      "--- Candidate 7: Abbr='$\\alpha$-SP', Before='$\\alpha$-synclein protein' ---\n",
      "\n",
      "Find_abbreviation_matches for '$\\alpha$-SP':\n",
      "                                0  1         2  3        4\n",
      "    Words Ahead          $\\alpha$  -  synclein     protein\n",
      "    Words Ahead Letters         a            s           p\n",
      "    Abbrs Letter                a            s           p\n",
      "    Abbrs String           \\alpha            S           P\n",
      "  VALID MATCH FOUND: Storing '$\\alpha$-SP' -> '$\\alpha$-synclein protein' (Usage: 1)\n",
      "\n",
      "--- Candidate 8: Abbr='BZR', Before='$\\beta$-Z residual' ---\n",
      "\n",
      "Find_abbreviation_matches for 'BZR':\n",
      "                               0  1  2  3         4\n",
      "    Words Ahead          $\\beta$  -  Z     residual\n",
      "    Words Ahead Letters        b     z            r\n",
      "    Abbrs Letter               b     z            r\n",
      "    Abbrs String               B     Z            R\n",
      "  VALID MATCH FOUND: Storing 'BZR' -> '$\\beta$-Z residual' (Usage: 1)\n",
      "\n",
      "--- Candidate 9: Abbr='$\\sigma$-ZR', Before='$\\sigma$-Z residual' ---\n",
      "\n",
      "Find_abbreviation_matches for '$\\sigma$-ZR':\n",
      "                                0  1  2  3         4\n",
      "    Words Ahead          $\\sigma$  -  Z     residual\n",
      "    Words Ahead Letters         s     z            r\n",
      "    Abbrs Letter                s     z            r\n",
      "    Abbrs String           \\sigma     Z            R\n",
      "  VALID MATCH FOUND: Storing '$\\sigma$-ZR' -> '$\\sigma$-Z residual' (Usage: 1)\n",
      "\n",
      "--- Candidate 10: Abbr='$\\frac { \\gamma } { Z } $-R', Before='$\\frac { \\gamma } { Z } $-residuals' ---\n",
      "\n",
      "Find_abbreviation_matches for '$\\frac { \\gamma } { Z } $-R':\n",
      "                             0  1  2  3       4  5  6  7  8  9  10 11 12 13 14 15         16\n",
      "    Words Ahead          $\\frac     {     \\gamma     }     {     Z     }     $  -  residuals\n",
      "    Words Ahead Letters       f                g                 z                         r\n",
      "    Abbrs Letter              f                g                 z                         r\n",
      "    Abbrs String          \\frac           \\gamma                 Z                         R\n",
      "  VALID MATCH FOUND: Storing '$\\frac { \\gamma } { Z } $-R' -> '$\\frac { \\gamma } { Z } $-residuals' (Usage: 1)\n",
      "\n",
      "--- Candidate 11: Abbr='DA', Before='What is desregarded as abbreviations' ---\n",
      "\n",
      "Find_abbreviation_matches for 'DA':\n",
      "                            0  1   2  3            4  5   6  7              8\n",
      "    Words Ahead          What     is     desregarded     as     abbreviations\n",
      "    Words Ahead Letters     w      i               d      a                 a\n",
      "    Abbrs Letter                                   d                        a\n",
      "    Abbrs String                                   D                        A\n",
      "  VALID MATCH FOUND: Storing 'DA' -> 'desregarded as abbreviations' (Usage: 1)\n",
      "\n",
      "--- Candidate 12: Abbr='Li et al. 2025', Before='this one' ---\n",
      "\n",
      "Find_abbreviation_matches for 'Li et al. 2025':\n",
      "  No matching word found for Abbr[4]('l')\n",
      "  No matching word found for Abbr[3]('a')\n",
      "  No matching word found for Abbr[1]('e')\n",
      "  No matching word found for Abbr[0]('l')\n",
      "                            0  1    2\n",
      "    Words Ahead          this     one\n",
      "    Words Ahead Letters     t       o\n",
      "    Abbrs Letter            t        \n",
      "    Abbrs String            t        \n",
      "  Validation Failed: Match ratio 0.20 (1/5) < threshold 0.70\n",
      "\n",
      "--- Candidate 13: Abbr='$\\beta$', Before='and this' ---\n",
      "\n",
      "Find_abbreviation_matches for '$\\beta$':\n",
      "  No matching word found for Abbr[0]('b')\n",
      "                           0  1     2\n",
      "    Words Ahead          and     this\n",
      "    Words Ahead Letters    a        t\n",
      "    Abbrs Letter                     \n",
      "    Abbrs String                     \n",
      "  Validation Failed: Match ratio 0.00 (0/1) < threshold 0.70\n",
      "\n",
      "Creating final DataFrame from 11 valid abbreviations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>full_name</th>\n",
       "      <th>usage_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$\\alpha$-SP</td>\n",
       "      <td>$\\alpha$-synclein protein</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$\\frac { \\gamma } { Z } $-R</td>\n",
       "      <td>$\\frac { \\gamma } { Z } $-residuals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$\\sigma$-ZR</td>\n",
       "      <td>$\\sigma$-Z residual</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFT</td>\n",
       "      <td>accelerated failure time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BZR</td>\n",
       "      <td>$\\beta$-Z residual</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DA</td>\n",
       "      <td>desregarded as abbreviations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ETA</td>\n",
       "      <td>enjoy the app</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LT</td>\n",
       "      <td>latex text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RA</td>\n",
       "      <td>regarded as abbreviations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RSP</td>\n",
       "      <td>randomized survival probabilities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TC</td>\n",
       "      <td>Time-Constant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   abbreviation                            full_name  \\\n",
       "0                   $\\alpha$-SP            $\\alpha$-synclein protein   \n",
       "1   $\\frac { \\gamma } { Z } $-R  $\\frac { \\gamma } { Z } $-residuals   \n",
       "2                   $\\sigma$-ZR                  $\\sigma$-Z residual   \n",
       "3                           AFT             accelerated failure time   \n",
       "4                           BZR                   $\\beta$-Z residual   \n",
       "5                            DA         desregarded as abbreviations   \n",
       "6                           ETA                        enjoy the app   \n",
       "7                            LT                           latex text   \n",
       "8                            RA            regarded as abbreviations   \n",
       "9                           RSP    randomized survival probabilities   \n",
       "10                           TC                        Time-Constant   \n",
       "\n",
       "    usage_count  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "5             1  \n",
       "6             1  \n",
       "7             1  \n",
       "8             1  \n",
       "9             1  \n",
       "10            1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normtext = normalize_latex_math(example_text)\n",
    "print(normtext)\n",
    "extract_abbreviations(normtext, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31680e4-6079-42ef-ba55-7e9f7b28db00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Streamlit Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a40588-829c-43dc-ad4a-12e3530de652",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "st.set_page_config(layout=\"wide\") # Original layout setting\n",
    "st.title(r\"Extracting Abbreviations from $\\LaTeX$ Text\") # Original title\n",
    "\n",
    "# --- Initialize Session State ---\n",
    "# Use '_df' suffix for the variable storing the DataFrame result\n",
    "if 'abbreviations_df' not in st.session_state:\n",
    "    st.session_state.abbreviations_df = None\n",
    "if 'last_input_text' not in st.session_state:\n",
    "    st.session_state.last_input_text = example_text\n",
    "if 'processed_url_param' not in st.session_state:\n",
    "    st.session_state.processed_url_param = False\n",
    "\n",
    "# --- Handle URL Query Parameter (Logic remains the same, but uses _df variable) ---\n",
    "url_text_param = st.query_params.get(\"text\", None)\n",
    "\n",
    "if url_text_param and not st.session_state.processed_url_param:\n",
    "    print(f\"Processing text from URL parameter: {url_text_param[:50]}...\") # Debug print\n",
    "    st.session_state.last_input_text = url_text_param # Pre-fill text area state\n",
    "    try:\n",
    "        with st.spinner(\"Processing text from URL...\"):\n",
    "            normalized_text = normalize_latex_math(url_text_param)\n",
    "            # Store the DataFrame result\n",
    "            st.session_state.abbreviations_df = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "            st.session_state.processed_url_param = True # Mark as processed\n",
    "            # Consider uncommenting rerun if updates aren't immediate enough\n",
    "            # st.rerun()\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error processing text from URL: {e}\")\n",
    "        st.session_state.abbreviations_df = None # Clear result on error\n",
    "        st.session_state.processed_url_param = True # Mark as processed even if error\n",
    "elif not url_text_param:\n",
    "     st.session_state.processed_url_param = False\n",
    "\n",
    "# --- Create two main columns for side-by-side layout (Original Ratio) ---\n",
    "col_input, col_output = st.columns([3, 1]) # Original 3:1 ratio\n",
    "\n",
    "# --- Column 1: Input Area (Original Structure) ---\n",
    "with col_input:\n",
    "    st.subheader(\"Paste Your text\") # Original subheader\n",
    "    input_text = st.text_area(\n",
    "        label=\"input_text_main\",\n",
    "        label_visibility=\"collapsed\", # Original setting\n",
    "        value=st.session_state.last_input_text,\n",
    "        height=350,  # Original height\n",
    "        placeholder=\"Paste your text here...\",\n",
    "        key=\"input_text_area\"\n",
    "    )\n",
    "    st.caption(\"Privacy: this app does not save your text.\") # Original caption\n",
    "\n",
    "    # Update session state if text changes (useful for comparison)\n",
    "    if input_text != st.session_state.last_input_text:\n",
    "        st.session_state.last_input_text = input_text\n",
    "        # Optional: Clear results when text changes?\n",
    "        # st.session_state.abbreviations_df = None\n",
    "\n",
    "# --- Column 2: Controls and Output Display (Original Structure) ---\n",
    "with col_output:\n",
    "    # Original button label and settings\n",
    "    extract_pressed = st.button(\"Extract Abbreviations with Regex\", type=\"primary\", use_container_width=True)\n",
    "\n",
    "    # --- Processing Logic (Triggered by button press) ---\n",
    "    # Corrected: Process only when button is pressed\n",
    "    if extract_pressed:\n",
    "        if input_text:\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                try:\n",
    "                    normalized_text = normalize_latex_math(input_text)\n",
    "                    # Store the DataFrame result (which includes 'Row No.')\n",
    "                    st.session_state.abbreviations_df = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "                except Exception as e:\n",
    "                    st.error(f\"An error occurred during extraction: {e}\")\n",
    "                    st.session_state.abbreviations_df = None # Clear result on error\n",
    "        else:\n",
    "            # Original warning message\n",
    "            st.warning(\"Please enter some text in the input box above.\")\n",
    "            st.session_state.abbreviations_df = None # Clear result if no input\n",
    "\n",
    "\n",
    "    # --- Display Results Table ---\n",
    "    output_placeholder = \"Output will appear here after clicking 'Extract Abbreviations'.\" # Original placeholder\n",
    "    df_display = st.session_state.get('abbreviations_df', None) # Safely get the DataFrame\n",
    "\n",
    "    # Use container with original height, no border\n",
    "    with st.container(height=350, border=False): # Original height, border setting\n",
    "        if df_display is not None and not df_display.empty:\n",
    "            # --- MODIFICATION STARTS HERE ---\n",
    "            # Rename columns including the new 'Row No.' for display\n",
    "            df_display_renamed = df_display.rename(columns={\n",
    "                'Row No.': 'No.', # Rename for display\n",
    "                'abbreviation': 'Abbreviation',\n",
    "                'full_name': 'Full Phrase',\n",
    "                'usage_count': 'Usage'\n",
    "            })\n",
    "            # Select columns to display, including the new 'No.' column first\n",
    "            display_columns = ['No.', 'Abbreviation', 'Full Phrase', 'Usage']\n",
    "            # --- END MODIFICATION ---\n",
    "\n",
    "            # Generate markdown table from the selected & renamed columns\n",
    "            # index=False prevents pandas default index from showing (we use our 'No.' column)\n",
    "            markdown_table = df_display_renamed[display_columns].to_markdown(index=False)\n",
    "            st.markdown(markdown_table) # Display the table\n",
    "\n",
    "        elif df_display is not None and df_display.empty: # Explicitly handle empty DataFrame\n",
    "            # Use a message consistent with format_abbreviations output for empty results\n",
    "            st.info(\"No abbreviations found in the text.\")\n",
    "        # else: Display nothing or placeholder if df_display is None\n",
    "\n",
    "\n",
    "# --- Export Section (Original Structure) ---\n",
    "# Original column setup for export controls\n",
    "col_exp, _ = st.columns([1, 1])\n",
    "with col_exp:\n",
    "    st.subheader(\"Export\") # Original subheader\n",
    "    selected_format = st.selectbox(\n",
    "        label=\"Choose an exportting format:\", # Original label text\n",
    "        label_visibility=\"collapsed\",  # Original setting\n",
    "        options=['plain', 'tabular', 'nomenclature'],\n",
    "        index=0,  # Original default index (plain)\n",
    "        key='format_selector', # Original key\n",
    "        help=\"Select the format for the abbreviation list output.\" # Original help text\n",
    "    )\n",
    "\n",
    "    # --- Prepare and Display Formatted Output for Copying ---\n",
    "    formatted_output = \"\" # Default to empty string\n",
    "    df_export = st.session_state.get('abbreviations_df', None) # Safely get the DataFrame\n",
    "\n",
    "    if df_export is not None:\n",
    "        if df_export.empty:\n",
    "            formatted_output = \"No abbreviations found in the text.\"\n",
    "        else:\n",
    "            try:\n",
    "                # Pass the DataFrame (which might include 'Row No.') to the formatting function\n",
    "                # The format_abbreviations function should ideally ignore the 'Row No.' column if present\n",
    "                formatted_output = format_abbreviations(df_export, format_type=selected_format)\n",
    "            except Exception as format_e:\n",
    "                formatted_output = f\"Error formatting output: {format_e}\"\n",
    "                st.error(formatted_output) # Show error if formatting fails\n",
    "    # else: If df_export is None, formatted_output remains \"\" initially, or update message:\n",
    "    elif extract_pressed or url_text_param: # Only show if an attempt was made\n",
    "         formatted_output = \"Extract abbreviations first or check input/errors.\"\n",
    "\n",
    "\n",
    "    # Display the formatted output in the text area (Original settings)\n",
    "    st.text_area(\n",
    "        label=\"output_text_main\", # Original internal label\n",
    "        label_visibility=\"collapsed\", # Original setting\n",
    "        value=formatted_output, # Value is prepared above\n",
    "        height=150,  # Original height\n",
    "        help=\"Copy the output from this box.\", # Original help text\n",
    "        key=\"output_text_area\" # Original key\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Explanations Section (Original Structure) ---\n",
    "st.divider() # Original separator\n",
    "st.subheader(\"About the Algorithm\") # Original subheader\n",
    "\n",
    "# Define Content for Both Expanders (Keep existing text - updated slightly for accuracy)\n",
    "summary_expander_label = \" How Abbreviation Extraction Works (Summary)\"\n",
    "summary_explanation_text = \"\"\"\n",
    "This tool attempts to find abbreviations defined within parentheses, like `Full Definition (Abbr)`, even in text containing LaTeX formatting. Here's the basic process:\n",
    "\n",
    "1.  **Finding Candidates:** It scans the text using regular expressions to locate potential `Definition (Abbr)` patterns, focusing on words on the same line just before the parentheses.\n",
    "2.  **Parsing Abbreviation:** It breaks down the abbreviation (e.g., `GRs`, `\\\\gamma R`) into core components (like `g`, `r` or `\\\\gamma`, `r`), ignoring plural 's' after capitals.\n",
    "3.  **Matching Backwards:** It looks backward from the abbreviation's components through the preceding words/separators to find likely corresponding words (e.g., matching 'R' to 'Residuals'). It handles letters and LaTeX commands differently during matching.\n",
    "4.  **Reconstructing Definition:** If a consistent match is found, it rebuilds the definition phrase, preserving original spacing and hyphens.\n",
    "5.  **Validation:** A match is considered valid only if a high enough percentage (e.g., >= 70%) of the abbreviation's components were matched.\n",
    "6.  **Usage Count:** It counts how many times the validly defined abbreviation appears elsewhere in the text (outside its definition).\n",
    "7.  **Output:** Returns results (Abbreviation, Full Name, Count) as a DataFrame, sorted by count then abbreviation, including a row number.\n",
    "\n",
    "*(This process uses heuristics, especially for LaTeX, so results may vary.)*\n",
    "\"\"\"\n",
    "\n",
    "detailed_expander_label = \" Detailed Algorithm Explanation\"\n",
    "detailed_description_text = \"\"\"\n",
    "This algorithm identifies abbreviations defined as `Full Definition Phrase (Abbr)` within text, including LaTeX, extracts the phrase, and counts usage.\n",
    "\n",
    "**Core Steps:**\n",
    "\n",
    "1.  **Optional Preprocessing (`normalize_latex_math`):** Standardizes LaTeX comments, math delimiters (`\\\\(...\\\\)` to `\\$...\\$`), spacing around braces/commands.\n",
    "2.  **Candidate Identification (Regex):** Finds `Definition (Abbr)` patterns. Captures preceding words (Group 1, same line only) and the abbreviation (Group 2).\n",
    "3.  **Usage Counting:** Counts occurrences of each *potential* abbreviation string (from Group 2) elsewhere in the text using a separate regex pattern designed to match the abbreviation as a standalone unit. Stores these counts.\n",
    "4.  **Abbreviation Parsing (`get_letters_abbrs`):** Creates two lists from the abbreviation: one with single comparable letters, one with the original segments.\n",
    "5.  **Preceding Text Tokenization (Split):** Splits preceding words into `words_ahead` using `re.split(r'([ -]+)', ...)`, retaining spaces/hyphens as separate tokens.\n",
    "6.  **Word Analysis (`get_letters_words`):** Pre-calculates a list (`words_ahead_letters`) containing the single comparable letter for each token in `words_ahead`.\n",
    "7.  **Backward Matching (`find_abbreviation_matches`):** Matches `abbr_items` (letters) to `words_ahead_letters` tokens in reverse, respecting sequence and using state (`last_matched_index`) to constrain search. Returns two lists mapping word index to the matched original abbreviation part (`matched_abbrs_string`) and the matched abbreviation letter (`matched_abbrs_letters`).\n",
    "8.  **Validation:** Calculates the ratio of successfully matched items (`sum(1 for letter in matched_abbrs_letters if letter) / len(abbr_items)`). Considers the definition valid if this ratio meets/exceeds `match_threshold`.\n",
    "9.  **Phrase Reconstruction:** If valid, finds the min/max indices of matched words (from non-empty entries in `matched_abbrs_letters`), slices `words_ahead`, and reconstructs `full_name`.\n",
    "10. **Output Aggregation:** Stores valid `abbr_string` (original abbreviation), reconstructed `full_name`, and pre-calculated `usage_count` in a dictionary.\n",
    "11. **Final DataFrame Creation & Sorting:** Converts the final dictionary into a Pandas DataFrame, sorts it by usage count (desc) then abbreviation (asc), adds a 1-based 'Row No.' column, and returns it.\n",
    "\"\"\"\n",
    "\n",
    "# Create Columns and Display Expanders (Original column setup)\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    with st.expander(summary_expander_label):\n",
    "        st.markdown(summary_explanation_text)\n",
    "with col2:\n",
    "    with st.expander(detailed_expander_label):\n",
    "        st.markdown(detailed_description_text)\n",
    "\n",
    "\n",
    "# --- Footer (Original Structure) ---\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Author: Longhai Li, https://longhaisk.github.io, Saskatoon, SK, Canada\")\n",
    "# Original commented out date logic"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-remove",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
