{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39abbab8-5e18-4341-9e4d-2f93eb23070a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Converting .py and .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76551262",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "streamlit",
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate_abbrev.ipynb to script\n",
      "[NbConvertApp] Writing 28814 bytes to generate_abbrev.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('jupyter nbconvert --to script generate_abbrev.ipynb --TagRemovePreprocessor.remove_cell_tags=\"remove\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8692cd6-6cb5-4dc5-997f-0233184e3662",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate_abbrev.py to notebook\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbformat/reader.py\", line 19, in parse_json\n",
      "    nb_dict = json.loads(s, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/bin/jupyter-nbconvert\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/jupyter_core/application.py\", line 283, in launch_instance\n",
      "    super().launch_instance(argv=argv, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 420, in start\n",
      "    self.convert_notebooks()\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 597, in convert_notebooks\n",
      "    self.convert_single_notebook(notebook_filename)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 563, in convert_single_notebook\n",
      "    output, resources = self.export_single_notebook(\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 487, in export_single_notebook\n",
      "    output, resources = self.exporter.from_filename(\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/exporters/exporter.py\", line 201, in from_filename\n",
      "    return self.from_file(f, resources=resources, **kw)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbconvert/exporters/exporter.py\", line 221, in from_file\n",
      "    nbformat.read(file_stream, as_version=4), resources=resources, **kw\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbformat/__init__.py\", line 174, in read\n",
      "    return reads(buf, as_version, capture_validation_error, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbformat/__init__.py\", line 92, in reads\n",
      "    nb = reader.reads(s, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbformat/reader.py\", line 75, in reads\n",
      "    nb_dict = parse_json(s, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/jupyter-2025/lib/python3.10/site-packages/nbformat/reader.py\", line 25, in parse_json\n",
      "    raise NotJSONError(message) from e\n",
      "nbformat.reader.NotJSONError: Notebook does not appear to be JSON: '#!/usr/bin/env python\\n# coding: utf-8\\...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.system(\"jupyter nbconvert --to notebook generate_abbrev.py --output generate_abbrev.ipynb2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c63296-15ce-4ee3-b2d7-0daf6b159243",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6ad76cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import re\n",
    "from datetime import datetime\n",
    "from extract_abbrev_regex import *\n",
    "import socket\n",
    "import pandas as pd\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "DEBUG = \"streamlit\" not in hostname.lower()  # Assume cloud has \"streamlit\" in hostname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7fe80-d0fb-47d6-9c79-b559e0c3b057",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# normalizing and extracting abbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e52da80",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Functions for normalizing and extracting abbrs\n",
    "\n",
    "# Code block prepared on Thursday, April 3, 2025 at 12:38:43 AM CST in Saskatoon, Saskatchewan, Canada.\n",
    "# Optional import for error display if using Streamlit\n",
    "# try:\n",
    "#     import streamlit as st\n",
    "# except ImportError:\n",
    "#     st = None # Define st as None if not available\n",
    "\n",
    "# This list is used by normalize_latex_math\n",
    "upper_greek_cmds = [\n",
    "    'Gamma', 'Delta', 'Theta', 'Lambda', 'Xi', 'Pi',\n",
    "    'Sigma', 'Upsilon', 'Phi', 'Psi', 'Omega'\n",
    "]\n",
    "\n",
    "#Here's a summary of the functions:\n",
    "\n",
    "# normalize_dollar_spacing(text) (from artifact normalize_dollar_spacing_code)\n",
    "\n",
    "# Purpose: This function cleans up LaTeX text strings. Specifically, it looks for the dollar signs ($) used for inline math. It removes any extra whitespace found immediately after an opening $ and immediately before a closing $. This helps standardize the formatting around inline math expressions.\n",
    "\n",
    "# render_dataframe_with_latex(df) (from artifact render_df_latex_code)\n",
    "\n",
    "# Purpose: This function takes a data table (specifically, a Pandas DataFrame) that contains text with LaTeX math code in its cells. It converts this table into HTML format. Importantly, it also includes the necessary setup for the MathJax library within that HTML. The result is an HTML object that, when displayed in a compatible environment (like a Jupyter notebook or a web browser), will show the table with the LaTeX code rendered as proper mathematical symbols and equations, rather than just the raw code.\n",
    "\n",
    "# In short, one function cleans up spacing around LaTeX math delimiters in text, and the other helps display a data table containing LaTeX math correctly rendered in environments that support HTML and JavaScript.\n",
    "\n",
    "\n",
    "\n",
    "def normalize_dollar_spacing(text):\n",
    "    \"\"\"\n",
    "    Removes whitespace immediately following an opening inline math '$' AND\n",
    "    whitespace immediately preceding a closing inline math '$'.\n",
    "    Handles escaped '\\$'.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string potentially containing LaTeX.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed string.\n",
    "    \"\"\"\n",
    "    processed_chars = []\n",
    "    in_math_mode = False\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while i < n:\n",
    "        char = text[i]\n",
    "\n",
    "        # Check for escaped dollar sign or backslash first\n",
    "        if char == '\\\\' and i + 1 < n:\n",
    "            # Keep backslash and the next character (e.g., '\\$' or '\\\\')\n",
    "            processed_chars.append(char)\n",
    "            processed_chars.append(text[i+1])\n",
    "            i += 2 # Skip both characters\n",
    "            continue\n",
    "\n",
    "        # Check for unescaped dollar sign\n",
    "        if char == '$':\n",
    "            if not in_math_mode:\n",
    "                # --- This is an OPENING dollar sign ---\n",
    "                processed_chars.append(char) # Keep the opening dollar\n",
    "                in_math_mode = True\n",
    "                # Check if the next characters are whitespace and skip them\n",
    "                j = i + 1\n",
    "                while j < n and text[j].isspace():\n",
    "                    j += 1\n",
    "                # Advance 'i' past the dollar and the skipped whitespace\n",
    "                i = j\n",
    "                continue # Continue to next iteration\n",
    "            else:\n",
    "                # --- This is a CLOSING dollar sign ---\n",
    "                in_math_mode = False\n",
    "                # Remove any trailing whitespace added just before this closing '$'\n",
    "                while processed_chars and processed_chars[-1].isspace():\n",
    "                    processed_chars.pop()\n",
    "                processed_chars.append(char) # Append the closing dollar\n",
    "                # Advance 'i' past the dollar for the next iteration\n",
    "                i += 1\n",
    "                continue # Continue to next iteration\n",
    "        else:\n",
    "            # Any other character\n",
    "            processed_chars.append(char)\n",
    "            i += 1 # Advance 'i' past the character\n",
    "\n",
    "    return \"\".join(processed_chars)\n",
    "\n",
    "# --- Normalization Function ---\n",
    "def normalize_latex_math(text):\n",
    "    \"\"\"\n",
    "    Preprocesses LaTeX text:\n",
    "    1. Converts LaTeX inline math \\( ... \\) to $ ... $.\n",
    "    2. Removes LaTeX comments (% to end of line), respecting \\%.\n",
    "    3. Removes preamble/end tags if \\begin{document} is found.\n",
    "    4a. Adds space BEFORE and AFTER opening curly braces ({).\n",
    "    4b. Adds space BEFORE and AFTER closing curly braces (}).\n",
    "    5. Adds space after specific uppercase Greek commands (\\Cmd) if not present. (Note: Using corrected pattern)\n",
    "    6. Adds space after lowercase LaTeX commands (\\cmd) if not already present. (Note: Pattern may be restrictive)\n",
    "    7. Removes whitespace immediately following $. (Moved Step)\n",
    "    8. Cleans up extra blank lines and trims whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        print(\"Warning: Input to normalize_latex_math was not a string.\")\n",
    "        return text\n",
    "\n",
    "    processed_text = text\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        # 0. Remove space inside $ $\n",
    "        processed_text =  normalize_dollar_spacing(processed_text)\n",
    "\n",
    "        # 1. Normalize math \\(...\\) to $...$\n",
    "        processed_text = re.sub(\n",
    "            r'\\\\\\(\\s*(.*?)\\s*\\\\\\)',\n",
    "            lambda match: f\"${match.group(1).strip()}$\",\n",
    "            processed_text\n",
    "        )\n",
    "\n",
    "        # 2. Remove LaTeX comment lines (respects \\%)\n",
    "        processed_text = re.sub(r'(?<!\\\\)%.*$', '', processed_text, flags=re.MULTILINE)\n",
    "\n",
    "        # 3. Remove preamble IF \\begin{document} exists\n",
    "        begin_doc_marker = r'\\begin{document}'\n",
    "        begin_doc_index = processed_text.find(begin_doc_marker)\n",
    "        if begin_doc_index != -1:\n",
    "            processed_text = processed_text[begin_doc_index + len(begin_doc_marker):]\n",
    "        # 3b. Remove \\end{document} if present near the end\n",
    "        end_doc_marker = r'\\end{document}'\n",
    "        end_doc_index = processed_text.rfind(end_doc_marker)\n",
    "        if end_doc_index != -1 and len(processed_text) - end_doc_index < 30: # Heuristic check\n",
    "            processed_text = processed_text[:end_doc_index]\n",
    "\n",
    "        # --- Spacing Adjustments ---\n",
    "        # 4a. Add space BEFORE and AFTER { (handles existing spaces robustly)\n",
    "        processed_text = re.sub(r'\\s*\\{\\s*', r' { ', processed_text)\n",
    "        # 4b. Add space BEFORE and AFTER } (handles existing spaces robustly)\n",
    "        processed_text = re.sub(r'\\s*\\}\\s*', r' } ', processed_text)\n",
    "        # 4c. Add space BEFORE ( (handles no space before ()\n",
    "        processed_text = re.sub(r'\\s*\\(', r' (', processed_text)\n",
    "        \n",
    "        # 5. Add space after specific uppercase Greek commands (\\Cmd) if not followed by space\n",
    "        pattern_part = '|'.join(upper_greek_cmds)\n",
    "        # Using corrected pattern (no space after \\\\)\n",
    "        pattern_upper = rf'(\\\\({pattern_part}))(?!\\s)'\n",
    "        processed_text = re.sub(pattern_upper, r'\\1 ', processed_text)\n",
    "\n",
    "        # 6. Add space after lowercase commands (\\cmd) if not followed by specific pattern\n",
    "        # !!! Note: This pattern (?=[A-Z][^a-z]) might be too restrictive.\n",
    "        processed_text = re.sub(r'(\\\\[a-z]+)(?=[A-Z][^a-z])', r'\\1 ', processed_text)\n",
    "\n",
    "\t\t# 7. Remove one or more whitespace characters (\\s+) immediately after a dollar sign ($) (Moved Step)\n",
    "        #processed_text = re.sub(r'\\$\\s+', '$', processed_text)\n",
    "\n",
    "        # 8. Clean up potential excessive blank lines and trim overall whitespace\n",
    "        processed_text = re.sub(r'(\\n\\s*){2,}', '\\n', processed_text) # Collapse blank lines\n",
    "        processed_text = re.sub(r'\\s+', ' ', processed_text) # Collapse blank lines\n",
    "        \n",
    "\n",
    "        return processed_text\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during LaTeX text preprocessing: {e}\"\n",
    "        try:\n",
    "            # Attempt to use streamlit for error display if available\n",
    "            import streamlit as st\n",
    "            st.error(error_message)\n",
    "        except ImportError:\n",
    "            # Fallback to print if streamlit is not available\n",
    "            print(error_message)\n",
    "        return text # Return original text on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7d54500",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## convert the abbreviation into a lower case letter for comparison\n",
    "\n",
    "def get_abbr_repr_items(abbr_string):\n",
    "    \"\"\"\n",
    "    Parses abbreviation string, returns list of representative items WITHOUT Greek mapping.\n",
    "    - Keeps ALL LaTeX commands (like \\frac, \\gamma) as strings.\n",
    "    - Takes the uppercase letter from sequences like 'Cp' or 'CPs', ignoring trailing lowercase.\n",
    "    - Includes standalone lowercase letters.\n",
    "    \"\"\"\n",
    "    representative_items = []\n",
    "    # Regex captures: \\cmd | Upper | OptionalLowerSuffix | StandaloneLower\n",
    "    findings = re.findall(r'(\\\\[a-zA-Z]+)|([A-Z])([a-z]+)?|([a-z])', abbr_string)\n",
    "\n",
    "    # The tuple returned by findall will have 4 elements corresponding to the groups\n",
    "    for command, upper, trailing_lower, standalone_lower in findings:\n",
    "        if command:  # Group 1: \\command\n",
    "            # Keep the original command string (no mapping)\n",
    "            representative_items.append(command)\n",
    "        elif upper:  # Group 2: An uppercase letter was found\n",
    "            # Use the uppercase letter, ignore trailing lowercase (group 3)\n",
    "            representative_items.append(upper.lower())\n",
    "        elif standalone_lower: # Group 4: A standalone lowercase letter\n",
    "            representative_items.append(standalone_lower)\n",
    "    return representative_items\n",
    "\n",
    "## capturing the first letter of the words for comparison\n",
    "def get_effective_char(word: str, debug: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Tries to derive the effective matching character from a LaTeX-style word\n",
    "    by stripping common leading markup and finding the first letter.\n",
    "    \"\"\"\n",
    "    original = word\n",
    "    word_to_check = word\n",
    "    try:\n",
    "        # Heuristically strip leading commands/braces to find the first actual letter.\n",
    "        m1 = re.match(r'^\\s*\\\\[a-zA-Z]+\\s*\\{(.*)', word_to_check)\n",
    "        if m1:\n",
    "            word_to_check = m1.group(1)\n",
    "            # Removed internal debug print for brevity in final code\n",
    "        else:\n",
    "            m2 = re.match(r'^\\s*\\{\\s*\\\\[a-zA-Z]+\\s+(.*)', word_to_check)\n",
    "            if m2:\n",
    "                content = m2.group(1)\n",
    "                if content.endswith('}'): content = content[:-1].rstrip()\n",
    "                word_to_check = content\n",
    "            else:\n",
    "                m3 = re.match(r'^\\s*\\\\[a-zA-Z]+(\\s+.*)', word_to_check)\n",
    "                if m3:\n",
    "                     if m3.group(1) and m3.group(1).strip():\n",
    "                         word_to_check = m3.group(1).lstrip()\n",
    "\n",
    "        if word_to_check.startswith('{'):\n",
    "            word_to_check = word_to_check[1:].lstrip()\n",
    "\n",
    "        match = re.search(r'[a-zA-Z]', word_to_check)\n",
    "        if match:\n",
    "             return match.group(0).lower()\n",
    "\n",
    "        if word_to_check is not original:\n",
    "             match_orig = re.search(r'[a-zA-Z]', original)\n",
    "             if match_orig:\n",
    "                  return match_orig.group(0).lower()\n",
    "\n",
    "        return ''\n",
    "\n",
    "    except Exception as e:\n",
    "        # Keep error print if helper function itself fails when its debug is on\n",
    "        if debug: print(f\"      Error in get_effective_char for '{original}': {e}\")\n",
    "        match = re.search(r'[a-zA-Z]', original)\n",
    "        return match.group(0).lower() if match else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a21706-10b7-4f2a-a417-e33d95a1f534",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Finding Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "de19eba7-9104-44a1-9941-9e0a92f4951f",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding Matching\n",
    "def find_abbreviation_matches(words_ahead, abbr_items, debug=True):\n",
    "    \"\"\"\n",
    "    Performs backward matching between definition words (words_ahead) and\n",
    "    abbreviation items (abbr_items). Uses V3 comparison logic.\n",
    "    If debug=True, prints cumulative matching DataFrame (requires pandas\n",
    "    to be imported globally as pd) and final indices map.\n",
    "    NOTE: Enabling debug=True can significantly slow down execution due to\n",
    "          DataFrame creation/printing in the loop.\n",
    "\n",
    "    Args:\n",
    "        words_ahead (list): List of word tokens from the definition part.\n",
    "        abbr_items (list): List of representative items from the abbreviation part.\n",
    "        debug (bool): Flag to enable cumulative DataFrame printing.\n",
    "\n",
    "    Returns:\n",
    "        list: A list where index `i` contains the index from `words_ahead`\n",
    "              that matches `abbr_items[i]`, or -1 if no match was found.\n",
    "    \"\"\"\n",
    "    num_abbr_items = len(abbr_items)\n",
    "    num_words = len(words_ahead)\n",
    "    match_indices = [-1] * num_abbr_items\n",
    "\n",
    "    # Initialize structures for pandas debug output if needed\n",
    "    words_line = words_ahead[:]\n",
    "    abbr_line = [''] * num_words\n",
    "\n",
    "    last_matched_index = num_words\n",
    "\n",
    "    # Outer loop iterates through Abbr Items in reverse\n",
    "    for abbr_idx in range(num_abbr_items - 1, -1, -1):\n",
    "        target_abbr = abbr_items[abbr_idx]\n",
    "        match_found_for_abbr = False # Renamed for clarity\n",
    "\n",
    "        # Inner loop iterates through Words in reverse\n",
    "        for i in range(last_matched_index - 1, -1, -1):\n",
    "            word = words_ahead[i]\n",
    "            # Call helper with debug=False unless you want its prints too\n",
    "            effective_char = get_effective_char(word, debug=False)\n",
    "\n",
    "            current_match_found = False\n",
    "            # --- V3 COMPARISON LOGIC ---\n",
    "            if target_abbr.startswith('\\\\'):\n",
    "                word_to_compare = word\n",
    "                if word_to_compare.startswith('$'):\n",
    "                    word_to_compare = word_to_compare[1:]\n",
    "                if word_to_compare.startswith(target_abbr):\n",
    "                    current_match_found = True\n",
    "            elif effective_char:\n",
    "                if effective_char == target_abbr:\n",
    "                    current_match_found = True\n",
    "            # --- END V3 COMPARISON LOGIC ---\n",
    "\n",
    "            if current_match_found:\n",
    "                match_indices[abbr_idx] = i\n",
    "                abbr_line[i] = target_abbr # Update debug line\n",
    "                last_matched_index = i\n",
    "                match_found_for_abbr = True\n",
    "                break # Found match for this abbr_idx\n",
    "\n",
    "        # --- Cumulative Debug Output ---\n",
    "        # This block now assumes 'pd' is available if debug is True\n",
    "        if debug:\n",
    "             try:\n",
    "                 # Create DataFrame using the globally imported pd\n",
    "                 df_data = {'Words before': words_line, 'Abb matched': abbr_line}\n",
    "                 df = pd.DataFrame(df_data)\n",
    "                 print(f\"\\nMatching result after item '{target_abbr}' (abbr_idx {abbr_idx}):\")\n",
    "                 print(df.T.to_string())\n",
    "             except NameError: # Catch error if pd wasn't imported globally\n",
    "                 print(\"(NameError: 'pd' not defined. Cannot print DataFrame. \"\n",
    "                       \"Import pandas as pd globally for DataFrame debug output.)\")\n",
    "                 print(f\"Abb matched line state: {abbr_line}\") # Fallback\n",
    "             except Exception as df_err:\n",
    "                 print(f\"(Error creating/printing DataFrame: {df_err})\")\n",
    "                 print(f\"Abb matched line state: {abbr_line}\") # Fallback\n",
    "        # --- End Cumulative Debug Output ---\n",
    "\n",
    "    # --- Final Debug Output ---\n",
    "    if debug:\n",
    "        print(f\"\\nFinal Abbreviation Match Indices: {match_indices}\")\n",
    "    # --- End Final Debug Output ---\n",
    "\n",
    "    return match_indices\n",
    "\n",
    "\n",
    "# Assume find_abbreviation_matches, get_abbr_repr_items, and get_effective_char\n",
    "# are defined as previously provided.\n",
    "# Assume normalize_latex_math is also available if you use it beforehand.\n",
    "\n",
    "# --- Updated Extraction function with Threshold Validation & Reduced Debug ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367f8cf-8c51-4c60-ab48-f2d640963229",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_abbreviations(text, match_threshold=0.7, debug=True):\n",
    "    \"\"\"\n",
    "    Extracts abbreviations defined as (Abbr) following their definition.\n",
    "    Validates match if a certain threshold of abbreviation items are matched\n",
    "    to corresponding words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text potentially containing definitions.\n",
    "        match_threshold (float): The minimum fraction (e.g., 0.7 for 70%) of\n",
    "                                 abbreviation items that must be successfully\n",
    "                                 matched to words for the definition to be\n",
    "                                 considered valid.\n",
    "        debug (bool): Flag to enable extensive debug printing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping abbreviation strings to their extracted full definitions.\n",
    "    \"\"\"\n",
    "    # Main pattern (same as before - restricted to same line)\n",
    "    pattern = re.compile(\n",
    "        r'('                      # Start Group 1: Preceding words\n",
    "        r'(?:[\\w\\-\\$\\\\\\{\\}]+[ \\t]+){1,10}' # Words separated by space/tab on same line\n",
    "        r')'                      # End Group 1\n",
    "        r'\\(\\s*'                  # Literal opening parenthesis\n",
    "        r'('                      # Start Group 2: Abbreviation\n",
    "        r'(?=.*[A-Z\\\\\\$])'       # Positive lookahead\n",
    "        r'[\\w\\s\\$\\-\\\\\\{\\}]+'   # Allowed characters\n",
    "        r')'                      # End Group 2 capture\n",
    "        r'\\s*\\)'                  # Literal closing parenthesis\n",
    "    )\n",
    "    \n",
    "    #\n",
    "    pattern = r'((?:[\\w\\\\\\$\\{\\}]+[ -]+){1,10}(?:[\\w\\\\\\$\\{\\}]+)[ -]?)\\(([^\\(\\)]*[A-Z]+[^\\(\\)]*)\\)'\n",
    "    #matches = pattern.findall(text)\n",
    "    matches = re.findall(pattern, text)\n",
    "    abbreviation_dict = {}\n",
    "\n",
    "    # Get current time and location context for potential use\n",
    "    current_time_str = \"Thursday, April 3, 2025 at 5:42:20 PM CST\" # Replace with dynamic time if needed\n",
    "    current_location = \"Saskatoon, Saskatchewan, Canada\"\n",
    "\n",
    "    if debug: print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
    "    if debug: print(f\"(Context: {current_time_str}, {current_location})\")\n",
    "\n",
    "\n",
    "    for match in matches:\n",
    "        words_before_abbr_text = match[0].strip()\n",
    "        abbr_string = match[1].strip()\n",
    "        abbr_items = get_abbr_repr_items(abbr_string)\n",
    "\n",
    "        # Split preceding text using space/hyphen, retaining delimiters\n",
    "        words_ahead = [item for item in re.split(r'([ -]+)', words_before_abbr_text) if item]\n",
    "\n",
    "        if debug:\n",
    "            # Debug printing for candidate\n",
    "            print(f\"\\n---\\nCandidate Found:\")\n",
    "            print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
    "            print(f\"  Generated abbr_items: {abbr_items}\")\n",
    "            print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
    "            # --- BLOCK REMOVED ---\n",
    "            # print(f\"  Split words_ahead (elements - includes separators):\")\n",
    "            # if words_ahead:\n",
    "            #     for i, word in enumerate(words_ahead):\n",
    "            #         print(f\"    [{i}]: '{word}'\")\n",
    "            # else:\n",
    "            #     print(\"    (list is empty)\")\n",
    "            # --- END BLOCK REMOVED ---\n",
    "            # You could optionally print the whole list if needed, e.g.:\n",
    "            # print(f\"  Split words_ahead list: {words_ahead}\")\n",
    "\n",
    "\n",
    "        # Initial check: Need words and abbreviation items to proceed\n",
    "        if not words_ahead or not abbr_items:\n",
    "             if debug: print(f\"  Skipping: No words ahead ({bool(words_ahead)}) or no abbr items found ({bool(abbr_items)}).\")\n",
    "             continue\n",
    "\n",
    "        # Call the matching function (assuming it's defined)\n",
    "        # Ensure find_abbreviation_matches is defined elsewhere using the latest logic\n",
    "        match_indices = find_abbreviation_matches(words_ahead, abbr_items, debug)\n",
    "\n",
    "        # Post-match checks and reconstruction\n",
    "        successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
    "        count_matched = len(successful_match_indices)\n",
    "        num_abbr_items = len(abbr_items)\n",
    "\n",
    "        if debug:\n",
    "             # Keep these summary debug prints\n",
    "             print(f\"  Successful match indices for words: {successful_match_indices}\")\n",
    "             print(f\"  Final match_indices map (abbr_idx -> word_idx): {match_indices}\")\n",
    "             print(f\"  Items matched: {count_matched} out of {num_abbr_items}\")\n",
    "\n",
    "        # Validation Logic (using threshold)\n",
    "        valid_match = False\n",
    "        if num_abbr_items > 0:\n",
    "             ratio_matched = count_matched / num_abbr_items\n",
    "             if ratio_matched >= match_threshold:\n",
    "                 valid_match = True\n",
    "             elif debug:\n",
    "                 print(f\"  Validation Failed: Match ratio {ratio_matched:.2f} \"\n",
    "                       f\"is less than threshold {match_threshold:.2f}\")\n",
    "        elif debug:\n",
    "             print(\"  Validation Failed: No abbreviation items were generated.\")\n",
    "\n",
    "        # Reconstruction Logic\n",
    "        if valid_match:\n",
    "            if not successful_match_indices:\n",
    "                 if debug: print(\"  Skipping: Match deemed valid by ratio, but no word indices found?\")\n",
    "                 continue\n",
    "\n",
    "            min_idx_py = min(successful_match_indices)\n",
    "            max_idx_py = max(successful_match_indices)\n",
    "\n",
    "            if min_idx_py <= max_idx_py:\n",
    "                full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
    "                full_name = ''.join(full_phrase_words_slice)\n",
    "\n",
    "                if debug: print(f\"  Validation Passed (Ratio >= {match_threshold:.2f}). Storing: '{abbr_string}': '{full_name}'\")\n",
    "                abbreviation_dict[abbr_string] = full_name\n",
    "            elif debug: print(f\"  Skipping: min_idx ({min_idx_py}) > max_idx ({max_idx_py}) issue.\")\n",
    "\n",
    "\n",
    "    if debug: print(f\"--- Debugging End ---\\nFinal Dict: {abbreviation_dict}\")\n",
    "    return abbreviation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ae5f67b6-a38d-4ad5-a0fb-f07d4c3bff33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "# new extract_abbreviations\n",
    "def extract_abbreviations(text, match_threshold=0.7, debug=True):\n",
    "    \"\"\"\n",
    "    Extracts abbreviations defined as (Abbr) following their definition.\n",
    "    Validates match if a certain threshold of abbreviation items are matched\n",
    "    to corresponding words.  Also filters abbreviations to include only those\n",
    "    that appear at least twice in the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text potentially containing definitions.\n",
    "        match_threshold (float): The minimum fraction (e.g., 0.7 for 70%) of\n",
    "                                abbreviation items that must be successfully\n",
    "                                matched to words for the definition to be\n",
    "                                considered valid.\n",
    "        debug (bool): Flag to enable extensive debug printing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping abbreviation strings to their extracted full definitions,\n",
    "              and their usage counts.\n",
    "    \"\"\"\n",
    "    # Main pattern (same as before - restricted to same line)\n",
    "    # pattern = re.compile(\n",
    "    #     r'('  # Start Group 1: Preceding words\n",
    "    #     r'(?:[\\w\\-\\$\\\\\\{\\}]+[ \\t]+){1,10}'  # Words separated by space/tab on same line\n",
    "    #     r')'  # End Group 1\n",
    "    #     r'\\(\\s*'  # Literal opening parenthesis\n",
    "    #     r'('  # Start Group 2: Abbreviation\n",
    "    #     r'(?=.*[A-Z\\\\\\$])'  # Positive lookahead\n",
    "    #     r'[\\w\\s\\$\\-\\\\\\{\\}]+'  # Allowed characters\n",
    "    #     r')'  # End Group 2 capture\n",
    "    #     r'\\s*\\)'  # Literal closing parenthesis\n",
    "    # )\n",
    "\n",
    "    #\n",
    "    pattern = r'((?:[\\w\\\\\\$\\{\\}]+[ -]+){1,10}(?:[\\w\\\\\\$\\{\\}]+)[ -]?)\\(([^\\(\\)]*[a-zA-Z0-9]{2,}[^\\(\\)]*)\\)'\n",
    "    # matches = pattern.findall(text)\n",
    "    matches = re.findall(pattern, text)\n",
    "    abbreviation_dict = {}\n",
    "    abbr_usage_count = {}\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
    "        \n",
    "\n",
    "    # --- NEW FEATURE: Count Abbreviation Usages ---\n",
    "    for abbr_def_match in matches:  # Iterate through the definitions found earlier\n",
    "        abbr = abbr_def_match[1]  # Extract the abbreviation string from the definition match.\n",
    "        # remove parenthesis and special characters\n",
    "        abbr_search_string = re.sub(r'[\\(\\)]', '', abbr)\n",
    "        #abbr_search_string = re.sub(r'[^a-zA-Z0-9\\$\\^\\_\\\\]', '', abbr_search_string)\n",
    "        abbr_usage_pattern = rf'(?<![a-zA-Z\\(\\)]){re.escape(abbr_search_string)}(?![a-zA-Z\\)\\)])'\n",
    "        abbr_usage_count[abbr] = len(re.findall(abbr_usage_pattern, text))  # Count occurrences\n",
    "    if debug:\n",
    "        print(f\"  Abbreviation Usage Counts: {abbr_usage_count}\")\n",
    "    # --- END NEW FEATURE ---\n",
    "\n",
    "    for match in matches:\n",
    "        words_before_abbr_text = match[0].strip()\n",
    "        abbr_string = match[1].strip()\n",
    "        abbr_items = get_abbr_repr_items(abbr_string)\n",
    "\n",
    "        # Split preceding text using space/hyphen, retaining delimiters\n",
    "        words_ahead = [item for item in re.split(r'([ -]+)', words_before_abbr_text) if item]\n",
    "\n",
    "        if debug:\n",
    "            # Debug printing for candidate\n",
    "            print(f\"\\n---\\nCandidate Found:\")\n",
    "            print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
    "            print(f\"  Generated abbr_items: {abbr_items}\")\n",
    "            print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
    "\n",
    "        # Initial check: Need words and abbreviation items to proceed\n",
    "        if not words_ahead or not abbr_items:\n",
    "            if debug:\n",
    "                print(\n",
    "                    f\"  Skipping: No words ahead ({bool(words_ahead)}) or no abbr items found ({bool(abbr_items)}).\"\n",
    "                )\n",
    "            continue\n",
    "\n",
    "        # Call the matching function (assuming it's defined)\n",
    "        # Ensure find_abbreviation_matches is defined elsewhere using the latest logic\n",
    "        match_indices = find_abbreviation_matches(words_ahead, abbr_items, debug)\n",
    "\n",
    "        # Post-match checks and reconstruction\n",
    "        successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
    "        count_matched = len(successful_match_indices)\n",
    "        num_abbr_items = len(abbr_items)\n",
    "\n",
    "        if debug:\n",
    "            # Keep these summary debug prints\n",
    "            print(f\"  Successful match indices for words: {successful_match_indices}\")\n",
    "            print(f\"  Final match_indices map (abbr_idx -> word_idx): {match_indices}\")\n",
    "            print(f\"  Items matched: {count_matched} out of {num_abbr_items}\")\n",
    "\n",
    "        # Validation Logic (using threshold)\n",
    "        valid_match = False\n",
    "        if num_abbr_items > 0:\n",
    "            ratio_matched = count_matched / num_abbr_items\n",
    "            if ratio_matched >= match_threshold:\n",
    "                valid_match = True\n",
    "            elif debug:\n",
    "                print(f\"  Validation Failed: Match ratio {ratio_matched:.2f} \"\n",
    "                      f\"is less than threshold {match_threshold:.2f}\")\n",
    "        elif debug:\n",
    "            print(\"  Validation Failed: No abbreviation items were generated.\")\n",
    "\n",
    "        # Reconstruction Logic\n",
    "        if valid_match:\n",
    "            if not successful_match_indices:\n",
    "                if debug:\n",
    "                    print(\"  Skipping: Match deemed valid by ratio, but no word indices found?\")\n",
    "                continue\n",
    "\n",
    "            min_idx_py = min(successful_match_indices)\n",
    "            max_idx_py = max(successful_match_indices)\n",
    "\n",
    "            if min_idx_py <= max_idx_py:\n",
    "                full_phrase_words_slice = words_ahead[min_idx_py: max_idx_py + 1]\n",
    "                full_name = ''.join(full_phrase_words_slice)\n",
    "\n",
    "                # --- NEW FEATURE: Check Usage Count ---\n",
    "            if debug:\n",
    "                print(\n",
    "                    f\" Storing: '{abbr_string}': '{full_name}'\")\n",
    "            \n",
    "            abbreviation_dict[abbr_string] = {\n",
    "                'full_name': full_name,\n",
    "                'usage_count': abbr_usage_count[abbr_string]\n",
    "            }\n",
    "\n",
    "    if debug:\n",
    "        print(\"--- Debugging End ---\\nFinal Dict: {abbreviation_dict}\")\n",
    "\n",
    "    # --- ADD SORTING STEP HERE ---\n",
    "    try:\n",
    "        # Sort the dictionary items alphabetically based on the abbreviation (item[0])\n",
    "        sorted_items = sorted(\n",
    "            abbreviation_dict.items(),\n",
    "            key=lambda item: get_sort_key_from_abbr(item[0])\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Error handling for sorting, fallback to unsorted\n",
    "        sorted_items = abbreviation_dict.items()\n",
    "    # --- END SORTING STEP ---\n",
    "    \n",
    "        \n",
    "    return sorted_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598d4f-64fc-4a0c-b19b-329e0fba2700",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Extracting Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b64854-efc0-4093-8117-9954c2ccbb38",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_abbreviations(text, match_threshold=0.7, debug=True):\n",
    "    \"\"\"\n",
    "    Extracts abbreviations defined as (Abbr) following their definition.\n",
    "    Validates match, includes usage counts.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "        match_threshold (float): Minimum match ratio for validation.\n",
    "        debug (bool): Enable debug prints.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'abbreviation', 'full_name', 'usage_count',\n",
    "                      sorted primarily by 'usage_count' (descending),\n",
    "                      then by 'abbreviation' (ascending).\n",
    "                      Returns an empty DataFrame if no valid abbreviations found.\n",
    "    \"\"\"\n",
    "    pattern = r'((?:[\\w\\\\\\$\\{\\}]+[ -]+){1,10}(?:[\\w\\\\\\$\\{\\}]+)[ -]?)\\(([^\\(\\)]*[a-zA-Z0-9]{2,}[^\\(\\)]*)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    abbreviation_dict = {}\n",
    "    abbr_usage_count = {}\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
    "\n",
    "    # --- Count Abbreviation Usages ---\n",
    "    all_potential_abbrs = [match[1].strip() for match in matches]\n",
    "    for abbr in set(all_potential_abbrs):\n",
    "        abbr_search_string = re.sub(r'[\\(\\)]', '', abbr)\n",
    "        # Consider word boundaries for more robust counting\n",
    "        abbr_usage_pattern = rf'\\b{re.escape(abbr_search_string)}\\b'\n",
    "        # Original pattern (might be too restrictive or too loose depending on context):\n",
    "        # abbr_usage_pattern = rf'(?<![a-zA-Z\\(\\)]){re.escape(abbr_search_string)}(?![a-zA-Z\\)\\)])'\n",
    "        try:\n",
    "            count = len(re.findall(abbr_usage_pattern, text))\n",
    "            abbr_usage_count[abbr] = count\n",
    "        except re.error as re_err:\n",
    "             if debug: print(f\"Regex error counting usage for '{abbr}': {re_err}\")\n",
    "             abbr_usage_count[abbr] = 0 # Set count to 0 on error\n",
    "\n",
    "    if debug:\n",
    "        print(f\"  Abbreviation Usage Counts: {abbr_usage_count}\")\n",
    "    # --- END Usage Count ---\n",
    "\n",
    "\n",
    "    # --- Process Matches and Build Dictionary ---\n",
    "    for match in matches:\n",
    "        words_before_abbr_text = match[0].strip()\n",
    "        abbr_string = match[1].strip()\n",
    "        current_usage_count = abbr_usage_count.get(abbr_string, 0)\n",
    "\n",
    "        try:\n",
    "            abbr_items = get_abbr_repr_items(abbr_string)\n",
    "            words_ahead = [item for item in re.split(r'([ -]+)', words_before_abbr_text) if item]\n",
    "\n",
    "            if debug:\n",
    "                print(f\"\\n---\\nCandidate Found: '{abbr_string}'\")\n",
    "                # Add other debug prints as needed\n",
    "\n",
    "            if not words_ahead or not abbr_items:\n",
    "                 if debug: print(f\"  Skipping '{abbr_string}': No words ahead or no abbr items.\")\n",
    "                 continue\n",
    "\n",
    "            match_indices = find_abbreviation_matches(words_ahead, abbr_items, debug)\n",
    "            successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
    "            count_matched = len(successful_match_indices)\n",
    "            num_abbr_items = len(abbr_items)\n",
    "\n",
    "            # Validation Logic\n",
    "            valid_match = False\n",
    "            if num_abbr_items > 0:\n",
    "                ratio_matched = count_matched / num_abbr_items\n",
    "                if ratio_matched >= match_threshold:\n",
    "                    valid_match = True\n",
    "                elif debug:\n",
    "                     print(f\"  Validation Failed for '{abbr_string}': Ratio {ratio_matched:.2f} < {match_threshold:.2f}\")\n",
    "            elif debug:\n",
    "                 print(f\"  Validation Failed for '{abbr_string}': No abbreviation items.\")\n",
    "\n",
    "            # Reconstruction Logic\n",
    "            if valid_match:\n",
    "                if not successful_match_indices:\n",
    "                     if debug: print(f\"  Skipping '{abbr_string}': Valid match but no indices?\")\n",
    "                     continue\n",
    "\n",
    "                min_idx_py = min(successful_match_indices)\n",
    "                max_idx_py = max(successful_match_indices)\n",
    "\n",
    "                if 0 <= min_idx_py <= max_idx_py < len(words_ahead):\n",
    "                    full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
    "                    full_name = ''.join(full_phrase_words_slice)\n",
    "\n",
    "                    if debug:\n",
    "                        print(f\"  Storing '{abbr_string}': '{full_name}' (Usage: {current_usage_count})\")\n",
    "\n",
    "                    abbreviation_dict[abbr_string] = {\n",
    "                        'full_name': full_name,\n",
    "                        'usage_count': current_usage_count\n",
    "                    }\n",
    "                else:\n",
    "                     if debug: print(f\"  Skipping '{abbr_string}': Invalid index range.\")\n",
    "\n",
    "        except Exception as e_process:\n",
    "            if debug:\n",
    "                print(f\"  ERROR processing match for '{abbr_string}': {e_process}\")\n",
    "            continue\n",
    "    # --- END Processing Matches ---\n",
    "\n",
    "    if debug:\n",
    "        print(f\"--- Debugging End ---\\nFinal Dict before DF creation: {abbreviation_dict}\")\n",
    "\n",
    "    # --- Check if dictionary is empty BEFORE processing ---\n",
    "    if not abbreviation_dict:\n",
    "        if debug:\n",
    "            print(\"No valid abbreviations found meeting criteria. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=['abbreviation', 'full_name', 'usage_count'])\n",
    "\n",
    "    # --- Convert Dict to DataFrame ---\n",
    "    # Convert dictionary directly to DataFrame with abbreviations as index first\n",
    "    try:\n",
    "         df = pd.DataFrame.from_dict(abbreviation_dict, orient='index')\n",
    "         # Reset index to make 'abbreviation' a column\n",
    "         df = df.reset_index().rename(columns={'index': 'abbreviation'})\n",
    "         # Ensure correct column order for clarity\n",
    "         df = df[['abbreviation', 'full_name', 'usage_count']]\n",
    "\n",
    "    except Exception as df_e:\n",
    "         if debug:\n",
    "              print(f\"Error creating DataFrame from dictionary: {df_e}. Returning empty DataFrame.\")\n",
    "         return pd.DataFrame(columns=['abbreviation', 'full_name', 'usage_count'])\n",
    "\n",
    "\n",
    "    # --- NEW SORTING STEP (Usage Count Desc, Abbreviation Asc) ---\n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"\\nSorting DataFrame by Usage Count (Desc), then Abbreviation (Asc)...\")\n",
    "\n",
    "        # Sort the DataFrame using sort_values\n",
    "        df = df.sort_values(\n",
    "            by=['usage_count', 'abbreviation'], # Columns to sort by\n",
    "            ascending=[False, True],           # Order for each column (False=Desc, True=Asc)\n",
    "            ignore_index=True                  # Reset index to 0, 1, 2... after sorting\n",
    "        )\n",
    "        if debug:\n",
    "            print(\"DataFrame sorted successfully.\")\n",
    "\n",
    "    except KeyError as e:\n",
    "         # This might happen if the DataFrame columns aren't named as expected\n",
    "         if debug:\n",
    "              print(f\"Sorting error: Column '{e}' not found for sorting. Returning DataFrame unsorted by count/abbr.\")\n",
    "         # Return the DataFrame without the new sort if columns are missing\n",
    "    except Exception as e_sort:\n",
    "        if debug:\n",
    "            print(f\"Generic sorting error: {e_sort}. Returning DataFrame unsorted by count/abbr.\")\n",
    "        # Return the DataFrame without the new sort on other errors\n",
    "    # --- END NEW SORTING STEP ---\n",
    "\n",
    "\n",
    "    # --- Return the final sorted DataFrame ---\n",
    "    if debug:\n",
    "        print(\"\\nFinal DataFrame head:\\n\", df.head())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53df77a1-2dda-45f0-bec2-11fec4bd519b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified extract_abbreviations with Panda DataFrame output\n",
    "\n",
    "\n",
    "def get_sort_key_from_abbr(abbr_string):\n",
    "    \"\"\"Generates a lowercase string key for sorting abbreviations.\"\"\"\n",
    "    repr_letters = get_abbr_repr_items(abbr_string)\n",
    "    sort_key = \"\".join(repr_letters).lower()\n",
    "    if not sort_key:\n",
    "         fallback_key = re.sub(r\"^[^\\w]+\", \"\", abbr_string.lower())\n",
    "         return fallback_key\n",
    "    return sort_key\n",
    "\n",
    "def extract_abbreviations(text, match_threshold=0.7, debug=True):\n",
    "    \"\"\"\n",
    "    Extracts abbreviations defined as (Abbr) following their definition.\n",
    "    Validates match if a certain threshold of abbreviation items are matched\n",
    "    to corresponding words. Also includes usage counts for matched abbreviations.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text potentially containing definitions.\n",
    "        match_threshold (float): The minimum fraction (e.g., 0.7 for 70%) of\n",
    "                                 abbreviation items that must be successfully\n",
    "                                 matched to words for the definition to be\n",
    "                                 considered valid.\n",
    "        debug (bool): Flag to enable extensive debug printing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing 'abbreviation', 'full_name',\n",
    "                      and 'usage_count', sorted alphabetically by abbreviation.\n",
    "                      Returns an empty DataFrame if no valid abbreviations are found.\n",
    "    \"\"\"\n",
    "    # Existing pattern and initialization\n",
    "    pattern = r'((?:[\\w\\\\\\$\\{\\}]+[ -]+){1,10}(?:[\\w\\\\\\$\\{\\}]+)[ -]?)\\(([^\\(\\)]*[a-zA-Z0-9]{2,}[^\\(\\)]*)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    abbreviation_dict = {}\n",
    "    abbr_usage_count = {}\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\nDebugging extract_abbreviations: Found {len(matches)} potential matches.\")\n",
    "\n",
    "    # --- Count Abbreviation Usages ---\n",
    "    # Count usage for all potential abbreviations found in parentheses first\n",
    "    all_potential_abbrs = [match[1].strip() for match in matches]\n",
    "    for abbr in set(all_potential_abbrs): # Use set to count each unique string once\n",
    "        # remove parenthesis and special characters for accurate search\n",
    "        abbr_search_string = re.sub(r'[\\(\\)]', '', abbr)\n",
    "        # Pattern to find the abbreviation as a whole word/unit\n",
    "        # Uses negative lookbehind/lookahead to avoid matching parts of words or inside brackets\n",
    "        abbr_usage_pattern = rf'(?<![a-zA-Z\\(\\)]){re.escape(abbr_search_string)}(?![a-zA-Z\\)\\)])' # Added spaces\n",
    "        # Count occurrences (adjust pattern if needed based on how abbreviations appear)\n",
    "        # Use finditer for potentially overlapping matches if required, len(findall) is usually sufficient\n",
    "        abbr_usage_count[abbr] = len(re.findall(abbr_usage_pattern, text))\n",
    "    if debug:\n",
    "        print(f\"  Abbreviation Usage Counts: {abbr_usage_count}\")\n",
    "    # --- END Usage Count ---\n",
    "\n",
    "\n",
    "    # --- Process Matches and Build Dictionary ---\n",
    "    for match in matches:\n",
    "        words_before_abbr_text = match[0].strip()\n",
    "        abbr_string = match[1].strip()\n",
    "\n",
    "        # Get the pre-calculated usage count\n",
    "        current_usage_count = abbr_usage_count.get(abbr_string, 0)\n",
    "\n",
    "        # Note: Original code didn't strictly filter by usage_count >= 2 here,\n",
    "        # keeping it that way unless explicitly needed. You could add:\n",
    "        # if current_usage_count < 2: continue\n",
    "\n",
    "        try: # Wrap processing for robustness\n",
    "            abbr_items = get_abbr_repr_items(abbr_string)\n",
    "            # Split preceding text using space/hyphen, retaining delimiters\n",
    "            words_ahead = [item for item in re.split(r'([ -]+)', words_before_abbr_text) if item]\n",
    "\n",
    "            if debug:\n",
    "                print(f\"\\n---\\nCandidate Found:\")\n",
    "                print(f\"  Captured Abbr String: '{abbr_string}'\")\n",
    "                print(f\"  Generated abbr_items: {abbr_items}\")\n",
    "                print(f\"  Preceding Text for Split: '{words_before_abbr_text}'\")\n",
    "                print(f\"  Words Ahead: {words_ahead}\")\n",
    "\n",
    "            # Initial check: Need words and abbreviation items to proceed\n",
    "            if not words_ahead or not abbr_items:\n",
    "                if debug:\n",
    "                    print(f\"  Skipping: No words ahead ({bool(words_ahead)}) or no abbr items found ({bool(abbr_items)}).\")\n",
    "                continue\n",
    "\n",
    "            match_indices = find_abbreviation_matches(words_ahead, abbr_items, debug)\n",
    "            successful_match_indices = [idx for idx in match_indices if idx != -1]\n",
    "            count_matched = len(successful_match_indices)\n",
    "            num_abbr_items = len(abbr_items)\n",
    "\n",
    "            if debug:\n",
    "                print(f\"  Successful match indices for words: {successful_match_indices}\")\n",
    "                print(f\"  Final match_indices map (abbr_idx -> word_idx): {match_indices}\")\n",
    "                print(f\"  Items matched: {count_matched} out of {num_abbr_items}\")\n",
    "\n",
    "            # Validation Logic (using threshold)\n",
    "            valid_match = False\n",
    "            if num_abbr_items > 0:\n",
    "                ratio_matched = count_matched / num_abbr_items\n",
    "                if ratio_matched >= match_threshold:\n",
    "                    valid_match = True\n",
    "                elif debug:\n",
    "                    print(f\"  Validation Failed: Match ratio {ratio_matched:.2f} is less than threshold {match_threshold:.2f}\")\n",
    "            elif debug:\n",
    "                print(\"  Validation Failed: No abbreviation items were generated.\")\n",
    "\n",
    "            # Reconstruction Logic\n",
    "            if valid_match:\n",
    "                if not successful_match_indices:\n",
    "                    if debug:\n",
    "                        print(\"  Skipping: Match deemed valid by ratio, but no word indices found?\")\n",
    "                    continue\n",
    "\n",
    "                min_idx_py = min(successful_match_indices)\n",
    "                max_idx_py = max(successful_match_indices)\n",
    "\n",
    "                if min_idx_py <= max_idx_py < len(words_ahead): # Check max_idx_py is valid\n",
    "                    full_phrase_words_slice = words_ahead[min_idx_py : max_idx_py + 1]\n",
    "                    full_name = ''.join(full_phrase_words_slice)\n",
    "\n",
    "                    if debug:\n",
    "                        print(f\"  Storing: '{abbr_string}': '{full_name}' (Usage: {current_usage_count})\")\n",
    "\n",
    "                    # Store in dictionary\n",
    "                    abbreviation_dict[abbr_string] = {\n",
    "                        'full_name': full_name,\n",
    "                        'usage_count': current_usage_count # Use pre-calculated count\n",
    "                    }\n",
    "                else:\n",
    "                     if debug:\n",
    "                        print(f\"  Skipping '{abbr_string}': Invalid index range {min_idx_py}-{max_idx_py} for words_ahead length {len(words_ahead)}.\")\n",
    "\n",
    "\n",
    "        except Exception as e_process:\n",
    "            if debug:\n",
    "                print(f\"  ERROR processing potential match for '{abbr_string}': {e_process}\")\n",
    "            continue # Safely skip to the next match if an error occurs\n",
    "\n",
    "    if debug:\n",
    "        print(f\"--- Debugging End ---\\nFinal Dict before sorting: {abbreviation_dict}\")\n",
    "\n",
    "    # --- Handle Empty Results BEFORE Sorting ---\n",
    "    if not abbreviation_dict:\n",
    "        if debug:\n",
    "            print(\"No valid abbreviations found meeting criteria. Returning empty DataFrame.\")\n",
    "        # Return an empty DataFrame with the expected column structure\n",
    "        return pd.DataFrame(columns=['abbreviation', 'full_name', 'usage_count'])\n",
    "\n",
    "    # --- SORTING STEP ---\n",
    "    try:\n",
    "        # Sort the dictionary items alphabetically based on the abbreviation key\n",
    "        sorted_items = sorted(\n",
    "            abbreviation_dict.items(),\n",
    "            key=lambda item: get_sort_key_from_abbr(item[0]) # item[0] is the abbreviation string\n",
    "        )\n",
    "    except Exception as e_sort:\n",
    "        if debug:\n",
    "            print(f\"Sorting error: {e_sort}. Proceeding with unsorted items.\")\n",
    "        # Fallback to unsorted list if sorting fails\n",
    "        sorted_items = list(abbreviation_dict.items())\n",
    "    # --- END SORTING STEP ---\n",
    "\n",
    "\n",
    "    # --- Convert sorted_items list to DataFrame (Method 1) ---\n",
    "    if debug:\n",
    "        print(f\"\\nConverting {len(sorted_items)} sorted items to DataFrame.\")\n",
    "\n",
    "    data_for_df = []\n",
    "    for abbr, details in sorted_items:\n",
    "        row_dict = {'abbreviation': abbr} # Start row dict with the abbreviation\n",
    "        row_dict.update(details)          # Add 'full_name' and 'usage_count' from details\n",
    "        data_for_df.append(row_dict)\n",
    "\n",
    "    # Create the DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data_for_df)\n",
    "    # --- END Conversion Step ---\n",
    "\n",
    "    # Ensure columns are in the desired order (optional but good practice)\n",
    "    if not df.empty:\n",
    "        df = df[['abbreviation', 'full_name', 'usage_count']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example Usage:\n",
    "# text_example = \"The Department of Defense (DoD) is important. Another mention of DoD. Federal Bureau of Investigation (FBI) is also key. Not a match (NaM).\"\n",
    "# df_results = extract_abbreviations(text_example, debug=True)\n",
    "# print(\"\\n--- Final DataFrame Output ---\")\n",
    "# print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b0656-b735-45ef-af7c-33fde94a3970",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Formatting abbrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41288878-4fac-4181-a1c7-e1350c665adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d212994a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def format_abbreviations(sorted_items, format_type=\"plain\"):\n",
    "    \"\"\"Formats the extracted abbreviations based on the specified type.\n",
    "       Sorts abbreviations alphabetically, handling LaTeX commands in keys.\n",
    "       ASSUMES extracted abbr and full_name are valid LaTeX snippets\n",
    "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
    "    \"\"\"\n",
    "    if not sorted_items:\n",
    "        return \"No abbreviations found.\"\n",
    "\n",
    "    #sorted_items = abbreviations_dict.items()\n",
    "    if format_type == \"nomenclature\":\n",
    "        # LaTeX nomenclature package format\n",
    "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
    "        latex_output += \"\\\\makenomenclature\\n\"\n",
    "        for abbr, full_name in sorted_items:\n",
    "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    elif format_type == \"tabular\":\n",
    "        # LaTeX tabular format for a table\n",
    "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        for abbr, full_name in sorted_items:\n",
    "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\end{tabular}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    else:\n",
    "        # Default format: plain list of abbreviations and full names\n",
    "        output = \"\"\n",
    "        items_list = list(sorted_items)  # Convert to list for index access if needed\n",
    "        for i, (abbr, full_name) in enumerate(items_list):\n",
    "            output += f\"{abbr}: {full_name}\"\n",
    "            if i < len(items_list) - 1:\n",
    "                output += \"; \\n\"  # Adds a semicolon between items\n",
    "        return output\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3d80636a-7888-407c-84b9-30abebd73873",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_abbreviations(abbr_df, format_type=\"plain\"):\n",
    "    \"\"\"Formats the extracted abbreviations DataFrame based on the specified type.\n",
    "       Assumes the input DataFrame is already sorted alphabetically by 'abbreviation'.\n",
    "       ASSUMES 'abbreviation' and 'full_name' columns contain valid LaTeX snippets\n",
    "       for 'tabular' and 'nomenclature' formats. No escaping is applied.\n",
    "\n",
    "    Args:\n",
    "        abbr_df (pd.DataFrame): DataFrame with at least 'abbreviation' and 'full_name' columns.\n",
    "                                Expected to be sorted by 'abbreviation'.\n",
    "        format_type (str): The desired output format ('nomenclature', 'tabular', or other for plain text).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the abbreviations, or a message if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    # Check if the input DataFrame is empty\n",
    "    if abbr_df.empty:\n",
    "        return \"No abbreviations found.\"\n",
    "\n",
    "    # NOTE: Sorting is assumed to have been done *before* this function is called.\n",
    "\n",
    "    if format_type == \"nomenclature\":\n",
    "        # LaTeX nomenclature package format\n",
    "        latex_output = \"\\\\usepackage{nomencl}\\n\"\n",
    "        latex_output += \"\\\\makenomenclature\\n\"\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            latex_output += f\"\\\\nomenclature{{{abbr}}}{{{full_name}}}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    elif format_type == \"tabular\":\n",
    "        # LaTeX tabular format for a table\n",
    "        latex_output = \"\\\\begin{tabular}{ll}\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\textbf{Abbreviation} & \\\\textbf{Full Name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            latex_output += f\"{abbr} & {full_name} \\\\\\\\\\n\"\n",
    "        latex_output += \"\\\\hline\\n\"\n",
    "        latex_output += \"\\\\end{tabular}\\n\"\n",
    "        return latex_output\n",
    "\n",
    "    else:\n",
    "        # Default format: plain list of abbreviations and full names\n",
    "        output_parts = []\n",
    "        # Iterate over DataFrame rows\n",
    "        for index, row in abbr_df.iterrows():\n",
    "            abbr = row['abbreviation']\n",
    "            full_name = row['full_name']\n",
    "            output_parts.append(f\"{abbr}: {full_name}\")\n",
    "\n",
    "        # Join the parts with \"; \\n\" separator\n",
    "        return \"; \\n\".join(output_parts)\n",
    "\n",
    "# Example Usage (assuming df_results is a DataFrame from extract_abbreviations):\n",
    "# df_results = pd.DataFrame({\n",
    "#    'abbreviation': ['CAD', 'FBI', 'USA'],\n",
    "#    'full_name': ['Canada', 'Federal Bureau of Investigation', 'United States of America'],\n",
    "#    'usage_count': [1, 2, 3] # usage_count is ignored by this function\n",
    "# })\n",
    "\n",
    "# print(\"--- Nomenclature Format ---\")\n",
    "# print(format_abbreviations(df_results, \"nomenclature\"))\n",
    "# print(\"\\n--- Tabular Format ---\")\n",
    "# print(format_abbreviations(df_results, \"tabular\"))\n",
    "# print(\"\\n--- Plain Text Format ---\")\n",
    "# print(format_abbreviations(df_results, \"plain\")) # Any format_type other than the two specific ones\n",
    "# print(\"\\n--- Empty DataFrame Test ---\")\n",
    "# print(format_abbreviations(pd.DataFrame(columns=['abbreviation', 'full_name']), \"tabular\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abc22e-6480-4a7a-a2a9-839c909e6940",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Example Text and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a2f758e",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example_text\n",
    "example_text = r\"\"\"Paste your latex text (LT)  and enjoy the app (ETA). There is no limitation of the length of text. \n",
    "\n",
    "What is regarded as abbreviations (RA):\n",
    "\n",
    "The abbreviations like randomized survival probabilities (RSP) and  accelerated failure time(AFT), or \\textbf{Time-Constant (TC) Data}. The full definitions and abbrievations can contain greek symbols, for example,  $\\alpha$-synclein protein ($\\alpha$-SP), $\\beta$-Z residual (BZR), $\\sigma$-Z residual ($\\sigma$-ZR), $\\frac{\\gamma}{Z}$-residuals ($\\frac{\\gamma}{Z}$-R). The first letters of latex commands will be used to compare against the abbreviation letters.\n",
    "\n",
    "What is desregarded as abbreviations (DA):\n",
    "\n",
    "Citations and explanations in brackets will be omitted, eg. this one (Li et al. 2025), and this ($\\beta$). The $T$ in $f(T)$ is not an abbreviation too.   %This abbreviation, comment text (CT) or the line starting with % will be omitted. \n",
    "\n",
    "Note: the extraction is not perfect as it cannot accommodate all possible abbreviations and may include those you don't want. Modify the results as necessary.\n",
    "\n",
    "The abbreviations used above include: AFT, BZR,  DA,  ETA, LT, RSP,  RA, TC, $\\alpha$-SP, $\\frac{\\gamma}{Z}$-R, $\\sigma$-ZR. We will happily use LT as we want. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8fb451f0-d794-4299-aa74-eab227871cfe",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   abbreviation                            full_name  \\\n",
      "0                   $\\alpha$-SP            $\\alpha$-synclein protein   \n",
      "1   $\\frac { \\gamma } { Z } $-R  $\\frac { \\gamma } { Z } $-residuals   \n",
      "2                   $\\sigma$-ZR                  $\\sigma$-Z residual   \n",
      "3                           AFT             accelerated failure time   \n",
      "4                           BZR                   $\\beta$-Z residual   \n",
      "5                            DA         desregarded as abbreviations   \n",
      "6                           ETA                        enjoy the app   \n",
      "7                            LT                           latex text   \n",
      "8                            RA            regarded as abbreviations   \n",
      "9                           RSP    randomized survival probabilities   \n",
      "10                           TC                        Time-Constant   \n",
      "\n",
      "    usage_count  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "5             1  \n",
      "6             1  \n",
      "7             2  \n",
      "8             1  \n",
      "9             1  \n",
      "10            1  \n",
      "$\\alpha$-SP: $\\alpha$-synclein protein; \n",
      "$\\frac { \\gamma } { Z } $-R: $\\frac { \\gamma } { Z } $-residuals; \n",
      "$\\sigma$-ZR: $\\sigma$-Z residual; \n",
      "AFT: accelerated failure time; \n",
      "BZR: $\\beta$-Z residual; \n",
      "DA: desregarded as abbreviations; \n",
      "ETA: enjoy the app; \n",
      "LT: latex text; \n",
      "RA: regarded as abbreviations; \n",
      "RSP: randomized survival probabilities; \n",
      "TC: Time-Constant\n"
     ]
    }
   ],
   "source": [
    "# testing with exmaple test\n",
    "\n",
    "abbre_dict = extract_abbreviations(normalize_latex_math(example_text),debug=False)\n",
    "print(abbre_dict)\n",
    "print(format_abbreviations(abbre_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a0a6b",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "normalize_latex_math Example with example_text\n",
    "normtext = normalize_latex_math(example_text)\n",
    "\n",
    "print(normtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31680e4-6079-42ef-ba55-7e9f7b28db00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Streamlit interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a40588-829c-43dc-ad4a-12e3530de652",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "st.set_page_config(layout=\"wide\") # Original layout setting\n",
    "st.title(r\"Extracting Abbreviations from $\\LaTeX$ Text\") # Original title\n",
    "\n",
    "# --- Initialize Session State ---\n",
    "# Use '_df' suffix for the variable storing the DataFrame result\n",
    "if 'abbreviations_df' not in st.session_state:\n",
    "    st.session_state.abbreviations_df = None\n",
    "if 'last_input_text' not in st.session_state:\n",
    "    st.session_state.last_input_text = example_text\n",
    "if 'processed_url_param' not in st.session_state:\n",
    "    st.session_state.processed_url_param = False\n",
    "# Removed 'first_run_done' as its logic seemed intertwined with layout issues,\n",
    "# relying on button press or URL processing should be sufficient.\n",
    "\n",
    "# --- Handle URL Query Parameter (Logic remains the same, but uses _df variable) ---\n",
    "url_text_param = st.query_params.get(\"text\", None)\n",
    "\n",
    "if url_text_param and not st.session_state.processed_url_param:\n",
    "    print(f\"Processing text from URL parameter: {url_text_param[:50]}...\") # Debug print\n",
    "    st.session_state.last_input_text = url_text_param # Pre-fill text area state\n",
    "    try:\n",
    "        with st.spinner(\"Processing text from URL...\"):\n",
    "            normalized_text = normalize_latex_math(url_text_param)\n",
    "            # Store the DataFrame result\n",
    "            st.session_state.abbreviations_df = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "            st.session_state.processed_url_param = True # Mark as processed\n",
    "            # st.rerun() # Rerun might be needed depending on desired immediate update behavior\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error processing text from URL: {e}\")\n",
    "        st.session_state.abbreviations_df = None # Clear result on error\n",
    "        st.session_state.processed_url_param = True # Mark as processed even if error\n",
    "elif not url_text_param:\n",
    "     st.session_state.processed_url_param = False\n",
    "\n",
    "# --- Create two main columns for side-by-side layout (Original Ratio) ---\n",
    "col_input, col_output = st.columns([3, 1]) # Original 3:1 ratio\n",
    "\n",
    "# --- Column 1: Input Area (Original Structure) ---\n",
    "with col_input:\n",
    "    st.subheader(\"Paste Your text\") # Original subheader\n",
    "    input_text = st.text_area(\n",
    "        label=\"input_text_main\",\n",
    "        label_visibility=\"collapsed\", # Original setting\n",
    "        value=st.session_state.last_input_text,\n",
    "        height=350,  # Original height\n",
    "        placeholder=\"Paste your text here...\",\n",
    "        key=\"input_text_area\"\n",
    "    )\n",
    "    st.caption(\"Privacy: this app does not save your text.\") # Original caption\n",
    "\n",
    "    # Update session state if text changes (useful for comparison)\n",
    "    if input_text != st.session_state.last_input_text:\n",
    "        st.session_state.last_input_text = input_text\n",
    "        # Decide if results should clear when text changes - currently they don't unless button pressed again\n",
    "        # st.session_state.abbreviations_df = None\n",
    "\n",
    "# --- Column 2: Controls and Output Display (Original Structure) ---\n",
    "with col_output:\n",
    "    # Original button label and settings\n",
    "    extract_pressed = st.button(\"Extract Abbreviations with Regex\", type=\"primary\", use_container_width=True)\n",
    "\n",
    "    # --- Processing Logic (Triggered by button press) ---\n",
    "    if True:\n",
    "        if input_text:\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                try:\n",
    "                    normalized_text = normalize_latex_math(input_text)\n",
    "                    # Store the DataFrame result\n",
    "                    st.session_state.abbreviations_df = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "                except Exception as e:\n",
    "                    st.error(f\"An error occurred during extraction: {e}\")\n",
    "                    st.session_state.abbreviations_df = None # Clear result on error\n",
    "        else:\n",
    "            # Original warning message\n",
    "            st.warning(\"Please enter some text in the input box above.\")\n",
    "            st.session_state.abbreviations_df = None # Clear result if no input\n",
    "\n",
    "\n",
    "    # --- Display Results Table ---\n",
    "    output_placeholder = \"Output will appear here after clicking 'Extract Abbreviations'.\" # Original placeholder\n",
    "    df_display = st.session_state.get('abbreviations_df', None) # Safely get the DataFrame\n",
    "\n",
    "    # Use container with original height, no border\n",
    "    with st.container(height=350, border=False): # Original height, border setting\n",
    "        if df_display is not None and not df_display.empty:\n",
    "            # Rename columns to match original example attempt for display table\n",
    "            df_display_renamed = df_display.rename(columns={\n",
    "                'abbreviation': 'Abbreviation',\n",
    "                'full_name': 'Full Phrase',\n",
    "                'usage_count': 'Usage' \n",
    "            })\n",
    "            # Select only the columns intended for display in the original code\n",
    "            display_columns = ['Abbreviation', 'Full Phrase', 'Usage']\n",
    "            # Generate markdown table from the DataFrame\n",
    "            markdown_table = df_display_renamed[display_columns].to_markdown(index=False)\n",
    "            st.markdown(markdown_table) # Display the table\n",
    "\n",
    "        elif df_display is not None and df_display.empty: # Explicitly handle empty DataFrame\n",
    "            # Use a message consistent with format_abbreviations output for empty results\n",
    "            st.info(\"No abbreviations found in the text.\")\n",
    "        # else: # df_display is None (initial state or after error/clearing)\n",
    "            # Original code didn't explicitly display placeholder *here*.\n",
    "            # If processing hasn't happened or failed, this area will remain blank,\n",
    "            # which matches the implied behavior of the original structure.\n",
    "            # To show placeholder requires tracking if button was ever pressed.\n",
    "            # Simpler approach: rely on Export section's output area to show status.\n",
    "\n",
    "\n",
    "# --- Export Section (Original Structure) ---\n",
    "# Original column setup for export controls\n",
    "col_exp, _ = st.columns([1, 1])\n",
    "with col_exp:\n",
    "    st.subheader(\"Export\") # Original subheader\n",
    "    selected_format = st.selectbox(\n",
    "        label=\"Choose an exportting format:\", # Original label text\n",
    "        label_visibility=\"collapsed\",  # Original setting\n",
    "        options=['plain', 'tabular', 'nomenclature'],\n",
    "        index=0,  # Original default index (plain)\n",
    "        key='format_selector', # Original key\n",
    "        help=\"Select the format for the abbreviation list output.\" # Original help text\n",
    "    )\n",
    "\n",
    "    # --- Prepare and Display Formatted Output for Copying ---\n",
    "    # Initialize variable for the text area value\n",
    "    formatted_output = \"\" # Default to empty string\n",
    "    df_export = st.session_state.get('abbreviations_df', None) # Safely get the DataFrame\n",
    "\n",
    "    if df_export is not None:\n",
    "        # Check if the DataFrame is empty using .empty\n",
    "        if df_export.empty:\n",
    "            # Use the specific message for empty results\n",
    "            formatted_output = \"No abbreviations found in the text.\"\n",
    "        else:\n",
    "            try:\n",
    "                # Pass the DataFrame to the formatting function\n",
    "                formatted_output = format_abbreviations(df_export, format_type=selected_format)\n",
    "            except Exception as format_e:\n",
    "                formatted_output = f\"Error formatting output: {format_e}\"\n",
    "                st.error(formatted_output) # Show error if formatting fails\n",
    "    # else: If df_export is None, formatted_output remains \"\" initially\n",
    "\n",
    "    # Display the formatted output in the text area (Original settings)\n",
    "    st.text_area(\n",
    "        label=\"output_text_main\", # Original internal label\n",
    "        label_visibility=\"collapsed\", # Original setting\n",
    "        value=formatted_output, # Value is prepared above\n",
    "        height=150,  # Original height\n",
    "        help=\"Copy the output from this box.\", # Original help text\n",
    "        key=\"output_text_area\" # Original key\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Explanations Section (Original Structure) ---\n",
    "st.divider() # Original separator\n",
    "st.subheader(\"About the Algorithm\") # Original subheader\n",
    "\n",
    "# Define Content for Both Expanders (Keep existing text - updated slightly for accuracy)\n",
    "summary_expander_label = \"ⓘ How Abbreviation Extraction Works (Summary)\"\n",
    "summary_explanation_text = \"\"\"\n",
    "This tool attempts to find abbreviations defined within parentheses, like `Full Definition (Abbr)`, even in text containing LaTeX formatting. Here's the basic process:\n",
    "\n",
    "1.  **Finding Candidates:** It scans the text using regular expressions to locate potential `Definition (Abbr)` patterns, focusing on words on the same line just before the parentheses.\n",
    "2.  **Parsing Abbreviation:** It breaks down the abbreviation (e.g., `GRs`, `\\\\gamma R`) into core components (like `g`, `r` or `\\\\gamma`, `r`), ignoring plural 's' after capitals.\n",
    "3.  **Matching Backwards:** It looks backward from the abbreviation's components through the preceding words/separators to find likely corresponding words (e.g., matching 'R' to 'Residuals'). It handles letters and LaTeX commands differently during matching.\n",
    "4.  **Reconstructing Definition:** If a consistent match is found, it rebuilds the definition phrase, preserving original spacing and hyphens.\n",
    "5.  **Validation:** A match is considered valid only if a high enough percentage (e.g., >= 70%) of the abbreviation's components were matched.\n",
    "6.  **Usage Count:** It counts how many times the validly defined abbreviation appears elsewhere in the text (outside its definition).\n",
    "7.  **Output:** Returns results (Abbreviation, Full Name, Count) as a DataFrame, sorted alphabetically.\n",
    "\n",
    "*(This process uses heuristics, especially for LaTeX, so results may vary.)*\n",
    "\"\"\"\n",
    "\n",
    "detailed_expander_label = \"ⓘ Detailed Algorithm Explanation\"\n",
    "detailed_description_text = \"\"\"\n",
    "This algorithm identifies abbreviations defined as `Full Definition Phrase (Abbr)` within text, including LaTeX, extracts the phrase, and counts usage.\n",
    "\n",
    "**Core Steps:**\n",
    "\n",
    "1.  **Optional Preprocessing (`normalize_latex_math`):** Standardizes LaTeX comments, math delimiters (`\\\\(...\\\\)` to `\\$...\\$`), spacing around braces/commands.\n",
    "2.  **Candidate Identification (Regex):** Finds `Definition (Abbr)` patterns. Captures preceding words (Group 1, same line only) and the abbreviation (Group 2).\n",
    "3.  **Usage Counting:** Counts occurrences of each *potential* abbreviation string (from Group 2) elsewhere in the text using a separate regex pattern designed to match the abbreviation as a standalone unit. Stores these counts.\n",
    "4.  **Abbreviation Parsing (`get_abbr_repr_items`):** Creates a list (`abbr_items`) from the abbreviation. Keeps `\\\\commands` as strings, uses initial uppercase letters (ignoring trailing lowercase, e.g., `CPs` -> `c`, `p`), includes standalone lowercase.\n",
    "5.  **Preceding Text Tokenization (Split):** Splits preceding words into `words_ahead` using `re.split(r'([ -]+)', ...)`, retaining spaces/hyphens as separate tokens (empty strings removed).\n",
    "6.  **Backward Matching (`find_abbreviation_matches`):** Matches `abbr_items` to `words_ahead` tokens in reverse.\n",
    "    * **Word Analysis (`get_effective_char`):** Derives a single effective character (first letter after heuristic LaTeX stripping) from word tokens for letter-matching.\n",
    "    * **Comparison:** Matches command `abbr_items` if a word token starts with the command (allows leading `\\$`). Matches letter `abbr_items` against a word token's `effective_char`. Skips separator tokens.\n",
    "    * Records `match_indices` (word index for each abbr index, or -1).\n",
    "7.  **Validation:** Calculates the ratio of successfully matched items (`count_matched / num_abbr_items`). Considers the definition valid if this ratio meets/exceeds a `match_threshold` (default 0.7).\n",
    "8.  **Phrase Reconstruction:** If valid, finds the min/max matched word indices, slices `words_ahead` (getting words and separators), and reconstructs the `full_name` using `\"\".join(slice)` to preserve original spacing/hyphens.\n",
    "9.  **Output Aggregation:** Stores valid `abbreviation`, reconstructed `full_name`, and pre-calculated `usage_count` in a dictionary.\n",
    "10. **Final Conversion & Sorting:** Converts the final dictionary into a Pandas DataFrame and sorts it alphabetically by abbreviation before returning.\n",
    "\"\"\"\n",
    "\n",
    "# Create Columns and Display Expanders (Original column setup)\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    with st.expander(summary_expander_label):\n",
    "        st.markdown(summary_explanation_text)\n",
    "with col2:\n",
    "    with st.expander(detailed_expander_label):\n",
    "        st.markdown(detailed_description_text)\n",
    "\n",
    "\n",
    "# --- Footer (Original Structure) ---\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Author: Longhai Li, https://longhaisk.github.io, Saskatoon, SK, Canada\")\n",
    "# Original commented out date logic\n",
    "# current_date_param = st.query_params.get('current_date', 'N/A')\n",
    "# st.caption(f\"Current date (from URL param 'current_date', if provided): {current_date_param}\")\n",
    "# st.caption(f\"Actual current server time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (CST)\") # Indicate CST\n",
    "# st.caption(\"Location context: Saskatoon, SK, Canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4277c7-c744-4241-b068-b898e11e3e26",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(r\"Extracting Abbreviations from $\\LaTeX$ Text\")\n",
    "# --- Initialize Session State (Add 'processed_url_param') ---\n",
    "if 'abbreviations_dict' not in st.session_state:\n",
    "    st.session_state.abbreviations_dict = None\n",
    "if 'last_input_text' not in st.session_state:\n",
    "    st.session_state.last_input_text = example_text\n",
    "if 'processed_url_param' not in st.session_state:\n",
    "    st.session_state.processed_url_param = False  # Flag to process URL text only once\n",
    "\n",
    "# --- Handle URL Query Parameter (Place this *before* UI rendering) ---\n",
    "# Use \"text\" as the parameter name, default to None if not present\n",
    "url_text_param = st.query_params.get(\"text\", None)\n",
    "\n",
    "if url_text_param and not st.session_state.processed_url_param:\n",
    "    # If param exists AND we haven't processed it automatically yet\n",
    "    print(f\"Processing text from URL parameter: {url_text_param[:50]}...\")  # Debug print\n",
    "    st.session_state.last_input_text = url_text_param  # Pre-fill text area state\n",
    "    try:\n",
    "        # Use a spinner just like the button press\n",
    "        with st.spinner(\"Processing text from URL...\"):\n",
    "            normalized_text = normalize_latex_math(url_text_param)\n",
    "            # Run extraction and store result directly in session state\n",
    "            st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "            st.session_state.processed_url_param = True  # Mark as processed\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error processing text from URL: {e}\")\n",
    "        st.session_state.abbreviations_dict = None\n",
    "        st.session_state.processed_url_param = True  # Mark as processed even if error\n",
    "elif not url_text_param:\n",
    "    # If no URL text parameter on this run, reset the flag\n",
    "    # Allows reprocessing if user navigates away and back without param\n",
    "    st.session_state.processed_url_param = False\n",
    "\n",
    "# --- Create two main columns for side-by-side layout ---\n",
    "col_input, col_output = st.columns([3, 1])  # Create two equal-width columns\n",
    "\n",
    "# --- Column 1: Input Area ---\n",
    "with col_input:\n",
    "    st.subheader(\"Paste Your text\")\n",
    "    input_text = st.text_area(\n",
    "        label=\"input_text_main\",\n",
    "        label_visibility=\"collapsed\",\n",
    "        value=st.session_state.last_input_text,\n",
    "        height=350,  # Adjust height as needed for side-by-side view\n",
    "        placeholder=\"Paste your text here...\",\n",
    "        key=\"input_text_area\"\n",
    "    )\n",
    "    st.caption(\"Privacy: this app does not save your text.\")\n",
    "\n",
    "    # --- Use THREE columns in ONE row for Button, Label, Selector ---\n",
    "    # Adjust the ratios as needed for desired visual spacing\n",
    "\n",
    "\n",
    "with col_output:\n",
    "    # st.subheader(\"Formatted Abbreviations\")  # Header\n",
    "\n",
    "    extract_pressed = st.button(\"Extract Abbreviations with Regex\", type=\"primary\",\n",
    "                                use_container_width=True)\n",
    "    if input_text != st.session_state.last_input_text:\n",
    "        st.session_state.last_input_text = input_text\n",
    "    # Processing Logic (triggered by button state)\n",
    "    if \"first_run_done\" not in st.session_state:\n",
    "        st.session_state.first_run_done = True  # Mark that the first run has happened\n",
    "\n",
    "    if extract_pressed or st.session_state.first_run_done:  # Check the state of the button variable\n",
    "        if input_text:\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                normalized_text = normalize_latex_math(input_text)\n",
    "                # Run extraction and store result directly in session state\n",
    "                st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=False)\n",
    "        else:\n",
    "            st.warning(\"Please enter some text in the input box above.\")\n",
    "            st.session_state.abbreviations_dict = None\n",
    "\n",
    "    # st.session_state.selected_method = st.selectbox(\n",
    "    #    label=\"Choose a method:\", #\n",
    "    #    label_visibility=\"collapsed\",\n",
    "    #    options=['regex', 'Gemini', 'ChatGPT'],\n",
    "    #    index=0,  # Default to 'tabular'\n",
    "    #    key='method_selector', # Key allows state to persist\n",
    "    #    help=\"Select the method for extracting abbreviations.\"\n",
    "    # )\n",
    "    # Update session state for input text (placement fine here)\n",
    "    # if input_text != st.session_state.last_input_text:\n",
    "    #    st.session_state.last_input_text = input_text\n",
    "    # # if st.session_state.first_run_done: # Check the state of the button variable\n",
    "    # if st.session_state.selected_method:\n",
    "    #    with st.spinner(\"Processing...\"):\n",
    "    #        normalized_text = normalize_latex_math(input_text)\n",
    "    #        st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "    # else:\n",
    "    #    st.warning(\"Other method is not implemented yet.\")\n",
    "    #    st.session_state.abbreviations_dict = None\n",
    "\n",
    "    # --- Prepare Output Value ---\n",
    "    output_placeholder = \"Output will appear here after clicking 'Extract Abbreviations'.\"\n",
    "\n",
    "    formatted_output_display = output_placeholder\n",
    "    if st.session_state.abbreviations_dict is not None:\n",
    "        if not st.session_state.abbreviations_dict:\n",
    "            formatted_output_display = \"No abbreviations found in the text.\"\n",
    "        else:\n",
    "            formatted_output_display = format_abbreviations(st.session_state.abbreviations_dict,\n",
    "                                                            format_type=\"plain\")\n",
    "\n",
    "    # --- Display Output Text Area ---\n",
    "\n",
    "    # Convert to Markdown table string\n",
    "    if st.session_state.abbreviations_dict:\n",
    "        df_abbr = pd.DataFrame(st.session_state.abbreviations_dict,\n",
    "                                columns=['Abbreviation', 'Full Phrase', 'Usage Count'])\n",
    "        markdown_table = df_abbr.to_markdown(index=False)\n",
    "    else:\n",
    "        markdown_table = \"No abbreviations found\"\n",
    "    # html_table = render_dataframe_with_latex(df_abbr)\n",
    "    # Display using st.markdown - LaTeX should render automatically\n",
    "    with st.container(height=350, border=False):  # Adjust height in pixels as needed\n",
    "        st.markdown(markdown_table)\n",
    "    # st.markdown(html_table, unsafe_allow_html=True)\n",
    "\n",
    "# sub_col_label, sub_col_widget = st.columns([0.5, 3])\n",
    "# with sub_col_label:\n",
    "#  # Place label text in the second sub-column\n",
    "#  # Using markdown allows potential styling. Adjust padding/margin for vertical alignment.\n",
    "#  st.markdown(\"<div style='margin-top: 0.6rem; text-align: left;'>Format:</div>\", unsafe_allow_html=True)\n",
    "#  # Simpler alternative: st.text(\"Format:\") - may not align vertically as well\n",
    "\n",
    "# with sub_col_widget:\n",
    "#  # Place selectbox in the third sub-column (hide its own label)\n",
    "col_exp, _ = st.columns([1, 1])\n",
    "with col_exp:\n",
    "    st.subheader(\"Export\")\n",
    "    selected_format = st.selectbox(\n",
    "        label=\"Choose an exporting format:\",  #\n",
    "        label_visibility=\"collapsed\",\n",
    "        options=['plain', 'tabular', 'nomenclature'],\n",
    "        index=0,  # Default to 'tabular'\n",
    "        key='format_selector',  # Key allows state to persist\n",
    "        help=\"Select the format for the abbreviation list output.\"\n",
    "    )\n",
    "\n",
    "    if st.session_state.abbreviations_dict is not None:\n",
    "        if not st.session_state.abbreviations_dict:\n",
    "            formatted_output = \"No abbreviations found in the text.\"\n",
    "        else:\n",
    "            formatted_output = format_abbreviations(st.session_state.abbreviations_dict,\n",
    "                                                    format_type=selected_format)\n",
    "    st.text_area(\n",
    "        label=\"output_text_main\",\n",
    "        label_visibility=\"collapsed\",\n",
    "        value=formatted_output,\n",
    "        height=150,  # Explicit Height (Match input column)\n",
    "        help=\"Copy the output from this box.\",\n",
    "        key=\"output_text_area\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d626294",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "streamlit",
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(r\"Extracting Abbreviations from $\\LaTeX$ Text\")\n",
    "# --- Initialize Session State (Add 'processed_url_param') ---\n",
    "if 'abbreviations_dict' not in st.session_state:\n",
    "    st.session_state.abbreviations_dict = None\n",
    "if 'last_input_text' not in st.session_state:\n",
    "    st.session_state.last_input_text = example_text\n",
    "if 'processed_url_param' not in st.session_state:\n",
    "     st.session_state.processed_url_param = False # Flag to process URL text only once\n",
    "\n",
    "# --- Handle URL Query Parameter (Place this *before* UI rendering) ---\n",
    "# Use \"text\" as the parameter name, default to None if not present\n",
    "url_text_param = st.query_params.get(\"text\", None)\n",
    "\n",
    "if url_text_param and not st.session_state.processed_url_param:\n",
    "    # If param exists AND we haven't processed it automatically yet\n",
    "    print(f\"Processing text from URL parameter: {url_text_param[:50]}...\") # Debug print\n",
    "    st.session_state.last_input_text = url_text_param # Pre-fill text area state\n",
    "    try:\n",
    "        # Use a spinner just like the button press\n",
    "        with st.spinner(\"Processing text from URL...\"):\n",
    "             normalized_text = normalize_latex_math(url_text_param)\n",
    "             # Run extraction and store result directly in session state\n",
    "             st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "             st.session_state.processed_url_param = True # Mark as processed\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error processing text from URL: {e}\")\n",
    "        st.session_state.abbreviations_dict = None\n",
    "        st.session_state.processed_url_param = True # Mark as processed even if error\n",
    "elif not url_text_param:\n",
    "     # If no URL text parameter on this run, reset the flag\n",
    "     # Allows reprocessing if user navigates away and back without param\n",
    "     st.session_state.processed_url_param = False\n",
    "\n",
    "# --- Create two main columns for side-by-side layout ---\n",
    "col_input, col_output = st.columns([3, 1]) # Create two equal-width columns\n",
    "\n",
    "# --- Column 1: Input Area ---\n",
    "with col_input:\n",
    "    st.subheader(\"Paste Your text\")\n",
    "    input_text = st.text_area(\n",
    "        label=\"input_text_main\",\n",
    "        label_visibility=\"collapsed\",\n",
    "        value=st.session_state.last_input_text,\n",
    "        height=350,  # Adjust height as needed for side-by-side view\n",
    "        placeholder=\"Paste your text here...\",\n",
    "        key=\"input_text_area\"\n",
    "    )\n",
    "    st.caption(\"Privacy: this app does not save your text.\")\n",
    "\n",
    "\n",
    "    # --- Use THREE columns in ONE row for Button, Label, Selector ---\n",
    "    # Adjust the ratios as needed for desired visual spacing\n",
    "  \n",
    "        \n",
    "with col_output:\n",
    "    #st.subheader(\"Formatted Abbreviations\")  # Header\n",
    "\n",
    "    extract_pressed = st.button(\"Extract Abbreviations with Regex\", type=\"primary\", use_container_width=True)\n",
    "    if input_text != st.session_state.last_input_text:\n",
    "         st.session_state.last_input_text = input_text\n",
    "    # Processing Logic (triggered by button state)\n",
    "    if \"first_run_done\" not in st.session_state:\n",
    "        st.session_state.first_run_done = True  # Mark that the first run has happened\n",
    "\n",
    "    if extract_pressed or st.session_state.first_run_done: # Check the state of the button variable\n",
    "        if input_text:\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                normalized_text = normalize_latex_math(input_text)\n",
    "                st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=False)\n",
    "        else:\n",
    "            st.warning(\"Please enter some text in the input box above.\")\n",
    "            st.session_state.abbreviations_dict = None\n",
    "  \n",
    "    # st.session_state.selected_method = st.selectbox(\n",
    "    #     label=\"Choose a method:\", # \n",
    "    #     label_visibility=\"collapsed\", \n",
    "    #     options=['regex', 'Gemini', 'ChatGPT'],\n",
    "    #     index=0,  # Default to 'tabular'\n",
    "    #     key='method_selector', # Key allows state to persist\n",
    "    #     help=\"Select the method for extracting abbreviations.\"\n",
    "    # )\n",
    "    # Update session state for input text (placement fine here)\n",
    "    # if input_text != st.session_state.last_input_text:\n",
    "    #     st.session_state.last_input_text = input_text\n",
    "    # # if st.session_state.first_run_done: # Check the state of the button variable\n",
    "    # if st.session_state.selected_method:\n",
    "    #     with st.spinner(\"Processing...\"):\n",
    "    #         normalized_text = normalize_latex_math(input_text)\n",
    "    #         st.session_state.abbreviations_dict = extract_abbreviations(normalized_text, debug=DEBUG)\n",
    "    # else:\n",
    "    #     st.warning(\"Other method is not implemented yet.\")\n",
    "    #     st.session_state.abbreviations_dict = None\n",
    "        \n",
    "    #--- Prepare Output Value ---\n",
    "    output_placeholder = \"Output will appear here after clicking 'Extract Abbreviations'.\"\n",
    "    \n",
    "    formatted_output_display = output_placeholder\n",
    "    if st.session_state.abbreviations_dict is not None:\n",
    "        formatted_output_display = \"No abbreviations found in the text.\"\n",
    "    else:\n",
    "        formatted_output_display = format_abbreviations(st.session_state.abbreviations_dict, format_type=\"plain\")\n",
    "\n",
    "    # --- Display Output Text Area ---\n",
    "\t\n",
    "    \n",
    "\n",
    "    # Convert to Markdown table string\n",
    "    df_abbr = pd.DataFrame(st.session_state.abbreviations_dict.items(), columns=['Abbreviation', 'Full Phrase'])\n",
    "    markdown_table = df_abbr.to_markdown(index=False)\n",
    "    #html_table = render_dataframe_with_latex(df_abbr)\n",
    "    # Display using st.markdown - LaTeX should render automatically\n",
    "    with st.container(height=350, border=False): # Adjust height in pixels as needed\n",
    "        st.markdown(markdown_table)\n",
    "\t#st.markdown(html_table, unsafe_allow_html=True)\n",
    "    \n",
    "#sub_col_label, sub_col_widget = st.columns([0.5, 3])\n",
    "#with sub_col_label:\n",
    "    # Place label text in the second sub-column\n",
    "    # Using markdown allows potential styling. Adjust padding/margin for vertical alignment.\n",
    "#    st.markdown(\"<div style='margin-top: 0.6rem; text-align: left;'>Format:</div>\", unsafe_allow_html=True)\n",
    "    # Simpler alternative: st.text(\"Format:\") - may not align vertically as well\n",
    "\n",
    "#with sub_col_widget:\n",
    "    # Place selectbox in the third sub-column (hide its own label)\n",
    "col_exp, _ = st.columns([1, 1])\n",
    "with col_exp:\n",
    "    st.subheader(\"Export\")        \n",
    "    selected_format = st.selectbox(\n",
    "        label=\"Choose an exportting format:\", # \n",
    "        label_visibility=\"collapsed\", \n",
    "        options=['plain', 'tabular', 'nomenclature'],\n",
    "        index=0,  # Default to 'tabular'\n",
    "        key='format_selector', # Key allows state to persist\n",
    "        help=\"Select the format for the abbreviation list output.\"\n",
    "    )\n",
    "        \n",
    "    if st.session_state.abbreviations_dict is not None:\n",
    "            if not st.session_state.abbreviations_dict:\n",
    "                formatted_output = \"No abbreviations found in the text.\"\n",
    "            else:\n",
    "                formatted_output = format_abbreviations(st.session_state.abbreviations_dict, format_type=selected_format)    \n",
    "    st.text_area(\n",
    "            label=\"output_text_main\",\n",
    "            label_visibility=\"collapsed\",\n",
    "            value=formatted_output,\n",
    "            height=150,  # Explicit Height (Match input column)\n",
    "            help=\"Copy the output from this box.\",\n",
    "            key=\"output_text_area\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Add a visual separator before the explanations\n",
    "st.divider()\n",
    "st.subheader(\"About the Algorithm\") # Optional subheader for the section\n",
    "\n",
    "# --- Define Content for Both Expanders ---\n",
    "\n",
    "# 1. Conceptual Summary Content\n",
    "summary_expander_label = \"ⓘ How Abbreviation Extraction Works (Summary)\"\n",
    "summary_explanation_text = \"\"\"\n",
    "This tool attempts to find abbreviations defined within parentheses, like `Full Definition (Abbr)`, even in text containing LaTeX formatting. Here's the basic process:\n",
    "\n",
    "1.  **Finding Candidates:** It scans the text using regular expressions to locate potential `Definition (Abbr)` patterns, focusing on words on the same line just before the parentheses.\n",
    "2.  **Parsing Abbreviation:** It breaks down the abbreviation (e.g., `GRs`, `\\\\gamma R`) into core components (like `g`, `r` or `\\\\gamma`, `r`), ignoring plural 's' after capitals.\n",
    "3.  **Matching Backwards:** It looks backward from the abbreviation's components through the preceding words/separators to find likely corresponding words (e.g., matching 'R' to 'Residuals'). It handles letters and LaTeX commands differently during matching.\n",
    "4.  **Reconstructing Definition:** If a consistent match is found, it rebuilds the definition phrase, preserving original spacing and hyphens.\n",
    "5.  **Validation:** A match is considered valid only if a high enough percentage (e.g., >= 70%) of the abbreviation's components were matched.\n",
    "\n",
    "*(This process uses heuristics, especially for LaTeX, so results may vary.)*\n",
    "\"\"\"\n",
    "\n",
    "# 2. Detailed Description Content\n",
    "detailed_expander_label = \"ⓘ Detailed Algorithm Explanation\"\n",
    "detailed_description_text = \"\"\"\n",
    "This algorithm identifies abbreviations defined as `Full Definition Phrase (Abbr)` within text, including LaTeX, and extracts the phrase.\n",
    "\n",
    "**Core Steps:**\n",
    "\n",
    "1.  **Optional Preprocessing (`normalize_latex_math`):** Standardizes LaTeX comments, math delimiters (`\\\\(...\\\\)` to `\\$...\\$`), spacing around braces/commands.\n",
    "2.  **Candidate Identification (Regex):** Finds `Definition (Abbr)` patterns. Captures preceding words (Group 1, same line only) and the abbreviation (Group 2).\n",
    "3.  **Abbreviation Parsing (`get_abbr_repr_items`):** Creates a list (`abbr_items`) from the abbreviation. Keeps `\\\\commands` as strings, uses initial uppercase letters (ignoring trailing lowercase, e.g., `CPs` -> `c`, `p`), includes standalone lowercase. No Greek mapping.\n",
    "4.  **Preceding Text Tokenization (Split):** Splits preceding words into `words_ahead` using `re.split(r'([ -]+)', ...)`, retaining spaces/hyphens as separate tokens (empty strings removed).\n",
    "5.  **Backward Matching (`find_abbreviation_matches`):** Matches `abbr_items` to `words_ahead` tokens in reverse.\n",
    "    * **Word Analysis (`get_effective_char`):** Derives a single effective character (first letter after heuristic LaTeX stripping) from word tokens for letter-matching.\n",
    "    * **Comparison:** Matches command `abbr_items` if a word token starts with the command (allows leading `\\$`). Matches letter `abbr_items` against a word token's `effective_char`. Skips separator tokens.\n",
    "    * Records `match_indices` (word index for each abbr index, or -1).\n",
    "6.  **Validation:** Calculates the ratio of successfully matched items (`count_matched / num_abbr_items`). Considers the definition valid if this ratio meets/exceeds a `match_threshold` (default 0.7).\n",
    "7.  **Phrase Reconstruction:** If valid, finds the min/max matched word indices, slices `words_ahead` (getting words and separators), and reconstructs the `full_name` using `\"\".join(slice)` to preserve original spacing/hyphens.\n",
    "8.  **Output:** Returns a dictionary mapping abbreviations to their reconstructed definitions.\n",
    "\"\"\"\n",
    "\n",
    "# --- Create Columns and Display Expanders ---\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    with st.expander(summary_expander_label):\n",
    "        st.markdown(summary_explanation_text)\n",
    "\n",
    "with col2:\n",
    "    with st.expander(detailed_expander_label):\n",
    "        st.markdown(detailed_description_text)\n",
    "\n",
    "   \n",
    "   # --- Footer (outside columns) ---\n",
    "st.markdown(\"---\")\n",
    "\n",
    "st.caption(\"Author: Longhai Li, https://longhaisk.github.io, Saskatoon, SK, Canada\")\n",
    "# current_date_param = st.query_params.get('current_date', 'N/A')\n",
    "# st.caption(f\"Current date (from URL param 'current_date', if provided): {current_date_param}\")\n",
    "# st.caption(f\"Actual current server time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (CST)\") # Indicate CST\n",
    "# st.caption(\"Location context: Saskatoon, SK, Canada\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-remove",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
