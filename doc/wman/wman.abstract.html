<html><head>

<title>
Abstract for ``Are Bayesian inferences weak for Wasserman's example?''</title>

</head>

<body>

<h1>
Are Bayesian Inferences Weak for Wasserman's Example?
</h1>

<b>
<a href="/index.html">Longhai Li</a>, Department of Mathematics and Statistics, University of Saskatchewan
</b>

<p>
An example was given in the textbook All of Statistics (Wasserman, 2004, pages 186-188) for arguing that, in the problems with a great many parameters Bayesian inferences are weak, because they relies heavily on the likelihood function that captures information of only a tiny fraction of the total parameters. I have found that this argument is inaccurate and is very misleading to the readers of this textbook. Alternatively he suggested non-Bayesian Horwitz-Thompson estimator, which cannot be obtained from a likelihood-based approaches, including Bayesian approaches. Based on that this estimator is unbiased and consistent, he argued that this estimator is good. In this paper, I compared the mean square errors of this estimator with a Bayes estimator derived from assigning a simple prior for the interested parameter at a wide range of parameter configurations. I also simulated these two estimators to visualize them directly. From these comparisons, I conclude that the simple Bayes estimator works better than Horwitz-Thompson estimator for most parameter configurations. Hence Bayesian inferences are not weak for this example.
<p>

<b>

[<a href="../wman/wman.abstract.html">abstract</a>], 
  
[<a href="../wman/wman-r1-online.pdf">PDF</a>],

[<a href="../wman/ssc10talk.pdf">slides</a>].

</b>

<p>Published in: 
<a href="http://www.informaworld.com/smpp/ftinterface~db=all~content=a919418073~fulltext=713240930">
<i>Communications in Statistics - Simulation and Computation</i>, 
Volume 39, Issue 3 March 2010, pages 655 - 667</a> (PDF).
</p>

<hr>
Back to <a href="../publications.html">Longhai Li's publication page.</a>

</body></html>
