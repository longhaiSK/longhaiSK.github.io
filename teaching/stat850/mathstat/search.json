[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "Preface\nThis is a concise course about statistical inference.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "Statistical Inference",
    "section": "Key Features",
    "text": "Key Features",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introstatinf.html",
    "href": "introstatinf.html",
    "title": "1  Introduction to Statistical Inference",
    "section": "",
    "text": "1.1 Population Model (Data Model)\nWe begin with observations (units) \\(X_1, X_2, \\dots, X_n\\). These may be vectors. We regard these observations as a realization of random variables.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#statistical-inference-setup",
    "href": "introstatinf.html#statistical-inference-setup",
    "title": "1  Introduction to Statistical Inference",
    "section": "",
    "text": "Definition 1.1 (Population Distribution) We assume that \\(X_1, X_2, \\dots, X_n \\sim f(x)\\). The function \\(f(x)\\) is called the population distribution.\n\n\n1.1.1 Assumptions and Scope\nFor simplicity, we often assume the data are Independent and Identically Distributed (i.i.d.). The assumption of identical distribution can be relaxed to regression settings in which the distributions of \\(x_i\\)’s are independent but dependent on covariate \\(x_i\\).\nIn Parametric Statistics, we assume \\(f(x)\\) is of a known analytic form but involves unknown parameters.\n\nExample 1.1 (Parametric Model: Normal) Consider the Normal distribution: \\[f(x; \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\] Here, the parameter space is \\(\\Theta = \\{ (\\mu, \\sigma^2) : \\mu \\in \\mathbb{R}, \\sigma \\in [0, +\\infty) \\}\\). The goal is to learn aspects of the unknown \\(\\theta\\) from observations \\(X_1, \\dots, X_n\\).\n\n\nExample 1.2 (Parametric Model: Bernoulli) Consider a sequence of binary outcomes (e.g., Success/Failure) where each \\(X_i \\in \\{0, 1\\}\\). We assume \\(X_i \\sim \\text{Bernoulli}(\\theta)\\). The probability mass function is: \\[f(x; \\theta) = \\theta^x (1-\\theta)^{1-x}\\] Here, the parameter space is \\(\\Theta = [0, 1]\\), where \\(\\theta\\) represents the probability of success.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#probability-vs.-statistics",
    "href": "introstatinf.html#probability-vs.-statistics",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.2 Probability vs. Statistics",
    "text": "1.2 Probability vs. Statistics\nThere is a fundamental distinction between probability and statistics regarding the parameter \\(\\theta\\). We can visualize this using a “shooting target” analogy:\n\n\\(\\theta\\) (The Center): The true, unknown bullseye location.\n\\(x\\) (The Shots): The observed holes on the target board.\nProbability (Deductive): The center \\(\\theta\\) is known. We predict where the shots \\(x\\) will land.\nStatistics (Inductive): The shots \\(x\\) are observed on the board. The center \\(\\theta\\) is unknown. We hypothesize different potential centers to see which one best explains the shots.\n\n\n\n\n\n\n\n\n\nFigure 1.1: Probability vs Statistics. Left: Probability—The model is fixed (Blue center/contours), generating random data. Right: Statistics—Data is fixed (Black points); we test two hypothesized models: H1 (Green) centered at the sample mean (Good Fit) and H2 (Red) shifted by (1.5, 1.5) (Bad Fit).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#types-of-statistical-inference",
    "href": "introstatinf.html#types-of-statistical-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.4 Types of Statistical Inference",
    "text": "1.4 Types of Statistical Inference\nWe can categorize inference into four main types:\n\nDefinition 1.3 (Point Estimation) We use a single number to capture the parameter. \\[\\hat{\\theta} = \\theta(X_1, \\dots, X_n)\\]\n\n\nExample 1.4 (Estimating Average Height) We want to estimate the average height (\\(\\mu\\)) of all students in a university. We measure 100 students and calculate the sample mean \\(\\bar{x} = 170\\) cm. Our point estimate is \\(\\hat{\\mu} = 170\\).\n\n\nDefinition 1.4 (Interval Estimation) We construct an interval that likely contains the true parameter. \\[\\theta \\in (L(X_1, \\dots, X_n), U(X_1, \\dots, X_n))\\] The true parameter is within this interval.\n\n\nExample 1.5 (Confidence Interval for Height) Using the same height data, we calculate a 95% Confidence Interval. We state: “We are 95% confident that the true average height is between 168 cm and 172 cm.”\n\n\nDefinition 1.5 (Hypothesis Testing) We test a specific theory about the parameter. \\[H_0: \\theta = \\theta_0 \\quad \\text{vs} \\quad H_1: \\theta \\neq \\theta_0\\] (Or one-sided alternatives like \\(\\theta &gt; \\theta_0\\)).\n\n\nExample 1.6 (Testing Soda Volume) A manufacturer claims their soda bottles contain exactly 500ml (\\(H_0: \\mu = 500\\)). We measure a sample and find an average of 495ml. We perform a test to see if this difference is significant enough to reject the manufacturer’s claim.\n\n\nDefinition 1.6 (Predictive Inference) Given observed data \\((X_1, Y_1), \\dots, (X_n, Y_n)\\), we want to predict a new observation \\(Y_{n+1}\\) given \\(X_{n+1}\\). This is often the primary goal in Machine Learning.\n\n\nExample 1.7 (Predicting House Prices) Based on data about house sizes (\\(X\\)) and prices (\\(Y\\)) from the last year, we want to predict the selling price (\\(Y_{n+1}\\)) of a specific new house that is 2000 sq ft (\\(X_{n+1}\\)).\n\nThere are two primary frameworks for how to perform these inferences.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#standard-paradigms-for-inference",
    "href": "introstatinf.html#standard-paradigms-for-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.5 Standard Paradigms for Inference",
    "text": "1.5 Standard Paradigms for Inference\nThere are two primary frameworks for how to perform these inferences.\n\n1.5.1 Frequentist Inference (Fisher)\nDeveloped largely by Fisher (c. 1920).\n\nConcept: The parameter \\(\\theta\\) is a fixed, unknown constant. The data \\(X\\) are random.\nRepeated Sampling Principle: Inference is based on the performance of methods (estimators) under hypothetical repeated sampling of the data.\nSampling Distribution: We analyze how the estimator \\(\\hat{\\theta}\\) behaves over many different datasets generated from the same population.\n\n\n\n\n\n\n\n\n\nFigure 1.3: Frequentist Concept: The Sampling Distribution. The parameter \\(\\theta\\) is fixed (vertical line). The curve represents how the estimator \\(\\hat{\\theta}\\) varies across many hypothetical samples.\n\n\n\n\n\n\n1.5.1.1 Bernoulli Example: Sampling Distribution\nFor our Bernoulli data (\\(x = \\{1, 0, 1\\}\\), \\(n=3\\)), the estimator \\(\\bar{X}\\) is a scaled Binomial variable. If the true parameter were \\(\\theta = 0.5\\), the exact distribution and its Normal approximation would be:\n\n\nCode\ntrue_theta &lt;- 0.5\nn &lt;- 3\nk_vals &lt;- 0:n\nx_bar_vals &lt;- k_vals / n\nprobs &lt;- dbinom(k_vals, size=n, prob=true_theta)\n\ndf_exact &lt;- data.frame(x_bar = x_bar_vals, prob = probs)\n\nx_grid &lt;- seq(-0.2, 1.2, length.out=200)\nsd_approx &lt;- sqrt(true_theta * (1 - true_theta) / n)\nnorm_dens &lt;- dnorm(x_grid, mean=true_theta, sd=sd_approx)\ndf_approx &lt;- data.frame(x = x_grid, density = norm_dens)\n\n# Identify extreme regions for p-value shading (Two-sided: x &gt;= 2/3 and x &lt;= 1/3)\n# Note: 1/3 is symmetric to 2/3 around the mean of 0.5\ndf_shade &lt;- subset(df_approx, x &gt;= 2/3 | x &lt;= 1/3)\n\nggplot() +\n  # 1. Exact Discrete Bars\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob), \n               size=5, color=\"darkgreen\", alpha=0.6) +\n  \n  # 2. Shaded P-value Regions (Normal Approx)\n  geom_area(data=df_shade, aes(x=x, y=density * (1/n)), \n            fill=\"red\", alpha=0.3) +\n  \n  # 3. Normal Approximation Curve\n  geom_line(data=df_approx, aes(x=x, y=density * (1/n)), \n            color=\"red\", size=1.2, linetype=\"dashed\") +\n  \n  # 4. Vertical Line at Observed Mean\n  geom_vline(xintercept = 2/3, color = \"blue\", size = 1, linetype = \"solid\") +\n  annotate(\"text\", x = 2/3, y = -0.02, label = \"Observed\\nbar(x) == 2/3\", \n           parse = TRUE, color = \"blue\", vjust = 1, size = 3.5) +\n  \n  labs(title = expression(paste(\"Sampling Distribution: Transformed Binomial vs. Normal\")),\n       subtitle = expression(paste(\"Testing \", H[0]: theta == 0.5, \" vs \", H[1]: theta != 0.5)),\n       x = expression(bar(x)), y = \"Probability Mass\") +\n  theme_minimal() +\n  # Increase bottom margin for annotation\n  theme(plot.margin = margin(t=10, r=10, b=30, l=10))\n\n\n\n\n\n\n\n\nFigure 1.4: Sampling Distribution of \\(\\bar{X}\\) for \\(n=3\\) assuming true \\(\\theta=0.5\\). The vertical line shows the observed \\(\\bar{x}=2/3\\). The shaded red areas represent the p-value (probability of observing a result as extreme as 2/3 under the Null).\n\n\n\n\n\n\n\n1.5.1.2 Key Questions in Statistical Inference\n\nPoint Estimation\n\nConstruction: How do we construct an estimator for an unknown parameter \\(\\theta\\)? (e.g., Method of Moments, Maximum Likelihood Estimation).\nEvaluation: Which estimator is “better”? How do we compare them? (e.g., Unbiasedness, Minimum Variance, Mean Squared Error, Consistency).\nDistribution: What is the sampling distribution of the estimator? Is it exact or asymptotic (approximate)?\n\n\n\nHypothesis Testing\n\nConstruction: How do we construct a test statistic to decide between hypotheses? (e.g., Likelihood Ratio Test, Wald Test, Score Test).\nDecision Rule: How do we determine the critical region or rejection rule?\nErrors: How do we control the probability of making errors? (Type I vs. Type II errors, Power of the test).\n\n\n\nInterval Estimation\n\nConstruction: How do we construct a confidence interval (or credible interval) that covers the true parameter with high probability?\nDuality: How does interval estimation relate to hypothesis testing? (e.g., Inverting a test statistic).\n\n\n\nPrediction\n\nFuture Observations: How do we account for both the uncertainty in the parameter estimate and the random variation of the new data point?\n\n\n\n\n\n1.5.2 Bayesian Inference\nIn the Bayesian framework, we treat the parameter \\(\\theta\\) as a random variable representing our knowledge/uncertainty.\n\nPrior: We assign a prior distribution \\(\\pi(\\theta)\\) reflecting beliefs before seeing data.\nData Model: We have the likelihood \\(f(x_1, \\ldots, x_n|\\theta)\\).\nPosterior: We compute the posterior distribution using Bayes’ theorem: \\[f(\\theta|x_1, \\ldots, x_n) = \\frac{\\pi(\\theta)f(x_1, \\ldots, x_n|\\theta)}{\\int \\pi(\\theta)f(x_1, \\ldots, x_n|\\theta) d\\theta}\\]\n\nIn this framework, inference is based entirely on the Posterior Distribution, which combines the Prior and the Likelihood.\n\n1.5.2.1 Bernoulli Example: Bayesian Update\nUsing \\(x = \\{1, 0, 1\\}\\) and a weakly informative \\(\\text{Beta}(2,2)\\) prior:\n\nPrior: \\(\\theta \\sim \\text{Beta}(2,2)\\)\nLikelihood: \\(L(\\theta) \\propto \\theta^2(1-\\theta)^1\\)\nPosterior: \\(\\theta|x \\sim \\text{Beta}(2+2, 2+1) = \\text{Beta}(4,3)\\)\n\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nprior &lt;- dbeta(theta_grid, 2, 2)\nposterior &lt;- dbeta(theta_grid, 4, 3)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"Posterior\" = \"blue\", \"Prior\" = \"gray\")) +\n  labs(title = \"Bayesian Updating: Prior vs Posterior\",\n       x = expression(theta), y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.5: Bayesian Updating for Bernoulli Data {1, 0, 1}.\n\n\n\n\n\n\n\n\n1.5.3 Bayesian Prediction\nThe predictive density for a new observation \\(x_{n+1}\\) is obtained by integrating over the posterior: \\[f(x_{n+1}|x) = \\int f(x_{n+1}|\\theta) \\pi(\\theta|x) d\\theta\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "decision.html",
    "href": "decision.html",
    "title": "2  Decision Theory",
    "section": "",
    "text": "2.1 Formulation of Decision Theory\nIn decision theory, we formalize the process of making decisions under uncertainty using the following components:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#decision-rules-and-risk-functions",
    "href": "decision.html#decision-rules-and-risk-functions",
    "title": "2  Decision Theory",
    "section": "2.2 Decision Rules and Risk Functions",
    "text": "2.2 Decision Rules and Risk Functions\n\n2.2.1 Decision Rule\nA decision rule is a function \\(d: \\mathcal{X} \\rightarrow \\mathcal{A}\\). It dictates the action \\(d(x)\\) we take when we observe data \\(x\\).\n\n\n2.2.2 Risk Function\nThe risk function is the expected loss for a given decision rule \\(d\\) as a function of the parameter \\(\\theta\\).\n\\[R(\\theta, d) = E_\\theta[L(\\theta, d(X))]\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#comparing-decision-rules",
    "href": "decision.html#comparing-decision-rules",
    "title": "2  Decision Theory",
    "section": "2.5 Comparing Decision Rules",
    "text": "2.5 Comparing Decision Rules\nWe typically do not have a single rule \\(d\\) that is better than all other rules for all \\(\\theta\\).\n\n\\(d\\) strictly dominates \\(d'\\) if \\(R(\\theta, d) \\le R(\\theta, d')\\) for all \\(\\theta\\), with strict inequality for at least one \\(\\theta\\).\nAdmissibility: A decision rule \\(d\\) is admissible if it is not dominated by any other rule. If it is dominated, it is inadmissible.\n\n\n2.5.1 Minimax Principle\nA rule \\(d\\) is Minimax if it minimizes the maximum possible risk.\n\\[\\sup_{\\theta} R(\\theta, d) \\le \\sup_{\\theta} R(\\theta, d') \\quad \\text{for all } d' \\in \\mathcal{D}\\]\nVisualize the risk functions of two rules, \\(d_1\\) and \\(d_2\\). \\(d_2\\) might have a higher risk in some areas but a lower “peak” risk, making it Minimax.\n\n\n\n\n\n\n\n\nFigure 2.1: Illustration of Minimax: Rule d2 has a lower maximum risk than d1, making it the Minimax rule, even though d1 is better for some values of theta.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#bayes-decision-rules",
    "href": "decision.html#bayes-decision-rules",
    "title": "Decision Theory",
    "section": "2.5 Bayes Decision Rules",
    "text": "2.5 Bayes Decision Rules\nWe specify a prior distribution \\(\\pi(\\theta)\\) on the parameter space \\(\\Theta\\).\n\n2.5.1 Bayes Risk\nThe Bayes risk of a rule \\(d\\) with respect to prior \\(\\pi\\) is the weighted average of the frequentist risk:\n\\[r(\\pi, d) = E_\\pi [R(\\theta, d)] = \\int_\\Theta R(\\theta, d) \\pi(\\theta) d\\theta\\]\n\n\n2.5.2 Bayes Rule Definition\nA decision rule \\(d_\\pi\\) is a Bayes rule with respect to \\(\\pi\\) if it minimizes the Bayes risk:\n\\[r(\\pi, d_\\pi) = \\inf_{d' \\in \\mathcal{D}} r(\\pi, d')\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#randomized-decision-rules-risk-sets",
    "href": "decision.html#randomized-decision-rules-risk-sets",
    "title": "Decision Theory",
    "section": "2.6 Randomized Decision Rules & Risk Sets",
    "text": "2.6 Randomized Decision Rules & Risk Sets\n\n2.6.1 Randomized Rules\nA randomized decision rule chooses between deterministic rules \\(d_1, d_2, \\dots\\) with probabilities \\(p_1, p_2, \\dots\\). The risk of a randomized rule \\(d^* = \\sum p_i d_i\\) is the linear combination of their risks: \\[R(\\theta, d^*) = \\sum p_i R(\\theta, d_i)\\]\n\n\n2.6.2 Geometric Interpretation (Finite Parameter Space)\nIf \\(\\Theta = \\{\\theta_1, \\theta_2, \\dots, \\theta_k\\}\\) is finite, we can plot the risk vector \\((R(\\theta_1, d), \\dots, R(\\theta_k, d))\\) in \\(\\mathbb{R}^k\\).\nRisk Set (\\(S\\)): The set of all possible risk vectors. Lemma: The Risk Set \\(S\\) is convex. This is because we can form randomized rules that lie on the line segment connecting any two deterministic rules.\n\n\n\n\n\n\n\n\nFigure 2.3: The Risk Set S. Points d1 and d2 are deterministic rules. The line connecting them represents randomized rules. The Minimax rule lies on the line R1=R2 (if accessible). The Bayes rule is found by bringing a tangent line with slope -pi1/pi2 toward the origin.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#example-the-great-aunts-necklace",
    "href": "decision.html#example-the-great-aunts-necklace",
    "title": "2  Decision Theory",
    "section": "2.6 Example: The “Great Aunt’s Necklace”",
    "text": "2.6 Example: The “Great Aunt’s Necklace”\nScenario: Two boxes. One contains a real necklace (\\(\\theta=1\\)), the other an imitation (\\(\\theta=2\\)). Loss is 1 if we choose the wrong box, 0 otherwise.\n\n\\(\\theta \\in \\{1, 2\\}\\)\nAction \\(a \\in \\{1, 2\\}\\) (Choose Box 1 or Box 2)\n\nData (\\(X\\)): Great Aunt’s judgment. \\(X \\in \\{1, 2\\}\\) (Aunt says Box 1 or Box 2). Probabilities: * If \\(\\theta=1\\) (Real in Box 1): Aunt is senile. \\(P(X=1)=1, P(X=2)=0\\). * If \\(\\theta=2\\) (Real in Box 2): Aunt guesses. \\(P(X=1)=0.5, P(X=2)=0.5\\).\nDecision Rules: 1. \\(d_1\\): Always choose Box 1. 2. \\(d_2\\): Always choose Box 2. 3. \\(d_3(x) = x\\): Follow Aunt’s advice. 4. \\(d_4(x) = 3-x\\): Do opposite of Aunt.\nRisk Calculation:\n\n\n\nRule\n\\(R(\\theta=1)\\)\n\\(R(\\theta=2)\\)\nCoordinates \\((R_1, R_2)\\)\n\n\n\n\n\\(d_1\\)\n0\n1\n(0, 1)\n\n\n\\(d_2\\)\n1\n0\n(1, 0)\n\n\n\\(d_3\\)\n0\n0.5\n(0, 0.5)\n\n\n\\(d_4\\)\n1\n0.5\n(1, 0.5)\n\n\n\nGeometry and Minimax: The risk set is the convex hull of these four points.\n\n\n\n\n\n\n\n\nFigure 2.3: Risk Set for the Necklace Example. The set is the quadrilateral defined by d1, d2, d3, d4. The Minimax rule is the intersection of the line R1=R2 and the lower boundary segment connecting d3 and d2.\n\n\n\n\n\nCalculation of Minimax Rule: The lower boundary connects \\(d_3 (0, 0.5)\\) and \\(d_2 (1, 0)\\). Equation of line: \\(R_2 - 0 = \\frac{0.5 - 0}{0 - 1} (R_1 - 1) \\Rightarrow R_2 = -0.5(R_1 - 1)\\). For Minimax, set \\(R_1 = R_2 = R\\). \\(R = -0.5R + 0.5 \\Rightarrow 1.5R = 0.5 \\Rightarrow R = 1/3\\). The minimax rule is a randomized combination: \\(d^* = \\frac{2}{3}d_3 + \\frac{1}{3}d_2\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#theorems-relating-minimax-and-bayes",
    "href": "decision.html#theorems-relating-minimax-and-bayes",
    "title": "2  Decision Theory",
    "section": "2.7 Theorems relating Minimax and Bayes",
    "text": "2.7 Theorems relating Minimax and Bayes\nTheorem 2.1: If a sequence of Bayes rules \\(\\delta_n\\) has Bayes risk converging to \\(C\\), and \\(R(\\theta, \\delta_0) \\le C\\) for all \\(\\theta\\), then \\(\\delta_0\\) is Minimax.\nTheorem 2.2 (Equalizer Rule): An Extended Bayes rule that is an equalizer rule (constant risk across all \\(\\theta\\)) must be Minimax.\nTheorem 2.3: Assume that the parameter space \\(\\Theta\\) is finite, and that the prior \\(\\pi(\\theta)\\) gives positive probability to each \\(\\theta_i\\). Then, a Bayes rule with respect to \\(\\pi\\) is admissible.\nTheorem 2.4: If a Bayes rule is unique, it is admissible.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#formulation-of-decision-theory",
    "href": "decision.html#formulation-of-decision-theory",
    "title": "2  Decision Theory",
    "section": "",
    "text": "Parameter Space (\\(\\Theta\\)): The set of all possible states of nature or values that the parameter can take. \\(\\theta \\in \\Theta\\) (e.g., mean, variance).\nSample Space (\\(\\mathcal{X}\\)): The space where the data \\(X\\) lies. Example: \\(X = (X_1, X_2, \\dots, X_n)\\) where \\(X_i \\in \\mathbb{R}\\). So \\(\\mathcal{X} \\in \\mathbb{R}^n\\).\nFamily of Probability Distributions: \\(\\{P_\\theta(x) : \\theta \\in \\Theta\\}\\). This describes how likely we are to see the data \\(X\\) given a specific parameter \\(\\theta\\).\n\nIf \\(X\\) is continuous: \\(P_\\theta(x) = f(x, \\theta)\\) (Probability Density Function).\nIf \\(X\\) is discrete: \\(P_\\theta(x) = f(x, \\theta)\\) (Probability Mass Function).\n\nAction Space (\\(\\mathcal{A}\\)): The set of all actions or decisions available to the experimenter.\nLoss Function: \\(L: \\Theta \\times \\mathcal{A} \\rightarrow \\mathbb{R}\\). \\(L(\\theta, a)\\) specifies the loss incurred if the true parameter is \\(\\theta\\) and we take action \\(a\\). Generally, \\(L(\\theta, a) \\ge 0\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "bayesian.html",
    "href": "bayesian.html",
    "title": "3  Bayesian Methods",
    "section": "",
    "text": "3.1 Bayes Theorem\nSuppose \\(\\theta \\sim \\pi(\\theta)\\) and \\(X \\sim f(x; \\theta)\\). The posterior density of \\(\\theta\\) given \\(X\\) is:\n\\[\n\\pi(\\theta|x) = \\frac{\\pi(\\theta) f(x;\\theta)}{\\int_{\\Theta} \\pi(\\theta) f(x;\\theta) d\\theta} \\propto \\pi(\\theta) \\cdot L(\\theta; x)\n\\]\nwhere \\(L(\\theta; x)\\) is the likelihood.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#examples",
    "href": "bayesian.html#examples",
    "title": "3  Bayesian Methods",
    "section": "3.2 Examples",
    "text": "3.2 Examples\n\n3.2.1 1. Binomial-Beta\n\n\\(X|\\theta \\sim \\text{Bin}(n, \\theta) \\Rightarrow f(x|\\theta) = \\binom{n}{x} \\theta^x (1-\\theta)^{n-x}\\)\nPrior \\(\\theta \\sim \\text{Beta}(a, b) \\Rightarrow \\pi(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\\)\n\nPosterior: \\[\n\\pi(\\theta|x) \\propto \\theta^{a-1}(1-\\theta)^{b-1} \\cdot \\theta^x (1-\\theta)^{n-x} = \\theta^{a+x-1} (1-\\theta)^{b+n-x-1}\n\\]\nSo, \\(\\theta|x \\sim \\text{Beta}(a+x, b+n-x)\\).\nMoments: * Mean: \\(E(\\theta|x) = \\frac{a+x}{a+b+n} \\approx \\frac{x}{n}\\) (for small \\(n\\)) * Variance: \\(\\text{Var}(\\theta|x) = \\frac{(a+x)(b+n-x)}{(a+b+n)^2(a+b+n+1)}\\)\n\n\n3.2.2 2. Normal-Normal (Known Variance)\n\n\\(X_1, \\dots, X_n \\sim N(\\mu, \\sigma^2)\\) where \\(\\sigma^2\\) is known.\nPrior \\(\\mu \\sim N(\\mu_0, \\sigma_0^2)\\).\n\nLet \\(\\tau_0 = 1/\\sigma_0^2\\) (prior precision), \\(\\tau = 1/\\sigma^2\\) (data precision). The posterior precision is \\(\\tau_1 = \\tau_0 + n\\tau\\).\nPosterior: \\[\n\\mu|x \\sim N\\left( \\frac{\\tau_0 \\mu_0 + n\\tau \\bar{x}}{\\tau_0 + n\\tau}, \\frac{1}{\\tau_0 + n\\tau} \\right)\n\\]\nThis shows the posterior mean is a weighted average of the prior mean and the sample mean.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#squared-error-loss-ltheta-a-theta---a2",
    "href": "bayesian.html#squared-error-loss-ltheta-a-theta---a2",
    "title": "3  Bayesian Methods",
    "section": "4.1 1. Squared Error Loss: \\(L(\\theta, a) = (\\theta - a)^2\\)",
    "text": "4.1 1. Squared Error Loss: \\(L(\\theta, a) = (\\theta - a)^2\\)\nMinimizing \\(E_{\\theta|x}[(\\theta - d)^2]\\) leads to: \\[\nd(x) = E(\\theta|x) \\quad \\text{(Posterior Mean)}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#absolute-error-loss-ltheta-a-theta---a",
    "href": "bayesian.html#absolute-error-loss-ltheta-a-theta---a",
    "title": "3  Bayesian Methods",
    "section": "4.2 2. Absolute Error Loss: \\(L(\\theta, a) = |\\theta - a|\\)",
    "text": "4.2 2. Absolute Error Loss: \\(L(\\theta, a) = |\\theta - a|\\)\nMinimizing \\(E_{\\theta|x}[|\\theta - d|]\\) leads to: \\[\n\\int_{-\\infty}^d \\pi(\\theta|x) d\\theta = \\int_{d}^{\\infty} \\pi(\\theta|x) d\\theta = 0.5\n\\] So, \\(d(x) = \\text{Median of } \\pi(\\theta|x)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#loss-hypothesis-testing",
    "href": "bayesian.html#loss-hypothesis-testing",
    "title": "3  Bayesian Methods",
    "section": "4.3 3. 0-1 Loss (Hypothesis Testing)",
    "text": "4.3 3. 0-1 Loss (Hypothesis Testing)\n\nLoss is 1 if error, 0 if correct.\nTesting \\(\\Theta_0\\) vs \\(\\Theta_1\\).\nBayes Rule: Choose class with highest posterior probability.\n\nReject \\(H_0\\) if \\(P(\\theta \\in \\Theta_1 | x) &gt; P(\\theta \\in \\Theta_0 | x)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#interval-estimation",
    "href": "bayesian.html#interval-estimation",
    "title": "3  Bayesian Methods",
    "section": "4.4 4. Interval Estimation",
    "text": "4.4 4. Interval Estimation\nWe want an interval \\(A = (d-\\delta, d+\\delta)\\) minimizing risk (maximizing coverage probability \\(1-\\alpha\\)).\nHighest Posterior Density (HPD) Interval: The set \\(C = \\{ \\theta : \\pi(\\theta|x) \\ge k \\}\\) where \\(P(\\theta \\in C|x) = 1-\\alpha\\). This is the shortest interval for a given confidence level if the posterior is unimodal.\n\n\nCode\nlibrary(ggplot2)\n\nx &lt;- seq(0, 15, length.out = 1000)\ny &lt;- dgamma(x, shape = 3, rate = 0.5)\ndf &lt;- data.frame(x = x, y = y)\n\n# Approximate HPD cutoff (visual)\nhpd_level &lt;- 0.05\ncutoff &lt;- 0.08 # Chosen for visual representation of the cut\n\nggplot(df, aes(x, y)) +\n  geom_line(size = 1) +\n  geom_area(data = subset(df, y &gt; cutoff), fill = \"skyblue\", alpha = 0.5) +\n  geom_hline(yintercept = cutoff, linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = 10, y = cutoff + 0.02, label = \"HPD Cutoff line\", color = \"red\") +\n  labs(title = \"Highest Posterior Density (HPD) Interval\", \n       subtitle = \"Points with density higher than the red line form the HPD set\",\n       x = \"Theta\", y = \"Posterior Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 4.1: Illustration of Highest Posterior Density (HPD) Interval vs Equi-tailed Interval on a skewed posterior.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#baseball-example-efron-morris",
    "href": "bayesian.html#baseball-example-efron-morris",
    "title": "3  Bayesian Methods",
    "section": "6.1 Baseball Example (Efron & Morris)",
    "text": "6.1 Baseball Example (Efron & Morris)\nWe observe batting averages for \\(p=18\\) players. * MLE: Individual batting averages. * JS: Shrinks individual averages toward the global average.\n\n\nCode\n# Creating mock data similar to the baseball example\nplayer &lt;- 1:10\nMLE &lt;- c(0.400, 0.370, 0.350, 0.300, 0.280, 0.250, 0.220, 0.200, 0.150, 0.100)\nGrandMean &lt;- mean(MLE)\nshrinkage_factor &lt;- 0.6 # c = 1 - (p-2)/S\nJS &lt;- GrandMean + shrinkage_factor * (MLE - GrandMean)\n\ndf_base &lt;- data.frame(player, MLE, JS)\n\nggplot(df_base) +\n  geom_point(aes(x = MLE, y = 1), color = \"red\", size = 3) +\n  geom_point(aes(x = JS, y = 1), color = \"blue\", size = 3) +\n  geom_segment(aes(x = MLE, y = 1, xend = JS, yend = 1), arrow = arrow(length = unit(0.2, \"cm\"))) +\n  geom_vline(xintercept = GrandMean, linetype = \"dashed\") +\n  annotate(\"text\", x = GrandMean, y = 1.1, label = \"Grand Mean\") +\n  ylim(0.9, 1.2) +\n  labs(title = \"James-Stein Shrinkage Effect\", \n       subtitle = \"Red: MLE, Blue: JS Estimator\",\n       x = \"Batting Average\") +\n  theme_void() +\n  theme(axis.title.x = element_text(), axis.text.x = element_text())\n\n\n\n\n\n\n\n\nFigure 6.1: Visualizing James-Stein Shrinkage (Mock Data based on Baseball Example). The arrows show MLEs being pulled toward the Grand Mean.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#empirical-bayes",
    "href": "bayesian.html#empirical-bayes",
    "title": "3  Bayesian Methods",
    "section": "7.1 Empirical Bayes",
    "text": "7.1 Empirical Bayes\nInstead of fixing hyperparameters \\((\\mu_0, \\sigma_0^2)\\), we estimate them from the marginal distribution of the data. \\[\nm(x) = \\int f(x|\\theta) \\pi(\\theta|\\eta) d\\theta\n\\] We estimate \\(\\eta\\) by maximizing \\(m(x)\\) (Type-II MLE) or method of moments.\nExample: If \\(X_i \\sim N(\\mu_i, 1)\\) and \\(\\mu_i \\sim N(0, \\tau^2)\\), then marginally \\(X_i \\sim N(0, 1+\\tau^2)\\). We can use \\(S = \\sum X_i^2\\) to estimate \\(\\tau^2\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "bayesian.html#hierarchical-models",
    "href": "bayesian.html#hierarchical-models",
    "title": "3  Bayesian Methods",
    "section": "7.2 Hierarchical Models",
    "text": "7.2 Hierarchical Models\nWe assume a multistage structure: 1. Data model: \\(X|\\theta \\sim f(x|\\theta)\\) 2. Parameter model: \\(\\theta|\\lambda \\sim \\pi(\\theta|\\lambda)\\) 3. Hyperparameter model: \\(\\lambda \\sim h(\\lambda)\\)\nComputation: Since analytical solutions are often impossible, we use Markov Chain Monte Carlo (MCMC).\n\n7.2.1 Gibbs Sampling\nTo sample from the joint posterior \\(f(\\theta, \\lambda | x)\\), we sample iteratively from the full conditional distributions: 1. Draw \\(\\theta^{(k+1)} \\sim f(\\theta | \\lambda^{(k)}, x)\\) 2. Draw \\(\\lambda^{(k+1)} \\sim f(\\lambda | \\theta^{(k+1)}, x)\\)\n\n\n7.2.2 Metropolis-Hastings\nIf a conditional distribution is hard to sample from directly: 1. Propose \\(\\theta^*\\) from a proposal density \\(q(\\theta^* | \\theta^{(t)})\\). 2. Calculate acceptance ratio \\(\\alpha = \\min \\left( 1, \\frac{f(\\theta^*|x)q(\\theta^{(t)}|\\theta^*)}{f(\\theta^{(t)}|x)q(\\theta^*|\\theta^{(t)})} \\right)\\). 3. Accept \\(\\theta^*\\) with probability \\(\\alpha\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Methods</span>"
    ]
  },
  {
    "objectID": "decision.html#examples-of-decision-problems",
    "href": "decision.html#examples-of-decision-problems",
    "title": "2  Decision Theory",
    "section": "2.3 Examples of Decision Problems",
    "text": "2.3 Examples of Decision Problems\n\n2.3.1 Example 1: Hypothesis Testing\nWe want to test \\(H_0\\) vs \\(H_1\\).\n\nAction Space: \\(\\mathcal{A} = \\{0, 1\\}\\) (0=“Accept \\(H_0\\)”, 1=“Reject \\(H_0\\)”).\nLoss Function (0-1 Loss): 0 if correct, 1 if wrong.\nRisk Function:\n\nIf \\(\\theta \\in H_0\\): \\(R(\\theta, d) = P(\\text{Type I Error})\\).\nIf \\(\\theta \\in H_1\\): \\(R(\\theta, d) = P(\\text{Type II Error})\\).\n\n\n\n\n2.3.2 Example 2: Point Estimation\nWe want to estimate a parameter \\(\\theta\\).\n\nAction Space: \\(\\mathcal{A} = \\Theta\\).\nLoss Function (Squared Error): \\(L(\\theta, a) = (\\theta - a)^2\\).\nRisk Function (MSE): \\(R(\\theta, d) = \\text{Var}(\\bar{x}) + \\text{Bias}^2\\).\n\n\n\n2.3.3 Example 3: Interval Estimation\nWe want to estimate a range for the parameter.\n\nAction Space: \\(\\mathcal{A} = \\{(l, u) : l \\in \\mathbb{R}, u \\in \\mathbb{R}, l \\le u\\}\\).\n\n\n\n2.3.4 Example 4: The Duchess and the Emerald Necklace\nScenario: You are the Duchess of Omnium. You have two necklaces: a priceless Real one and a valueless Imitation. They are indistinguishable to you. One is in the Left Drawer (Box 1), the other is in the Right Drawer (Box 2).\nThe Data (Great Aunt): You consult your Great Aunt. She inspects the Left Drawer first, then the Right.\n\nIf the Real necklace is in the Left (\\(\\theta=1\\)): She identifies it correctly. (Infallible).\nIf the Real necklace is in the Right (\\(\\theta=2\\)): She sees the fake first, gets confused, and guesses randomly (\\(50/50\\)).\n\n\n2.3.4.1 Formulation\n\nParameter Space: \\(\\Theta = \\{1, 2\\}\\) (1=Real Left, 2=Real Right).\nAction Space: \\(\\mathcal{A} = \\{1, 2\\}\\) (1=Wear Left, 2=Wear Right).\nLoss Function: 0 if correct, 1 if wrong.\n\n\n\n2.3.4.2 Risk Calculation for Deterministic Rules\nWe consider four deterministic rules \\(d(X)\\). We calculate the risk (\\(R_1\\) for \\(\\theta=1\\) and \\(R_2\\) for \\(\\theta=2\\)) for each.\nRule \\(d_1\\) (Always Left)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nLoss \\(L(1, d)\\)\n0\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\\(R_1 = 0\\)\n\n\n\\(\\theta=2\\)\nLoss \\(L(2, d)\\)\n1\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\\(R_2 = 1\\)\n\n\n\nRule \\(d_2\\) (Always Right)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nLoss \\(L(1, d)\\)\n1\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\\(R_1 = 1\\)\n\n\n\\(\\theta=2\\)\nLoss \\(L(2, d)\\)\n0\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\\(R_2 = 0\\)\n\n\n\nRule \\(d_3\\) (Follow Aunt)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nLoss \\(L(1, d)\\)\n0\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\\(R_1 = 0\\)\n\n\n\\(\\theta=2\\)\nLoss \\(L(2, d)\\)\n1\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\\(R_2 = 0.5\\)\n\n\n\nRule \\(d_4\\) (Do Opposite)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nLoss \\(L(1, d)\\)\n1\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\\(R_1 = 1\\)\n\n\n\\(\\theta=2\\)\nLoss \\(L(2, d)\\)\n0\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\\(R_2 = 0.5\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#example-the-duchess-and-the-emerald-necklace",
    "href": "decision.html#example-the-duchess-and-the-emerald-necklace",
    "title": "2  Decision Theory",
    "section": "2.5 Example: The Duchess and the Emerald Necklace",
    "text": "2.5 Example: The Duchess and the Emerald Necklace\nScenario: You are the Duchess of Omnium. You have two necklaces: a priceless Real one and a valueless Imitation. They are indistinguishable to you. One is in the Left Drawer (Box 1), the other is in the Right Drawer (Box 2).\nThe Data (Great Aunt): You consult your Great Aunt. She inspects the Left Drawer first, then the Right.\n\nIf the Real necklace is in the Left (\\(\\theta=1\\)): She identifies it correctly. (Infallible).\nIf the Real necklace is in the Right (\\(\\theta=2\\)): She sees the fake first, gets confused, and guesses randomly (\\(50/50\\)).\n\n\n2.5.1 Formulation\n\nParameter Space: \\(\\Theta = \\{1, 2\\}\\) (1=Real Left, 2=Real Right).\nAction Space: \\(\\mathcal{A} = \\{1, 2\\}\\) (1=Wear Left, 2=Wear Right).\nData: \\(X \\in \\{1, 2\\}\\) (Aunt says Left/Right).\nLoss Function: 0 if correct, 1 if wrong.\n\n\n\n2.5.2 Probability of Data Given Parameter (\\(P_\\theta(X)\\))\n\n\n\n\nState \\(\\theta=1\\)\n\nState \\(\\theta=2\\)\n\n\n\n\n\nOutcome\n\\(X=1\\)\n\\(X=2\\)\n\\(X=1\\)\n\\(X=2\\)\n\n\nProbability\n1\n0\n0.5\n0.5\n\n\n\n\n\n2.5.3 Decision Rules\nWe consider four deterministic rules \\(d(X)\\).\n\n\n\nRule\nDescription\nAction if \\(X=1\\)\nAction if \\(X=2\\)\n\n\n\n\n\\(d_1\\)\nAlways Left\n1\n1\n\n\n\\(d_2\\)\nAlways Right\n2\n2\n\n\n\\(d_3\\)\nFollow Aunt\n1\n2\n\n\n\\(d_4\\)\nDo Opposite\n2\n1\n\n\n\n\n\n2.5.4 Risk Calculation Tables\nFor each rule, we calculate the risk (\\(R_1\\) for \\(\\theta=1\\) and \\(R_2\\) for \\(\\theta=2\\)).\n\n2.5.4.1 Rule \\(d_1\\) (Always Left)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nAction \\(d_1(X)\\)\n1\n1\n\n\n\n\nLoss \\(L(1, d)\\)\n0\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\n\n\n\nProduct\n0\n0\n\\(R_1 = 0\\)\n\n\n\\(\\theta=2\\)\nAction \\(d_1(X)\\)\n1\n1\n\n\n\n\nLoss \\(L(2, d)\\)\n1\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\n\n\n\nProduct\n0.5\n0.5\n\\(R_2 = 1\\)\n\n\n\n\n\n2.5.4.2 Rule \\(d_2\\) (Always Right)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nAction \\(d_2(X)\\)\n2\n2\n\n\n\n\nLoss \\(L(1, d)\\)\n1\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\n\n\n\nProduct\n1\n0\n\\(R_1 = 1\\)\n\n\n\\(\\theta=2\\)\nAction \\(d_2(X)\\)\n2\n2\n\n\n\n\nLoss \\(L(2, d)\\)\n0\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\n\n\n\nProduct\n0\n0\n\\(R_2 = 0\\)\n\n\n\n\n\n2.5.4.3 Rule \\(d_3\\) (Follow Aunt)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nAction \\(d_3(X)\\)\n1\n2\n\n\n\n\nLoss \\(L(1, d)\\)\n0\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\n\n\n\nProduct\n0\n0\n\\(R_1 = 0\\)\n\n\n\\(\\theta=2\\)\nAction \\(d_3(X)\\)\n1\n2\n\n\n\n\nLoss \\(L(2, d)\\)\n1\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\n\n\n\nProduct\n0.5\n0\n\\(R_2 = 0.5\\)\n\n\n\n\n\n2.5.4.4 Rule \\(d_4\\) (Do Opposite)\n\n\n\nState\nComponent\n\\(X=1\\)\n\\(X=2\\)\nRisk (Sum)\n\n\n\n\n\\(\\theta=1\\)\nAction \\(d_4(X)\\)\n2\n1\n\n\n\n\nLoss \\(L(1, d)\\)\n1\n0\n\n\n\n\nProb \\(P(X \\mid \\theta=1)\\)\n1\n0\n\n\n\n\nProduct\n1\n0\n\\(R_1 = 1\\)\n\n\n\\(\\theta=2\\)\nAction \\(d_4(X)\\)\n2\n1\n\n\n\n\nLoss \\(L(2, d)\\)\n0\n1\n\n\n\n\nProb \\(P(X \\mid \\theta=2)\\)\n0.5\n0.5\n\n\n\n\nProduct\n0\n0.5\n\\(R_2 = 0.5\\)\n\n\n\n\n\n\n2.5.5 Application of Geometric Analysis to Necklace Problem\nWe plot the risks calculated above:\n\n\\(d_1\\): \\((0, 1)\\)\n\\(d_2\\): \\((1, 0)\\)\n\\(d_3\\): \\((0, 0.5)\\)\n\\(d_4\\): \\((1, 0.5)\\)\n\nFrom the plot below, we can see that the admissible boundary connects \\(d_3\\) and \\(d_2\\). The Minimax rule is a randomized mixture of these two.\n\n\n\n\n\n\n\n\nFigure 2.2: Risk Set for the Necklace Problem. The Minimax rule is found at the intersection of y=x and the lower boundary. The orange and green lines represent Bayes risks for different priors.\n\n\n\n\n\n\n\n2.5.6 Finding the Minimax Weights\nThe minimax rule lies on the boundary connecting \\(d_3\\) and \\(d_2\\). \\[R(\\delta^*) = p R(d_3) + (1-p) R(d_2) = p \\begin{pmatrix} 0 \\\\ 0.5 \\end{pmatrix} + (1-p) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1-p \\\\ 0.5p \\end{pmatrix}\\] Setting \\(R_1 = R_2\\): \\[1-p = 0.5p \\implies 1 = 1.5p \\implies p = 2/3\\] The Minimax strategy is to choose \\(d_3\\) with probability \\(2/3\\) and \\(d_2\\) with probability \\(1/3\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#formulation-of-the-decision-problem",
    "href": "decision.html#formulation-of-the-decision-problem",
    "title": "2  Decision Theory",
    "section": "2.5 Formulation of the Decision Problem",
    "text": "2.5 Formulation of the Decision Problem\n\n2.5.1 Parameter Space (\\(\\Theta\\))\nThe set of possible states of nature regarding the location of the real necklace:\n\n\\(\\theta_1\\): The Real necklace is in the Left Drawer.\n\\(\\theta_2\\): The Real necklace is in the Right Drawer.\n\n\n\n2.5.2 Action Space (\\(\\mathcal{A}\\))\nThe set of possible actions available to the Duchess:\n\n\\(a_1\\): Wear the Left necklace.\n\\(a_2\\): Wear the Right necklace.\n\n\n\n2.5.3 The Data (\\(X\\))\nThe data consists of the Great Aunt’s judgment after inspecting the necklaces:\n\n\\(X \\in \\{1, 2\\}\\)\n\\(X=1\\): Aunt says “Left is Real”.\n\\(X=2\\): Aunt says “Right is Real”.\n\n\n\n2.5.4 Probability of Data Given Parameter (\\(P_\\theta(X)\\))\nThe probability of the Aunt’s advice changes depending on the true state of nature (\\(\\theta\\)).\n\n\n\nState\n\\(P(X=1 \\mid \\theta)\\)\n\\(P(X=2 \\mid \\theta)\\)\n\n\n\n\n\\(\\theta_1\\) (Real Left)\n1\n0\n\n\n\\(\\theta_2\\) (Real Right)\n0.5\n0.5\n\n\n\n\n\n2.5.5 Loss Function (\\(L\\))\nThe loss is defined as 0 for a correct choice and 1 (representing £1M) for an incorrect choice.\n\n\n\nState  Action\n\\(a_1\\) (Wear Left)\n\\(a_2\\) (Wear Right)\n\n\n\n\n\\(\\theta_1\\) (Real Left)\n0\n1\n\n\n\\(\\theta_2\\) (Real Right)\n1\n0\n\n\n\n\n\n2.5.6 Decision Rules\nThere are four possible deterministic decision rules (\\(d: \\mathcal{X} \\rightarrow \\mathcal{A}\\)).\n\n\n\n\n\n\n\n\n\nRule\nDescription\nAction if \\(X=1\\) (Left)\nAction if \\(X=2\\) (Right)\n\n\n\n\n\\(d_1\\)\nAlways Left\n\\(a_1\\)\n\\(a_1\\)\n\n\n\\(d_2\\)\nAlways Right\n\\(a_2\\)\n\\(a_2\\)\n\n\n\\(d_3\\)\nFollow Aunt\n\\(a_1\\)\n\\(a_2\\)\n\n\n\\(d_4\\)\nDo Opposite\n\\(a_2\\)\n\\(a_1\\)\n\n\n\n\n\n2.5.7 Risk Calculation\nBelow are the risk calculation tables for each decision rule.\n\n2.5.7.1 Rule \\(d_1\\) (Always Left)\n\n\n\n\n\n\n\n\n\n\nState\nMetric\n\\(X=1\\)\n\\(X=2\\)\nRisk Calculation\n\n\n\n\n\\(\\theta_1\\)\nLoss\n0\n0\n\\(R(\\theta_1) = (0 \\times 1) + (0 \\times 0)\\)\n\n\n\nProb\n1\n0\n\\(= 0\\)\n\n\n\\(\\theta_2\\)\nLoss\n1\n1\n\\(R(\\theta_2) = (1 \\times 0.5) + (1 \\times 0.5)\\)\n\n\n\nProb\n0.5\n0.5\n\\(= 1\\)\n\n\n\n\n\n2.5.7.2 Rule \\(d_2\\) (Always Right)\n\n\n\n\n\n\n\n\n\n\nState\nMetric\n\\(X=1\\)\n\\(X=2\\)\nRisk Calculation\n\n\n\n\n\\(\\theta_1\\)\nLoss\n1\n1\n\\(R(\\theta_1) = (1 \\times 1) + (1 \\times 0)\\)\n\n\n\nProb\n1\n0\n\\(= 1\\)\n\n\n\\(\\theta_2\\)\nLoss\n0\n0\n\\(R(\\theta_2) = (0 \\times 0.5) + (0 \\times 0.5)\\)\n\n\n\nProb\n0.5\n0.5\n\\(= 0\\)\n\n\n\n\n\n2.5.7.3 Rule \\(d_3\\) (Follow Aunt)\n\n\n\n\n\n\n\n\n\n\nState\nMetric\n\\(X=1\\)\n\\(X=2\\)\nRisk Calculation\n\n\n\n\n\\(\\theta_1\\)\nLoss\n0\n1\n\\(R(\\theta_1) = (0 \\times 1) + (1 \\times 0)\\)\n\n\n\nProb\n1\n0\n\\(= 0\\)\n\n\n\\(\\theta_2\\)\nLoss\n1\n0\n\\(R(\\theta_2) = (1 \\times 0.5) + (0 \\times 0.5)\\)\n\n\n\nProb\n0.5\n0.5\n\\(= 0.5\\)\n\n\n\n\n\n2.5.7.4 Rule \\(d_4\\) (Do Opposite)\n\n\n\n\n\n\n\n\n\n\nState\nMetric\n\\(X=1\\)\n\\(X=2\\)\nRisk Calculation\n\n\n\n\n\\(\\theta_1\\)\nLoss\n1\n0\n\\(R(\\theta_1) = (1 \\times 1) + (0 \\times 0)\\)\n\n\n\nProb\n1\n0\n\\(= 1\\)\n\n\n\\(\\theta_2\\)\nLoss\n0\n1\n\\(R(\\theta_2) = (0 \\times 0.5) + (1 \\times 0.5)\\)\n\n\n\nProb\n0.5\n0.5\n\\(= 0.5\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#geometric-interpretation-and-principles",
    "href": "decision.html#geometric-interpretation-and-principles",
    "title": "2  Decision Theory",
    "section": "2.4 Geometric Interpretation and Principles",
    "text": "2.4 Geometric Interpretation and Principles\nWhen the parameter space is finite (e.g., \\(\\Theta = \\{1, 2\\}\\)), the risk function \\(R(\\theta, d)\\) can be represented as a point in \\(\\mathbb{R}^2\\) with coordinates \\((R_1, R_2) = (R(\\theta_1, d), R(\\theta_2, d))\\). This geometric perspective allows us to visualize fundamental concepts like Admissibility, Minimax, and Bayes rules.\n\n2.4.1 The Risk Set (\\(S\\))\nThe Risk Set \\(S\\) represents the collection of risk vectors for all possible decision rules.\n\nDeterministic Rules: These form the vertices (corners) of the set.\nRandomized Rules: If we mix two rules \\(d_1\\) and \\(d_2\\) with probabilities \\(p\\) and \\((1-p)\\), the resulting risk lies on the straight line segment connecting \\(R(d_1)\\) and \\(R(d_2)\\).\nConvexity: Because we can randomize between any rules, the Risk Set \\(S\\) is the convex hull of the deterministic rules. It typically forms a polygon filled with all possible randomized strategies.\n\n\n\n2.4.2 Admissibility (The Efficient Frontier)\nWe always prefer a lower risk.\n\nA rule \\(d\\) dominates rule \\(d'\\) if \\(R(\\theta, d) \\le R(\\theta, d')\\) for all \\(\\theta\\), with strict inequality for at least one \\(\\theta\\). Geometrically, this means \\(d\\) is to the “south-west” of \\(d'\\).\nA rule is Admissible if it is not dominated.\nThe set of admissible rules forms the lower-left boundary of the Risk Set \\(S\\). This is often called the “efficient frontier.”\n\n\n\n2.4.3 Finding the Minimax Rule\nThe Minimax principle seeks to minimize the maximum possible risk: \\(\\min_d [\\max(R_1, R_2)]\\).\n\nGeometrically, points of constant maximum risk (\\(\\max(R_1, R_2) = k\\)) form “L-shaped” right angles centered on the line \\(R_1 = R_2\\).\nTo find the Minimax rule, we find the intersection of the Risk Set \\(S\\) with the \\(45^\\circ\\) line \\(y = x\\) (\\(R_1 = R_2\\)).\nThe intersection point on the lower boundary of \\(S\\) is the Minimax rule.\n\n\n\n2.4.4 Finding the Bayes Rule\nA Bayes rule minimizes the weighted sum of risks for a given prior \\(\\pi = (\\pi_1, \\pi_2)\\).\n\nWe minimize Bayes Risk \\(r(\\pi, d) = \\pi_1 R_1 + \\pi_2 R_2\\).\nThe equation \\(\\pi_1 R_1 + \\pi_2 R_2 = c\\) defines a family of parallel lines with slope \\(m = -\\frac{\\pi_1}{\\pi_2}\\).\nTo find the Bayes rule, imagine taking a line with slope \\(-\\frac{\\pi_1}{\\pi_2}\\) and moving it from the origin outward until it just touches the Risk Set \\(S\\).\nThe point(s) of tangency are the Bayes rules for that prior.\n\n\n\n\n\n\n\n\n\nFigure 2.1: Geometric Representation of Decision Principles. The gray polygon is the Risk Set. The blue line segment represents the Admissible Rules. The red point is the Minimax Rule (intersection with R1=R2). The green point is a Bayes Rule, found by the tangent line determined by the prior.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#principles-for-choosing-a-decision-rule",
    "href": "decision.html#principles-for-choosing-a-decision-rule",
    "title": "2  Decision Theory",
    "section": "2.4 Principles for Choosing a Decision Rule",
    "text": "2.4 Principles for Choosing a Decision Rule\nSince no single rule minimizes risk for all \\(\\theta\\), we rely on several principles to order and select decision rules.\n\n2.4.1 Admissibility\nA decision rule \\(d\\) is admissible if it is not “dominated” by any other rule.\n\nDomination: A rule \\(d\\) dominates \\(d'\\) if \\(R(\\theta, d) \\le R(\\theta, d')\\) for all \\(\\theta\\), with strict inequality for at least one \\(\\theta\\).\nInadmissibility: If a rule is dominated, it is inadmissible and can be discarded (we can do better or equal in every possible state).\n\n\n\n\n\n\n\n\n\nFigure 2.1: Illustration of Domination: Rule A (Red) is inadmissible because Rule B (Blue) has lower risk for all values of theta.\n\n\n\n\n\n\n\n2.4.2 Minimax Principle\nThe Minimax principle is a conservative approach that guards against the worst-case scenario. It selects the rule that minimizes the maximum risk. \\[ \\min_{d} \\left[ \\sup_{\\theta} R(\\theta, d) \\right] \\]\nIn the plot below, while Rule B has lower risk in the center, it has a very high maximum risk. Rule A is “flatter” and has a lower maximum value, making it the Minimax choice.\n\n\n\n\n\n\n\n\nFigure 2.2: Illustration of Minimax: Rule A has a lower peak risk than Rule B, making Rule A the Minimax choice.\n\n\n\n\n\n\n\n2.4.3 Bayes Decision Rules\nThe Bayes principle incorporates prior knowledge. If we assign a probability distribution (prior) \\(\\pi(\\theta)\\) to the parameter, we can calculate the Bayes Risk, which is the weighted average of the risk function. We choose the rule that minimizes this average. \\[ r(\\pi, d) = E_\\pi [R(\\theta, d)] = \\int_\\Theta R(\\theta, d) \\pi(\\theta) d\\theta \\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#geometric-interpretation-risk-sets",
    "href": "decision.html#geometric-interpretation-risk-sets",
    "title": "2  Decision Theory",
    "section": "2.5 Geometric Interpretation (Risk Sets)",
    "text": "2.5 Geometric Interpretation (Risk Sets)\nFor finite parameter spaces (e.g., \\(\\Theta = \\{1, 2\\}\\)), we can visualize the problem in 2D space where the axes are \\(R_1 = R(\\theta_1)\\) and \\(R_2 = R(\\theta_2)\\).\n\n2.5.1 The Risk Set (\\(S\\))\nThe set of all possible risk vectors is called the Risk Set \\(S\\). * Deterministic Rules: These are the vertices of the set. * Randomized Rules: By choosing rule \\(d_i\\) with probability \\(p\\) and \\(d_j\\) with probability \\(1-p\\), we can achieve any risk on the line segment connecting them. * Convexity: The Risk Set is the convex hull of the deterministic rules.\n\n\n2.5.2 Visualizing Admissibility\nThe admissible rules lie on the lower-left boundary of the set. Any point to the “north-east” of another point is dominated (inadmissible).\n\n\n2.5.3 Visualizing Minimax\nThe Minimax rule is found by intersecting the Risk Set with the line \\(y=x\\) (\\(R_1 = R_2\\)). * We look for the point in \\(S\\) that touches the \\(45^\\circ\\) line at the lowest value. * If the set is entirely below the line, we minimize \\(R_2\\). If entirely above, we minimize \\(R_1\\).\n\n\n2.5.4 Visualizing Bayes Rules\nA Bayes rule minimizes \\(\\pi_1 R_1 + \\pi_2 R_2 = k\\). This equation represents a line with slope \\(m = -\\pi_1 / \\pi_2\\). * To find the Bayes rule, we find the tangent line to the Risk Set \\(S\\) with slope \\(-\\pi_1 / \\pi_2\\).\n\n\n\n\n\n\n\n\nFigure 2.3: Geometric Interpretation: The gray polygon is the Risk Set S. The blue boundary represents admissible rules. The red point is the Minimax rule. The green line represents a Bayes rule for a specific prior.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#revisiting-the-necklace-example-geometric-solution",
    "href": "decision.html#revisiting-the-necklace-example-geometric-solution",
    "title": "2  Decision Theory",
    "section": "2.6 Revisiting the Necklace Example: Geometric Solution",
    "text": "2.6 Revisiting the Necklace Example: Geometric Solution\nWe now apply the geometric interpretation to the Necklace problem using the risks calculated in Section 2.3.4.\n\n\\(d_1\\): \\((0, 1)\\)\n\\(d_2\\): \\((1, 0)\\)\n\\(d_3\\): \\((0, 0.5)\\)\n\\(d_4\\): \\((1, 0.5)\\)\n\n\n2.6.1 Analysis\n\nAdmissibility:\n\n\\(d_4\\) has risk \\((1, 0.5)\\). \\(d_3\\) has risk \\((0, 0.5)\\). Since \\(0 &lt; 1\\), \\(d_3\\) strictly dominates \\(d_4\\). Thus \\(d_4\\) is inadmissible.\nThe efficient frontier connects \\(d_3\\) and \\(d_2\\).\n\nMinimax Solution: The Minimax rule lies on the segment connecting \\(d_3 (0, 0.5)\\) and \\(d_2 (1, 0)\\).\n\nLet the randomized rule be \\(\\delta^* = p d_3 + (1-p) d_2\\).\n\\(R(\\delta^*) = p \\begin{pmatrix} 0 \\\\ 0.5 \\end{pmatrix} + (1-p) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1-p \\\\ 0.5p \\end{pmatrix}\\).\nSet \\(R_1 = R_2\\): \\(1-p = 0.5p \\Rightarrow 1 = 1.5p \\Rightarrow p = 2/3\\).\nResult: The Minimax rule is to choose \\(d_3\\) with probability \\(2/3\\) and \\(d_2\\) with probability \\(1/3\\).\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Necklace Problem Solution. The Minimax rule (red diamond) is the specific randomized combination of d3 and d2 that equalizes the risk.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#theorems-relating-minimax-and-bayes-rules",
    "href": "decision.html#theorems-relating-minimax-and-bayes-rules",
    "title": "2  Decision Theory",
    "section": "2.7 Theorems Relating Minimax and Bayes Rules",
    "text": "2.7 Theorems Relating Minimax and Bayes Rules\nIn practice, finding a Minimax rule directly is mathematically difficult. A standard strategy is to “guess” a Least Favorable Prior \\(\\pi\\)—defined as the prior distribution that maximizes the minimum Bayes risk (i.e., the prior against which it is hardest to defend)—find the corresponding Bayes rule, and then check if it satisfies specific conditions to confirm it is Minimax.\n\n2.7.1 Equalizer Rules\n\nTheorem 2.1 (The Equalizer Rule Strategy) If \\(\\delta^*\\) is a Bayes rule with respect to some prior \\(\\pi\\), and if \\(\\delta^*\\) is an equalizer rule (meaning \\(R(\\theta, \\delta^*) = C\\) for some constant \\(C\\) for all \\(\\theta \\in \\Theta\\)), then \\(\\delta^*\\) is Minimax.\n\n\nProof. \n\nBayes Risk Definition: Since \\(\\delta^*\\) is an equalizer rule with risk \\(C\\), its Bayes risk with respect to \\(\\pi\\) is: \\[r(\\pi, \\delta^*) = \\int_\\Theta R(\\theta, \\delta^*) \\pi(\\theta) d\\theta = \\int_\\Theta C \\pi(\\theta) d\\theta = C \\cdot 1 = C\\]\nMinimax Contradiction: Suppose, for the sake of contradiction, that \\(\\delta^*\\) is not Minimax. This implies there exists another rule \\(\\delta'\\) such that: \\[\\sup_{\\theta} R(\\theta, \\delta') &lt; \\sup_{\\theta} R(\\theta, \\delta^*)\\] Since \\(R(\\theta, \\delta^*) = C\\) for all \\(\\theta\\), the supremum is \\(C\\). Thus: \\[\\sup_{\\theta} R(\\theta, \\delta') &lt; C\\]\nInequality: This implies that for all \\(\\theta\\), \\(R(\\theta, \\delta') &lt; C\\).\nBayes Risk Comparison: Now, consider the Bayes risk of this alternative rule \\(\\delta'\\): \\[r(\\pi, \\delta') = \\int_\\Theta R(\\theta, \\delta') \\pi(\\theta) d\\theta\\] Since \\(R(\\theta, \\delta') &lt; C\\) for all \\(\\theta\\), it follows that: \\[r(\\pi, \\delta') &lt; \\int_\\Theta C \\pi(\\theta) d\\theta = C\\]\nConclusion: We have established that \\(r(\\pi, \\delta') &lt; C\\). However, we established in step 1 that \\(r(\\pi, \\delta^*) = C\\). This yields \\(r(\\pi, \\delta') &lt; r(\\pi, \\delta^*)\\). This contradicts the assumption that \\(\\delta^*\\) is a Bayes rule (since a Bayes rule must minimize the Bayes risk). Therefore, no such \\(\\delta'\\) exists, and \\(\\delta^*\\) is Minimax. \\(\\blacksquare\\)\n\n\n\n\n2.7.2 Limits of Bayes Rules\nSometimes the Minimax rule corresponds to an “improper” prior (a prior that does not integrate to 1, like a uniform distribution on the real line). We approach these via a limiting sequence.\n\nTheorem 2.2 (Limits of Bayes Rules) Let \\(\\{\\delta_n\\}\\) be a sequence of Bayes rules with respect to priors \\(\\{\\pi_n\\}\\). Let \\(r(\\pi_n, \\delta_n)\\) be the associated Bayes risks. If there exists a rule \\(\\delta_0\\) such that: \\[\\sup_{\\theta} R(\\theta, \\delta_0) \\le \\lim_{n \\to \\infty} r(\\pi_n, \\delta_n)\\] Then \\(\\delta_0\\) is Minimax.\n\n\nProof. \n\nDefine Limit: Let \\(V = \\lim_{n \\to \\infty} r(\\pi_n, \\delta_n)\\). We are given that \\(\\sup_{\\theta} R(\\theta, \\delta_0) \\le V\\).\nContradiction Setup: Suppose \\(\\delta_0\\) is not Minimax. Then there exists a rule \\(\\delta^*\\) such that: \\[\\sup_{\\theta} R(\\theta, \\delta^*) &lt; \\sup_{\\theta} R(\\theta, \\delta_0) \\le V\\] Let \\(\\sup_{\\theta} R(\\theta, \\delta^*) = V - \\epsilon\\) for some \\(\\epsilon &gt; 0\\).\nBayes Risk Bound: For any prior \\(\\pi_n\\), the Bayes risk of \\(\\delta^*\\) cannot exceed its maximum risk: \\[r(\\pi_n, \\delta^*) = \\int R(\\theta, \\delta^*) \\pi_n(\\theta) d\\theta \\le \\int (V - \\epsilon) \\pi_n(\\theta) d\\theta = V - \\epsilon\\]\nOptimality of \\(\\delta_n\\): Since \\(\\delta_n\\) is the Bayes rule for \\(\\pi_n\\), it minimizes Bayes risk. Thus: \\[r(\\pi_n, \\delta_n) \\le r(\\pi_n, \\delta^*)\\]\nCombining Inequalities: Combining steps 3 and 4: \\[r(\\pi_n, \\delta_n) \\le V - \\epsilon\\]\nTaking Limits: Taking the limit as \\(n \\to \\infty\\): \\[\\lim_{n \\to \\infty} r(\\pi_n, \\delta_n) \\le V - \\epsilon\\] \\[V \\le V - \\epsilon\\] This is a contradiction since \\(\\epsilon &gt; 0\\). Therefore, \\(\\delta_0\\) must be Minimax. \\(\\blacksquare\\)\n\n\n\n\n2.7.3 Admissibility of Bayes Rules\nBayes rules are generally good candidates for admissibility. If a rule is Bayes, it is likely efficient, provided the prior doesn’t ignore parts of the parameter space.\n\nTheorem 2.3 (Admissibility of Bayes Rules (Finite Support)) If the parameter space \\(\\Theta\\) is finite (or countable) and the prior \\(\\pi\\) assigns positive probability to every \\(\\theta \\in \\Theta\\) (i.e., \\(\\pi(\\theta) &gt; 0\\) for all \\(\\theta\\)), then any Bayes rule \\(\\delta_\\pi\\) is admissible.\n\n\nProof. \n\nContradiction Setup: Suppose \\(\\delta_\\pi\\) is inadmissible. Then there exists a rule \\(\\delta'\\) that dominates it. By definition of domination:\n\n\\(R(\\theta, \\delta') \\le R(\\theta, \\delta_\\pi)\\) for all \\(\\theta\\).\n\\(R(\\theta_k, \\delta') &lt; R(\\theta_k, \\delta_\\pi)\\) for at least one \\(\\theta_k\\).\n\nBayes Risk Difference: Consider the difference in Bayes risk: \\[r(\\pi, \\delta_\\pi) - r(\\pi, \\delta') = \\sum_{\\theta \\in \\Theta} \\pi(\\theta) [R(\\theta, \\delta_\\pi) - R(\\theta, \\delta')]\\]\nStrict Positivity:\n\nSince \\(\\delta'\\) dominates \\(\\delta_\\pi\\), each term \\([R(\\theta, \\delta_\\pi) - R(\\theta, \\delta')]\\) is non-negative (\\(\\ge 0\\)).\nAt \\(\\theta_k\\), the term is strictly positive (\\(&gt; 0\\)).\nWe assumed the prior has full support, so \\(\\pi(\\theta) &gt; 0\\) for all \\(\\theta\\).\n\nSummation: A sum of non-negative terms where at least one term is strictly positive must be strictly positive. \\[r(\\pi, \\delta_\\pi) - r(\\pi, \\delta') &gt; 0 \\implies r(\\pi, \\delta') &lt; r(\\pi, \\delta_\\pi)\\]\nConclusion: This contradicts the definition that \\(\\delta_\\pi\\) is a Bayes rule (which must minimize Bayes risk). Therefore, \\(\\delta_\\pi\\) is admissible. \\(\\blacksquare\\)\n\n\n\n\n2.7.4 Admissibility of Unique Bayes Rules\nIf the Bayes rule is unique, we can drop the requirement that the parameter space be discrete or finite.\n\nTheorem 2.4 (Admissibility of Unique Bayes Rules) Let \\(\\delta_\\pi\\) be a Bayes rule with respect to \\(\\pi\\). If \\(\\delta_\\pi\\) is the unique Bayes rule (up to risk equivalence), then \\(\\delta_\\pi\\) is admissible.\n\n\nProof. \n\nContradiction Setup: Suppose \\(\\delta_\\pi\\) is inadmissible. Then there exists a rule \\(\\delta'\\) such that: \\(R(\\theta, \\delta') \\le R(\\theta, \\delta_\\pi)\\) for all \\(\\theta\\), with strict inequality for some set of \\(\\theta\\).\nBayes Risk Inequality: Taking the expectation with respect to \\(\\pi\\): \\[r(\\pi, \\delta') = \\int R(\\theta, \\delta') \\pi(\\theta) d\\theta \\le \\int R(\\theta, \\delta_\\pi) \\pi(\\theta) d\\theta = r(\\pi, \\delta_\\pi)\\]\nMinimality: Since \\(\\delta_\\pi\\) is Bayes, it minimizes the risk, so \\(r(\\pi, \\delta_\\pi) \\le r(\\pi, \\delta')\\). Combining these gives \\(r(\\pi, \\delta') = r(\\pi, \\delta_\\pi)\\).\nUniqueness: This implies that \\(\\delta'\\) is also a Bayes rule. However, we assumed that \\(\\delta_\\pi\\) is the unique Bayes rule. Therefore, \\(\\delta'\\) must be equal to \\(\\delta_\\pi\\) (in terms of risk functions).\nConclusion: If \\(\\delta'\\) and \\(\\delta_\\pi\\) have identical risk functions, then \\(\\delta'\\) cannot strictly dominate \\(\\delta_\\pi\\). This contradicts the assumption of inadmissibility. Thus, \\(\\delta_\\pi\\) is admissible. \\(\\blacksquare\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "decision.html#risk-set-for-finite-parameter-space",
    "href": "decision.html#risk-set-for-finite-parameter-space",
    "title": "2  Decision Theory",
    "section": "2.5 Risk Set for Finite Parameter Space",
    "text": "2.5 Risk Set for Finite Parameter Space\nFor finite parameter spaces (e.g., \\(\\Theta = \\{1, 2\\}\\)), we can visualize the problem in 2D space where the axes are \\(R_1 = R(\\theta_1)\\) and \\(R_2 = R(\\theta_2)\\).\n\n2.5.1 The Risk Set (\\(S\\))\nThe set of all possible risk vectors is called the Risk Set \\(S\\).\n\nDeterministic Rules: These are the vertices of the set.\nRandomized Rules: By choosing rule \\(d_i\\) with probability \\(p\\) and \\(d_j\\) with probability \\(1-p\\), we can achieve any risk on the line segment connecting them.\nConvexity: The Risk Set is the convex hull of the deterministic rules.\n\n\n\n2.5.2 Visualizing Admissibility\nThe admissible rules lie on the lower-left boundary of the set. Any point to the “north-east” of another point is dominated (inadmissible).\n\n\n2.5.3 Visualizing Minimax\nThe Minimax rule is found by intersecting the Risk Set with the line \\(y=x\\) (\\(R_1 = R_2\\)).\n\nWe look for the point in \\(S\\) that touches the \\(45^\\circ\\) line at the lowest value.\nIf the set is entirely below the line, we minimize \\(R_2\\). If entirely above, we minimize \\(R_1\\).\n\n\n\n2.5.4 Visualizing Bayes Rules\nA Bayes rule minimizes \\(\\pi_1 R_1 + \\pi_2 R_2 = k\\). This equation represents a line with slope \\(m = -\\pi_1 / \\pi_2\\).\n\nTo find the Bayes rule, we find the tangent line to the Risk Set \\(S\\) with slope \\(-\\pi_1 / \\pi_2\\).\n\n\n\n\n\n\n\n\n\nFigure 2.3: Geometric Interpretation: The gray polygon is the Risk Set S. The blue boundary represents admissible rules. The red point is the Minimax rule. The green line represents a Bayes rule for a specific prior.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Decision Theory</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#the-likelihood-function",
    "href": "introstatinf.html#the-likelihood-function",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.5 The Likelihood Function",
    "text": "1.5 The Likelihood Function\nThe bridge between probability and statistics is the Likelihood Function.\n\nDefinition 1.2 (Likelihood Function) Let \\(f(x_1, \\dots, x_n; \\theta)\\) be the joint probability density (or mass) function of the data given the parameter \\(\\theta\\). When we view this function as a function of \\(\\theta\\) for fixed observed data \\(x_1, \\dots, x_n\\), we call it the likelihood function, denoted \\(L(\\theta)\\). \\[L(\\theta) = f(x_1, \\dots, x_n; \\theta)\\]\n\n\nExample: Lady Tasting Tea\nFor our Tea Tasting data, the likelihood is proportional to the Binomial probability: \\[L(\\theta) = \\binom{n}{k} \\theta^k (1-\\theta)^{n-k}\\]\n\nn=10 (k=7)n=40 (k=28)\n\n\nHere, \\(L(\\theta) = \\binom{10}{7} \\theta^{7} (1-\\theta)^{3}\\).\n\n\n\n\n\n\n\n\n\\(\\theta\\)\nCalculation \\(\\binom{10}{7} \\theta^{7} (1-\\theta)^{3}\\)\n\\(L(\\theta)\\)\n\n\n\n\n0.0\n120 \\(\\times 0^{7} \\times 1^{3}\\)\n0.0000\n\n\n0.2\n120 \\(\\times 0.2^{7} \\times 0.8^{3}\\)\n0.0008\n\n\n0.4\n120 \\(\\times 0.4^{7} \\times 0.6^{3}\\)\n0.0425\n\n\n0.6\n120 \\(\\times 0.6^{7} \\times 0.4^{3}\\)\n0.2150\n\n\n0.7\n120 \\(\\times 0.7^{7} \\times 0.3^{3}\\)\n0.2668 (Max)\n\n\n0.8\n120 \\(\\times 0.8^{7} \\times 0.2^{3}\\)\n0.2013\n\n\n1.0\n120 \\(\\times 1^{7} \\times 0^{3}\\)\n0.0000\n\n\n\n\n\nCode\nlikelihood_fun &lt;- function(theta) { choose(n_small, k_small) * theta^k_small * (1 - theta)^(n_small-k_small) }\ntheta_vals &lt;- seq(0, 1, length.out = 200)\ndf &lt;- data.frame(theta = theta_vals, Likelihood = likelihood_fun(theta_vals))\n\nggplot(df, aes(x = theta, y = Likelihood)) +\n  geom_line(color = \"darkblue\", size = 1.2) +\n  geom_vline(xintercept = k_small/n_small, linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = k_small/n_small, y = max(df$Likelihood)/4, label = paste(\"Max at\", k_small/n_small), color = \"red\", angle = 90, vjust = -0.5) +\n  labs(title = TeX(paste0(\"Likelihood $L(\\\\theta)$ for $n=\", n_small, \", k=\", k_small, \"$\")),\n       x = TeX(r'(Parameter $\\theta$)'),\n       y = TeX(r'(Likelihood $L(\\theta)$)')) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.2: Likelihood Function (n= 10 )\n\n\n\n\n\n\n\nHere, \\(L(\\theta) = \\binom{40}{28} \\theta^{28} (1-\\theta)^{12}\\). Notice how the likelihood becomes narrower (more peaked) with more data, even though the peak remains at 0.7.\n\n\n\n\n\n\n\n\n\\(\\theta\\)\nCalculation \\(\\binom{40}{28} \\theta^{28} (1-\\theta)^{12}\\)\n\\(L(\\theta)\\)\n\n\n\n\n0.0\n5.5868535^{9} \\(\\times 0^{28} \\times 1^{12}\\)\n0.0000\n\n\n0.2\n5.5868535^{9} \\(\\times 0.2^{28} \\times 0.8^{12}\\)\n0.0000\n\n\n0.4\n5.5868535^{9} \\(\\times 0.4^{28} \\times 0.6^{12}\\)\n0.0001\n\n\n0.6\n5.5868535^{9} \\(\\times 0.6^{28} \\times 0.4^{12}\\)\n0.0576\n\n\n0.7\n5.5868535^{9} \\(\\times 0.7^{28} \\times 0.3^{12}\\)\n0.1366 (Max)\n\n\n0.8\n5.5868535^{9} \\(\\times 0.8^{28} \\times 0.2^{12}\\)\n0.0443\n\n\n1.0\n5.5868535^{9} \\(\\times 1^{28} \\times 0^{12}\\)\n0.0000\n\n\n\n\n\nCode\nlikelihood_fun &lt;- function(theta) { choose(n_large, k_large) * theta^k_large * (1 - theta)^(n_large-k_large) }\ntheta_vals &lt;- seq(0, 1, length.out = 200)\ndf &lt;- data.frame(theta = theta_vals, Likelihood = likelihood_fun(theta_vals))\n\nggplot(df, aes(x = theta, y = Likelihood)) +\n  geom_line(color = \"darkblue\", size = 1.2) +\n  geom_vline(xintercept = k_large/n_large, linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = k_large/n_large, y = max(df$Likelihood)/4, label = paste(\"Max at\", k_large/n_large), color = \"red\", angle = 90, vjust = -0.5) +\n  labs(title = TeX(paste0(\"Likelihood $L(\\\\theta)$ for $n=\", n_large, \", k=\", k_large, \"$\")),\n       x = TeX(r'(Parameter $\\theta$)'),\n       y = TeX(r'(Likelihood $L(\\theta)$)')) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.3: Likelihood Function (n= 40 )\n\n\n\n\n\n\n\n\nQuestions:\n\nIs an estimator like \\(\\bar x\\), which is called Maximum Likelihood Estimator (MLE), a good estimator in general?\nWhat do you discover from actually observing the two likelihood unctions of different sample size \\(n\\)?\nIs the likelihood function central to all inference problems?\n\nThere are two primary frameworks for “How” to perform these inferences.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#frequentist-inference-fisher",
    "href": "introstatinf.html#frequentist-inference-fisher",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.6 Frequentist Inference (Fisher)",
    "text": "1.6 Frequentist Inference (Fisher)\n\nConcept: \\(\\theta\\) is fixed; Data \\(X\\) is random.\nSampling Distribution: We analyze how \\(\\hat{\\theta}\\) behaves under hypothetical repeated sampling.\n\n\nExample: Frequentist Test of Lady Tasting Tea\nWe test \\(H_0: \\theta=0.5\\) (Guessing) vs \\(H_1: \\theta &gt; 0.5\\) (Skill). We analyze the behavior of \\(\\bar{X}\\) assuming \\(H_0\\) is true. The rejection region (one-sided) is shaded red.\n\nn=10 (k=7)n=40 (k=28)\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 7\\) correct out of 10, assuming \\(\\theta=0.5\\).\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_small\nprobs &lt;- dbinom(k_vals, size=n_small, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_small, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_small/n_small, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\n# Plot\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=5, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_small/n_small, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.25, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_small, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.4: Sampling Distribution (n= 10 )\n\n\n\n\n\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 28\\) correct out of 40. With a larger sample size, the same proportion (0.7) provides stronger evidence against the null.\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_large\nprobs &lt;- dbinom(k_vals, size=n_large, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_large, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_large/n_large, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=4, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_large/n_large, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.15, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_large, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.5: Sampling Distribution (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.6.1 Questions to Answer\nIn this course, we will answer several challenging questions related to general parametric models in the Frequentist framework.\n\nMLE: Can we use the Maximum Likelihood Estimator (MLE) \\(\\hat{\\theta}\\) for general models even no closed-form solution exists? Is MLE a good method?\nSampling Distributions: What is the distribution of \\(\\hat{\\theta}_{\\text{MLE}}\\)? What’s its mean and standard deviation?\nConfidence Intervals: How to construct CI with \\(\\hat{\\theta}\\)?\nHypothesis Testing: How do we derive powerful tests from the likelihood function? How to assess goodness-of-fit of parametric models with their likelhiood information?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#bayesian-inference",
    "href": "introstatinf.html#bayesian-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.7 Bayesian Inference",
    "text": "1.7 Bayesian Inference\n\nConcept: \\(\\theta\\) is a random variable.\nPosterior: Posterior \\(\\propto\\) Likelihood \\(\\times\\) Prior.\n\n\nExample: Bayesian Analysis of the Lady Tasting Tea\nPrior: \\(\\text{Beta}(1,1)\\) (Uniform).\n\nn=10 (k=7)n=40 (k=28)\n\n\nPosterior: \\(\\text{Beta}(1+7, 1+3) = \\text{Beta}(8, 4)\\)\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_small, 1+(n_small-k_small))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_small, 1+(n_small-k_small), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_small, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.6: Bayesian Update (n= 10 )\n\n\n\n\n\n\n\nPosterior: \\(\\text{Beta}(1+28, 1+12) = \\text{Beta}(29, 13)\\).\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_large, 1+(n_large-k_large))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_large, 1+(n_large-k_large), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2.5, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_large, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.7: Bayesian Update (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.7.1 Questions to Answer\nWe will also tackle the specific technical challenges involved in Bayesian analysis.\n\nPosterior Derivation: How do we derive the posterior distribution \\(f(\\theta|x)\\) for various likelihoods and priors?\nComparing with Other methods: Are Bayesain methods good or not or general inference?\nComputation: When the posterior cannot be derived analytically, how do we use computational techniques like Markov Chain Monte Carlo (MCMC) to sample from it?\nSummarization: How do we construct Credible Intervals (e.g., Highest Posterior Density regions) from posterior samples?\nPrediction: How do we solve the integral required to compute the posterior predictive distribution for future data?\nPrior: How to choose our prior? What’s its effect on our inference?\nModel Comparison and Assessment: How to assess a Bayesian model?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#motivating-example-the-lady-tasting-tea",
    "href": "introstatinf.html#motivating-example-the-lady-tasting-tea",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.3 Motivating Example: The Lady Tasting Tea",
    "text": "1.3 Motivating Example: The Lady Tasting Tea\nTo illustrate the concepts of statistical inference, we consider the famous experiment described by R.A. Fisher.\nA lady claims she can distinguish whether milk was poured into the cup before or after the tea. To test this claim, we prepare \\(n\\) cups of tea.\n\nRandom Variable: Let \\(X_i=1\\) if she identifies the cup correctly, and \\(0\\) otherwise.\nParameter: Let \\(\\theta\\) be the probability that she correctly identifies a cup.\nThe Data: Suppose we observe that she identifies 70% of cups correctly (\\(\\bar{x} = 0.7\\)).\n\n\nSmall Sample (n=10)Large Sample (n=40)\n\n\nWe observe 7 out of 10 correct (\\(k=7\\)). \\[\\bar{x} = 0.7\\]\n\n\nWe observe 28 out of 40 correct (\\(k=28\\)). \\[\\bar{x} = 0.7\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#paradigms-of-inference",
    "href": "introstatinf.html#paradigms-of-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.6 Paradigms of Inference",
    "text": "1.6 Paradigms of Inference\nThere are two primary frameworks for “How” to perform these inferences.\n\n1.6.1 Frequentist Inference (Fisher)\n\nConcept: \\(\\theta\\) is fixed; Data \\(X\\) is random.\nSampling Distribution: We analyze how \\(\\hat{\\theta}\\) behaves under hypothetical repeated sampling.\n\n\nExample: Frequentist Test of Lady Tasting Tea\nWe test \\(H_0: \\theta=0.5\\) (Guessing) vs \\(H_1: \\theta &gt; 0.5\\) (Skill). We analyze the behavior of \\(\\bar{X}\\) assuming \\(H_0\\) is true. The rejection region (one-sided) is shaded red.\n\nn=10 (k=7)n=40 (k=28)\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 7\\) correct out of 10, assuming \\(\\theta=0.5\\).\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_small\nprobs &lt;- dbinom(k_vals, size=n_small, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_small, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_small/n_small, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\n# Plot\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=5, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_small/n_small, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.25, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_small, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.4: Sampling Distribution (n= 10 )\n\n\n\n\n\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 28\\) correct out of 40. With a larger sample size, the same proportion (0.7) provides stronger evidence against the null.\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_large\nprobs &lt;- dbinom(k_vals, size=n_large, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_large, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_large/n_large, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=4, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_large/n_large, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.15, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_large, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.5: Sampling Distribution (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.6.1.1 Questions to Answer\nIn this course, we will answer several challenging questions related to general parametric models in the Frequentist framework.\n\nMLE: Can we use the Maximum Likelihood Estimator (MLE) \\(\\hat{\\theta}\\) for general models even no closed-form solution exists? Is MLE a good method?\nSampling Distributions: What is the distribution of \\(\\hat{\\theta}_{\\text{MLE}}\\)? What’s its mean and standard deviation?\nConfidence Intervals: How to construct CI with \\(\\hat{\\theta}\\)?\nHypothesis Testing: How do we derive powerful tests from the likelihood function? How to assess goodness-of-fit of parametric models with their likelhiood information?\n\n\n\n\n1.6.2 Bayesian Inference\n\nConcept: \\(\\theta\\) is a random variable.\nPosterior: Posterior \\(\\propto\\) Likelihood \\(\\times\\) Prior.\n\n\nExample: Bayesian Analysis of the Lady Tasting Tea\nPrior: \\(\\text{Beta}(1,1)\\) (Uniform).\n\nn=10 (k=7)n=40 (k=28)\n\n\nPosterior: \\(\\text{Beta}(1+7, 1+3) = \\text{Beta}(8, 4)\\)\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_small, 1+(n_small-k_small))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_small, 1+(n_small-k_small), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_small, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.6: Bayesian Update (n= 10 )\n\n\n\n\n\n\n\nPosterior: \\(\\text{Beta}(1+28, 1+12) = \\text{Beta}(29, 13)\\).\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_large, 1+(n_large-k_large))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_large, 1+(n_large-k_large), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2.5, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_large, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.7: Bayesian Update (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.6.2.1 Questions to Answer\nWe will also tackle the specific technical challenges involved in Bayesian analysis.\n\nPosterior Derivation: How do we derive the posterior distribution \\(f(\\theta|x)\\) for various likelihoods and priors?\nComparing with Other methods: Are Bayesain methods good or not or general inference?\nComputation: When the posterior cannot be derived analytically, how do we use computational techniques like Markov Chain Monte Carlo (MCMC) to sample from it?\nSummarization: How do we construct Credible Intervals (e.g., Highest Posterior Density regions) from posterior samples?\nPrediction: How do we solve the integral required to compute the posterior predictive distribution for future data?\nPrior: How to choose our prior? What’s its effect on our inference?\nModel Comparison and Assessment: How to assess a Bayesian model?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#key-questions-in-statistical-inference",
    "href": "introstatinf.html#key-questions-in-statistical-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.4 Key Questions in Statistical Inference",
    "text": "1.4 Key Questions in Statistical Inference\nUsing this example, we identify the four main types of statistical inference.\n\nPoint Estimation\nWe want to use a single number to capture the parameter: \\(\\hat{\\theta} = \\theta(X_1, \\dots, X_n)\\).\n\nTea Example: Our best guess for her success rate is \\(\\hat{\\theta} = 0.7\\).\n\n\n\nHypothesis Testing\nWe want to test a theory about the parameter: \\(H_0\\) vs \\(H_1\\).\n\nTea Example: Is she just guessing? We test \\(H_0: \\theta = 0.5\\) vs \\(H_1: \\theta &gt; 0.5\\).\n\n\n\nInterval Estimation\nWe want to construct an interval likely to contain the parameter: \\(\\theta \\in (L, U)\\).\n\nTea Example: We might say her true skill \\(\\theta\\) is likely between \\(0.45\\) and \\(0.95\\).\n\n\n\nPrediction\nWe want to predict a new observation \\(Y_{n+1}\\) given previous data.\n\nTea Example: If we give her an \\((n+1)\\)-th cup, what is the probability she identifies it correctly?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#a-motivating-example-the-lady-tasting-tea",
    "href": "introstatinf.html#a-motivating-example-the-lady-tasting-tea",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.3 A Motivating Example: The Lady Tasting Tea",
    "text": "1.3 A Motivating Example: The Lady Tasting Tea\nTo illustrate the concepts of statistical inference, we consider the famous experiment described by R.A. Fisher.\nA lady claims she can distinguish whether milk was poured into the cup before or after the tea. To test this claim, we prepare \\(n\\) cups of tea.\n\nRandom Variable: Let \\(X_i=1\\) if she identifies the cup correctly, and \\(0\\) otherwise.\nParameter: Let \\(\\theta\\) be the probability that she correctly identifies a cup.\nThe Data: Suppose we observe that she identifies 70% of cups correctly (\\(\\bar{x} = 0.7\\)), which is a summary of the observed vector of \\(x_i\\), for example,\n\n\\[x=(0,1,1,0, 1,1,0,1,1,1)\\]\n\nSmall Sample (n=10)Large Sample (n=40)\n\n\nWe observe 7 out of 10 correct (\\(k=7\\)). \\[\\bar{x} = 0.7\\]\n\n\nWe observe 28 out of 40 correct (\\(k=28\\)). \\[\\bar{x} = 0.7\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#questions-answered-with-statistical-inference",
    "href": "introstatinf.html#questions-answered-with-statistical-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.4 Questions Answered with Statistical Inference",
    "text": "1.4 Questions Answered with Statistical Inference\nUsing this example, we identify the four main types of statistical inference.\n\nPoint Estimation\nWe want to use a single number to capture the parameter: \\(\\hat{\\theta} = \\theta(X_1, \\dots, X_n)\\).\n\nTea Example: Our best guess for her success rate is \\(\\hat{\\theta} = 0.7\\).\n\n\n\nHypothesis Testing\nWe want to test a theory about the parameter: \\(H_0\\) vs \\(H_1\\).\n\nTea Example: Is she just guessing? We test \\(H_0: \\theta = 0.5\\) vs \\(H_1: \\theta &gt; 0.5\\).\n\n\n\nModel Assessment\nWe want to test a theory about the parameter: \\(H_0\\) vs \\(H_1\\).\n\nExample: Can we use a reduced model? What level of complexity of \\(f(x; \\theta)\\) is necessary?\n\n\n\nInterval Estimation\nWe want to construct an interval likely to contain the parameter: \\(\\theta \\in (L, U)\\).\n\nTea Example: We might say her true skill \\(\\theta\\) is likely between \\(0.45\\) and \\(0.95\\).\n\n\n\nPrediction\nWe want to predict a new observation \\(Y_{n+1}\\) given previous data.\n\nTea Example: If we give her an \\((n+1)\\)-th cup, what is the probability she identifies it correctly?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#two-paradigms-of-inference",
    "href": "introstatinf.html#two-paradigms-of-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.6 Two Paradigms of Inference",
    "text": "1.6 Two Paradigms of Inference\nThere are two primary frameworks for “How” to perform these inferences.\n\n1.6.1 Frequentist Inference (Fisher)\n\nConcept: \\(\\theta\\) is fixed; Data \\(X\\) is random.\nSampling Distribution: We analyze how \\(\\hat{\\theta}\\) behaves under hypothetical repeated sampling.\n\n\nExample: Frequentist Test of Lady Tasting Tea\nWe test \\(H_0: \\theta=0.5\\) (Guessing) vs \\(H_1: \\theta &gt; 0.5\\) (Skill). We analyze the behavior of \\(\\bar{X}\\) assuming \\(H_0\\) is true. The rejection region (one-sided) is shaded red.\n\nn=10 (k=7)n=40 (k=28)\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 7\\) correct out of 10, assuming \\(\\theta=0.5\\).\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_small\nprobs &lt;- dbinom(k_vals, size=n_small, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_small, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_small/n_small, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\n# Plot\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=5, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_small/n_small, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.25, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_small, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.4: Sampling Distribution (n= 10 )\n\n\n\n\n\n\n\nWe calculate the P-value: Probability of observing \\(\\ge 28\\) correct out of 40. With a larger sample size, the same proportion (0.7) provides stronger evidence against the null.\n\n\nCode\ntrue_theta &lt;- 0.5; \nk_vals &lt;- 0:n_large\nprobs &lt;- dbinom(k_vals, size=n_large, prob=true_theta)\ndf_exact &lt;- data.frame(x_bar = k_vals/n_large, prob = probs)\n\n# One-sided rejection region\ndf_exact$color_group &lt;- ifelse(df_exact$x_bar &gt;= k_large/n_large, \"Extreme\", \"Normal\")\np_val &lt;- sum(df_exact$prob[df_exact$color_group == \"Extreme\"])\n\nggplot() +\n  geom_segment(data=df_exact, aes(x=x_bar, xend=x_bar, y=0, yend=prob, color=color_group), \n               size=4, alpha=0.8) +\n  scale_color_manual(values=c(\"Extreme\"=\"red\", \"Normal\"=\"darkgreen\"), guide=\"none\") +\n  geom_vline(xintercept = k_large/n_large, color = \"blue\", size = 1) +\n  annotate(\"label\", x = 1.05, y = 0.15, \n           label = paste0(\"P-value = \", round(p_val, 3)), \n           hjust = 1, color=\"red\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Sampling Distribution ($n=\", n_large, \"$)\")),\n       subtitle = TeX(r'(Testing $H_0: \\theta=0.5$ vs $H_1: \\theta &gt; 0.5$)'),\n       x = TeX(r'(Sample Mean $\\bar{x}$)'), y = \"Probability Mass\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 1.5: Sampling Distribution (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.6.1.1 Questions to Answer\nIn this course, we will answer several challenging questions related to general parametric models in the Frequentist framework.\n\nMLE: Can we use the Maximum Likelihood Estimator (MLE) \\(\\hat{\\theta}\\) for general models even no closed-form solution exists? Is MLE a good method?\nSampling Distributions: What is the distribution of \\(\\hat{\\theta}_{\\text{MLE}}\\)? What’s its mean and standard deviation?\nConfidence Intervals: How to construct CI with \\(\\hat{\\theta}\\)?\nHypothesis Testing: How do we derive powerful tests from the likelihood function? How to assess goodness-of-fit of parametric models with their likelhiood information?\n\n\n\n\n1.6.2 Bayesian Inference\n\nConcept: \\(\\theta\\) is a random variable.\nPosterior: Posterior \\(\\propto\\) Likelihood \\(\\times\\) Prior.\n\n\nExample: Bayesian Analysis of the Lady Tasting Tea\nPrior: \\(\\text{Beta}(1,1)\\) (Uniform).\n\nn=10 (k=7)n=40 (k=28)\n\n\nPosterior: \\(\\text{Beta}(1+7, 1+3) = \\text{Beta}(8, 4)\\)\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_small, 1+(n_small-k_small))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_small, 1+(n_small-k_small), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_small, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.6: Bayesian Update (n= 10 )\n\n\n\n\n\n\n\nPosterior: \\(\\text{Beta}(1+28, 1+12) = \\text{Beta}(29, 13)\\).\n\n\nCode\ntheta_grid &lt;- seq(0, 1, length.out = 200)\nposterior &lt;- dbeta(theta_grid, 1+k_large, 1+(n_large-k_large))\nprior &lt;- dbeta(theta_grid, 1, 1)\n\nprob_skill &lt;- pbeta(0.5, 1+k_large, 1+(n_large-k_large), lower.tail = FALSE)\n\ndf_bayes &lt;- data.frame(\n  Theta = rep(theta_grid, 2),\n  Density = c(prior, posterior),\n  Type = rep(c(\"Prior\", \"Posterior\"), each = 200)\n)\n\nggplot(df_bayes, aes(x = Theta, y = Density, color = Type, linetype = Type)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"blue\", \"gray\")) +\n  scale_linetype_manual(values = c(\"solid\", \"dashed\")) +\n  annotate(\"label\", x = 0.1, y = 2.5, \n           label = TeX(paste0(\"$P(\\\\theta &gt; 0.5 | x) = \", round(prob_skill, 3), \"$\")), \n           hjust = 0, color=\"blue\", fontface=\"bold\") +\n  labs(title = TeX(paste0(\"Bayesian Update ($n=\", n_large, \"$)\")),\n       x = TeX(r'($\\theta$)'), y = \"Density\") +\n  theme_minimal() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.7: Bayesian Update (n= 40 )\n\n\n\n\n\n\n\n\n\n\n1.6.2.1 Questions to Answer\nWe will also tackle the specific technical challenges involved in Bayesian analysis.\n\nPosterior Derivation: How do we derive the posterior distribution \\(f(\\theta|x)\\) for various likelihoods and priors?\nComparing with Other methods: Are Bayesain methods good or not or general inference?\nComputation: When the posterior cannot be derived analytically, how do we use computational techniques like Markov Chain Monte Carlo (MCMC) to sample from it?\nSummarization: How do we construct Credible Intervals (e.g., Highest Posterior Density regions) from posterior samples?\nPrediction: How do we solve the integral required to compute the posterior predictive distribution for future data?\nPrior: How to choose our prior? What’s its effect on our inference?\nModel Comparison and Assessment: How to assess a Bayesian model?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#questions-to-answer-in-statistical-inference",
    "href": "introstatinf.html#questions-to-answer-in-statistical-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.4 Questions to Answer in Statistical Inference",
    "text": "1.4 Questions to Answer in Statistical Inference\nUsing this example, we identify the four main types of statistical inference.\n\nPoint Estimation\nWe want to use a single number to capture the parameter: \\(\\hat{\\theta} = \\theta(X_1, \\dots, X_n)\\).\n\nTea Example: Our best guess for her success rate is \\(\\hat{\\theta} = 0.7\\).\n\n\n\nHypothesis Testing\nWe want to test a theory about the parameter: \\(H_0\\) vs \\(H_1\\).\n\nTea Example: Is she just guessing? We test \\(H_0: \\theta = 0.5\\) vs \\(H_1: \\theta &gt; 0.5\\).\n\n\n\nModel Assessment\nWe want to test a theory about the parameter: \\(H_0\\) vs \\(H_1\\).\n\nExample: Can we use a reduced model? What level of complexity of \\(f(x; \\theta)\\) is necessary?\n\n\n\nInterval Estimation\nWe want to construct an interval likely to contain the parameter: \\(\\theta \\in (L, U)\\).\n\nTea Example: We might say her true skill \\(\\theta\\) is likely between \\(0.45\\) and \\(0.95\\).\n\n\n\nPrediction\nWe want to predict a new observation \\(Y_{n+1}\\) given previous data.\n\nTea Example: If we give her an \\((n+1)\\)-th cup, what is the probability she identifies it correctly?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#population-model-data-model",
    "href": "introstatinf.html#population-model-data-model",
    "title": "1  Introduction to Statistical Inference",
    "section": "",
    "text": "Definition 1.1 (Population Distribution) We assume that \\(X_1, X_2, \\dots, X_n \\sim f(x)\\). The function \\(f(x)\\) is called the population distribution.\n\n\nAssumptions and Scope\nFor simplicity, we often assume the data are Independent and Identically Distributed (i.i.d.). The assumption of identical distribution can be relaxed to regression settings in which the distributions of \\(x_i\\)’s are independent but dependent on covariate \\(x_i\\).\nIn Parametric Statistics, we assume \\(f(x)\\) is of a known analytic form but involves unknown parameters.\n\nExample 1.1 (Parametric Model: Normal) Consider the Normal distribution: \\[f(x; \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\] Here, the parameter space is \\(\\Theta = \\{ (\\mu, \\sigma^2) : \\mu \\in \\mathbb{R}, \\sigma \\in [0, +\\infty) \\}\\). The goal is to learn aspects of the unknown \\(\\theta\\) from observations \\(X_1, \\dots, X_n\\).\n\n\nExample 1.2 (Parametric Model: Bernoulli) Consider a sequence of binary outcomes (e.g., Success/Failure) where each \\(X_i \\in \\{0, 1\\}\\). We assume \\(X_i \\sim \\text{Bernoulli}(\\theta)\\). The probability mass function is: \\[f(x; \\theta) = \\theta^x (1-\\theta)^{1-x}\\] Here, the parameter space is \\(\\Theta = [0, 1]\\), where \\(\\theta\\) represents the probability of success.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "introstatinf.html#probabilistic-model-vs.-statistical-inference",
    "href": "introstatinf.html#probabilistic-model-vs.-statistical-inference",
    "title": "1  Introduction to Statistical Inference",
    "section": "1.2 Probabilistic Model vs. Statistical Inference",
    "text": "1.2 Probabilistic Model vs. Statistical Inference\nThere is a fundamental distinction between probability and statistics regarding the parameter \\(\\theta\\). We can visualize this using a “shooting target” analogy:\n\n\\(\\theta\\) (The Center): The true, unknown bullseye location.\n\\(x\\) (The Shots): The observed holes on the target board.\nProbability (Deductive): The center \\(\\theta\\) is known. We predict where the shots \\(x\\) will land.\nStatistics (Inductive): The shots \\(x\\) are observed on the board. The center \\(\\theta\\) is unknown. We hypothesize different potential centers to see which one best explains the shots.\n\n\n\n\n\n\n\n\n\nFigure 1.1: Probability vs Statistics. Left: Probability—The model is fixed (Blue center/contours), generating random data. Right: Statistics—Data is fixed (Black points); we test two hypothesized models: H1 (Green) centered at the sample mean (Good Fit) and H2 (Red) shifted by (1.5, 1.5) (Bad Fit).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistical Inference</span>"
    ]
  }
]