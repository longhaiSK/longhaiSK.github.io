{
  "hash": "90d3b13d6847a3d7b0f202afdda8e959",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Decision Theory\"\nformat: \n  html: default\n  pdf: default\n---\n\n\n\n\n\n\n\n\n## Formulation of Decision Theory\n\nIn decision theory, we formalize the process of making decisions under uncertainty using the following components:\n\n1.  **Parameter Space ($\\Theta$):**\n    The set of all possible states of nature or values that the parameter can take.\n    $\\theta \\in \\Theta$ (e.g., mean, variance).\n\n2.  **Sample Space ($\\mathcal{X}$):**\n    The space where the data $X$ lies.\n    Example: $X = (X_1, X_2, \\dots, X_n)$ where $X_i \\in \\mathbb{R}$. So $\\mathcal{X} \\in \\mathbb{R}^n$.\n\n3.  **Family of Probability Distributions:**\n    $\\{P_\\theta(x) : \\theta \\in \\Theta\\}$.\n    This describes how likely we are to see the data $X$ given a specific parameter $\\theta$.\n\n    * If $X$ is continuous: $P_\\theta(x) = f(x, \\theta)$ (Probability Density Function).\n    * If $X$ is discrete: $P_\\theta(x) = f(x, \\theta)$ (Probability Mass Function).\n\n4.  **Action Space ($\\mathcal{A}$):**\n    The set of all actions or decisions available to the experimenter.\n\n5.  **Loss Function:**\n    $L: \\Theta \\times \\mathcal{A} \\rightarrow \\mathbb{R}$.\n    $L(\\theta, a)$ specifies the loss incurred if the true parameter is $\\theta$ and we take action $a$. Generally, $L(\\theta, a) \\ge 0$.\n\n## Decision Rules and Risk Functions\n\n### Decision Rule\nA decision rule is a function $d: \\mathcal{X} \\rightarrow \\mathcal{A}$. It dictates the action $d(x)$ we take when we observe data $x$.\n\n### Risk Function\nThe risk function is the expected loss for a given decision rule $d$ as a function of the parameter $\\theta$.\n\n$$R(\\theta, d) = E_\\theta[L(\\theta, d(X))]$$\n\n## Examples of Decision Problems\n\n### Example 1: Hypothesis Testing\nWe want to test $H_0$ vs $H_1$.\n\n* **Action Space:** $\\mathcal{A} = \\{0, 1\\}$ (0=\"Accept $H_0$\", 1=\"Reject $H_0$\").\n* **Loss Function (0-1 Loss):** 0 if correct, 1 if wrong.\n* **Risk Function:**\n    * If $\\theta \\in H_0$: $R(\\theta, d) = P(\\text{Type I Error})$.\n    * If $\\theta \\in H_1$: $R(\\theta, d) = P(\\text{Type II Error})$.\n\n### Example 2: Point Estimation\nWe want to estimate a parameter $\\theta$.\n\n* **Action Space:** $\\mathcal{A} = \\Theta$.\n* **Loss Function (Squared Error):** $L(\\theta, a) = (\\theta - a)^2$.\n* **Risk Function (MSE):** $R(\\theta, d) = \\text{Var}(\\bar{x}) + \\text{Bias}^2$.\n\n### Example 3: Interval Estimation\nWe want to estimate a range for the parameter.\n\n* **Action Space:** $\\mathcal{A} = \\{(l, u) : l \\in \\mathbb{R}, u \\in \\mathbb{R}, l \\le u\\}$.\n\n### Example 4: The Duchess and the Emerald Necklace {#sec-necklace}\n\n**Scenario:**\nYou are the Duchess of Omnium. You have two necklaces: a priceless **Real** one and a valueless **Imitation**. They are indistinguishable to you. One is in the **Left Drawer (Box 1)**, the other is in the **Right Drawer (Box 2)**.\n\n**The Data (Great Aunt):**\nYou consult your Great Aunt. She inspects the Left Drawer first, then the Right.\n\n* If the **Real** necklace is in the **Left** ($\\theta=1$): She identifies it correctly. (Infallible).\n* If the **Real** necklace is in the **Right** ($\\theta=2$): She sees the fake first, gets confused, and guesses randomly ($50/50$).\n\n#### Formulation\n\n1.  **Parameter Space:** $\\Theta = \\{1, 2\\}$ (1=Real Left, 2=Real Right).\n2.  **Action Space:** $\\mathcal{A} = \\{1, 2\\}$ (1=Wear Left, 2=Wear Right).\n3.  **Loss Function:** 0 if correct, 1 if wrong.\n\n#### Risk Calculation for Deterministic Rules\n\nWe consider four deterministic rules $d(X)$. We calculate the risk ($R_1$ for $\\theta=1$ and $R_2$ for $\\theta=2$) for each.\n\n**Rule $d_1$ (Always Left)**\n\n| State | Component | $X=1$ | $X=2$ | Risk (Sum) |\n| :--- | :--- | :---: | :---: | :---: |\n| **$\\theta=1$** | Loss $L(1, d)$ | 0 | 0 | |\n| | Prob $P(X \\mid \\theta=1)$ | 1 | 0 | **$R_1 = 0$** |\n| **$\\theta=2$** | Loss $L(2, d)$ | 1 | 1 | |\n| | Prob $P(X \\mid \\theta=2)$ | 0.5 | 0.5 | **$R_2 = 1$** |\n\n**Rule $d_2$ (Always Right)**\n\n| State | Component | $X=1$ | $X=2$ | Risk (Sum) |\n| :--- | :--- | :---: | :---: | :---: |\n| **$\\theta=1$** | Loss $L(1, d)$ | 1 | 1 | |\n| | Prob $P(X \\mid \\theta=1)$ | 1 | 0 | **$R_1 = 1$** |\n| **$\\theta=2$** | Loss $L(2, d)$ | 0 | 0 | |\n| | Prob $P(X \\mid \\theta=2)$ | 0.5 | 0.5 | **$R_2 = 0$** |\n\n**Rule $d_3$ (Follow Aunt)**\n\n| State | Component | $X=1$ | $X=2$ | Risk (Sum) |\n| :--- | :--- | :---: | :---: | :---: |\n| **$\\theta=1$** | Loss $L(1, d)$ | 0 | 1 | |\n| | Prob $P(X \\mid \\theta=1)$ | 1 | 0 | **$R_1 = 0$** |\n| **$\\theta=2$** | Loss $L(2, d)$ | 1 | 0 | |\n| | Prob $P(X \\mid \\theta=2)$ | 0.5 | 0.5 | **$R_2 = 0.5$** |\n\n**Rule $d_4$ (Do Opposite)**\n\n| State | Component | $X=1$ | $X=2$ | Risk (Sum) |\n| :--- | :--- | :---: | :---: | :---: |\n| **$\\theta=1$** | Loss $L(1, d)$ | 1 | 0 | |\n| | Prob $P(X \\mid \\theta=1)$ | 1 | 0 | **$R_1 = 1$** |\n| **$\\theta=2$** | Loss $L(2, d)$ | 0 | 1 | |\n| | Prob $P(X \\mid \\theta=2)$ | 0.5 | 0.5 | **$R_2 = 0.5$** |\n\n## Principles for Choosing a Decision Rule\n\nSince no single rule minimizes risk for all $\\theta$, we rely on several principles to order and select decision rules.\n\n### Admissibility\nA decision rule $d$ is **admissible** if it is not \"dominated\" by any other rule.\n\n* **Domination:** A rule $d$ dominates $d'$ if $R(\\theta, d) \\le R(\\theta, d')$ for all $\\theta$, with strict inequality for at least one $\\theta$.\n* **Inadmissibility:** If a rule is dominated, it is inadmissible and can be discarded (we can do better or equal in every possible state).\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Illustration of Domination: Rule A (Red) is inadmissible because Rule B (Blue) has lower risk for all values of theta.](decision_files/figure-html/fig-admissibility-1.png){#fig-admissibility width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n### Minimax Principle\nThe Minimax principle is a conservative approach that guards against the worst-case scenario. It selects the rule that minimizes the maximum risk.\n$$ \\min_{d} \\left[ \\sup_{\\theta} R(\\theta, d) \\right] $$\n\nIn the plot below, while Rule B has lower risk in the center, it has a very high maximum risk. Rule A is \"flatter\" and has a lower maximum value, making it the **Minimax** choice.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Illustration of Minimax: Rule A has a lower peak risk than Rule B, making Rule A the Minimax choice.](decision_files/figure-html/fig-minimax-curve-1.png){#fig-minimax-curve width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n### Bayes Decision Rules\nThe Bayes principle incorporates prior knowledge. If we assign a probability distribution (prior) $\\pi(\\theta)$ to the parameter, we can calculate the **Bayes Risk**, which is the weighted average of the risk function. We choose the rule that minimizes this average.\n$$ r(\\pi, d) = E_\\pi [R(\\theta, d)] = \\int_\\Theta R(\\theta, d) \\pi(\\theta) d\\theta $$\n\n## Risk Set for Finite Parameter Space\n\nFor finite parameter spaces (e.g., $\\Theta = \\{1, 2\\}$), we can visualize the problem in 2D space where the axes are $R_1 = R(\\theta_1)$ and $R_2 = R(\\theta_2)$.\n\n### The Risk Set ($S$)\nThe set of all possible risk vectors is called the Risk Set $S$.\n\n* **Deterministic Rules:** These are the vertices of the set.\n* **Randomized Rules:** By choosing rule $d_i$ with probability $p$ and $d_j$ with probability $1-p$, we can achieve any risk on the line segment connecting them.\n* **Convexity:** The Risk Set is the **convex hull** of the deterministic rules.\n\n### Visualizing Admissibility\nThe admissible rules lie on the **lower-left boundary** of the set. Any point to the \"north-east\" of another point is dominated (inadmissible).\n\n### Visualizing Minimax\nThe Minimax rule is found by intersecting the Risk Set with the line $y=x$ ($R_1 = R_2$).\n\n* We look for the point in $S$ that touches the $45^\\circ$ line at the lowest value.\n* If the set is entirely below the line, we minimize $R_2$. If entirely above, we minimize $R_1$.\n\n### Visualizing Bayes Rules\nA Bayes rule minimizes $\\pi_1 R_1 + \\pi_2 R_2 = k$. This equation represents a line with slope $m = -\\pi_1 / \\pi_2$.\n\n* To find the Bayes rule, we find the **tangent line** to the Risk Set $S$ with slope $-\\pi_1 / \\pi_2$.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Geometric Interpretation: The gray polygon is the Risk Set S. The blue boundary represents admissible rules. The red point is the Minimax rule. The green line represents a Bayes rule for a specific prior.](decision_files/figure-html/fig-generic-geometry-1.png){#fig-generic-geometry width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n## Revisiting the Necklace Example: Geometric Solution\n\nWe now apply the geometric interpretation to the Necklace problem using the risks calculated in @sec-necklace.\n\n* $d_1$: $(0, 1)$\n* $d_2$: $(1, 0)$\n* $d_3$: $(0, 0.5)$\n* $d_4$: $(1, 0.5)$\n\n### Analysis\n\n1.  **Admissibility:**\n    * $d_4$ has risk $(1, 0.5)$. $d_3$ has risk $(0, 0.5)$. Since $0 < 1$, $d_3$ strictly dominates $d_4$. Thus $d_4$ is **inadmissible**.\n    * The efficient frontier connects $d_3$ and $d_2$.\n\n2.  **Minimax Solution:**\n    The Minimax rule lies on the segment connecting $d_3 (0, 0.5)$ and $d_2 (1, 0)$.\n\n    * Let the randomized rule be $\\delta^* = p d_3 + (1-p) d_2$.\n    * $R(\\delta^*) = p \\begin{pmatrix} 0 \\\\ 0.5 \\end{pmatrix} + (1-p) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1-p \\\\ 0.5p \\end{pmatrix}$.\n    * Set $R_1 = R_2$: $1-p = 0.5p \\Rightarrow 1 = 1.5p \\Rightarrow p = 2/3$.\n    * **Result:** The Minimax rule is to choose $d_3$ with probability $2/3$ and $d_2$ with probability $1/3$.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Necklace Problem Solution. The Minimax rule (red diamond) is the specific randomized combination of d3 and d2 that equalizes the risk.](decision_files/figure-html/fig-necklace-geometry-1.png){#fig-necklace-geometry width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n## Theorems Relating Minimax and Bayes Rules\n\nIn practice, finding a Minimax rule directly is mathematically difficult. A standard strategy is to \"guess\" a Least Favorable Prior $\\pi$—defined as the prior distribution that maximizes the minimum Bayes risk (i.e., the prior against which it is hardest to defend)—find the corresponding Bayes rule, and then check if it satisfies specific conditions to confirm it is Minimax.\n\n### Equalizer Rules\n\n::: {#thm-equalizer}\n## The Equalizer Rule Strategy\n\nIf $\\delta^*$ is a Bayes rule with respect to some prior $\\pi$, and if $\\delta^*$ is an **equalizer** rule (meaning $R(\\theta, \\delta^*) = C$ for some constant $C$ for all $\\theta \\in \\Theta$), then $\\delta^*$ is Minimax.\n:::\n\n::: {.proof}\n\n1.  **Bayes Risk Definition:** Since $\\delta^*$ is an equalizer rule with risk $C$, its Bayes risk with respect to $\\pi$ is:\n    $$r(\\pi, \\delta^*) = \\int_\\Theta R(\\theta, \\delta^*) \\pi(\\theta) d\\theta = \\int_\\Theta C \\pi(\\theta) d\\theta = C \\cdot 1 = C$$\n\n2.  **Minimax Contradiction:** Suppose, for the sake of contradiction, that $\\delta^*$ is *not* Minimax.\n    This implies there exists another rule $\\delta'$ such that:\n    $$\\sup_{\\theta} R(\\theta, \\delta') < \\sup_{\\theta} R(\\theta, \\delta^*)$$\n    Since $R(\\theta, \\delta^*) = C$ for all $\\theta$, the supremum is $C$. Thus:\n    $$\\sup_{\\theta} R(\\theta, \\delta') < C$$\n\n3.  **Inequality:** This implies that for all $\\theta$, $R(\\theta, \\delta') < C$.\n\n4.  **Bayes Risk Comparison:** Now, consider the Bayes risk of this alternative rule $\\delta'$:\n    $$r(\\pi, \\delta') = \\int_\\Theta R(\\theta, \\delta') \\pi(\\theta) d\\theta$$\n    Since $R(\\theta, \\delta') < C$ for all $\\theta$, it follows that:\n    $$r(\\pi, \\delta') < \\int_\\Theta C \\pi(\\theta) d\\theta = C$$\n\n5.  **Conclusion:** We have established that $r(\\pi, \\delta') < C$. However, we established in step 1 that $r(\\pi, \\delta^*) = C$.\n    This yields $r(\\pi, \\delta') < r(\\pi, \\delta^*)$.\n    This contradicts the assumption that $\\delta^*$ is a Bayes rule (since a Bayes rule must minimize the Bayes risk).\n    Therefore, no such $\\delta'$ exists, and $\\delta^*$ is Minimax. $\\blacksquare$\n:::\n\n### Limits of Bayes Rules\n\nSometimes the Minimax rule corresponds to an \"improper\" prior (a prior that does not integrate to 1, like a uniform distribution on the real line). We approach these via a limiting sequence.\n\n::: {#thm-limits}\n#### Limits of Bayes Rules\n\nLet $\\{\\delta_n\\}$ be a sequence of Bayes rules with respect to priors $\\{\\pi_n\\}$. Let $r(\\pi_n, \\delta_n)$ be the associated Bayes risks. If there exists a rule $\\delta_0$ such that:\n$$\\sup_{\\theta} R(\\theta, \\delta_0) \\le \\lim_{n \\to \\infty} r(\\pi_n, \\delta_n)$$\nThen $\\delta_0$ is Minimax.\n:::\n\n::: {.proof}\n\n1.  **Define Limit:** Let $V = \\lim_{n \\to \\infty} r(\\pi_n, \\delta_n)$. We are given that $\\sup_{\\theta} R(\\theta, \\delta_0) \\le V$.\n\n2.  **Contradiction Setup:** Suppose $\\delta_0$ is *not* Minimax. Then there exists a rule $\\delta^*$ such that:\n    $$\\sup_{\\theta} R(\\theta, \\delta^*) < \\sup_{\\theta} R(\\theta, \\delta_0) \\le V$$\n    Let $\\sup_{\\theta} R(\\theta, \\delta^*) = V - \\epsilon$ for some $\\epsilon > 0$.\n\n3.  **Bayes Risk Bound:** For any prior $\\pi_n$, the Bayes risk of $\\delta^*$ cannot exceed its maximum risk:\n    $$r(\\pi_n, \\delta^*) = \\int R(\\theta, \\delta^*) \\pi_n(\\theta) d\\theta \\le \\int (V - \\epsilon) \\pi_n(\\theta) d\\theta = V - \\epsilon$$\n\n4.  **Optimality of $\\delta_n$:** Since $\\delta_n$ is the Bayes rule for $\\pi_n$, it minimizes Bayes risk. Thus:\n    $$r(\\pi_n, \\delta_n) \\le r(\\pi_n, \\delta^*)$$\n\n5.  **Combining Inequalities:** Combining steps 3 and 4:\n    $$r(\\pi_n, \\delta_n) \\le V - \\epsilon$$\n\n6.  **Taking Limits:** Taking the limit as $n \\to \\infty$:\n    $$\\lim_{n \\to \\infty} r(\\pi_n, \\delta_n) \\le V - \\epsilon$$\n    $$V \\le V - \\epsilon$$\n    This is a contradiction since $\\epsilon > 0$. Therefore, $\\delta_0$ must be Minimax. $\\blacksquare$\n:::\n\n### Admissibility of Bayes Rules\n\nBayes rules are generally good candidates for admissibility. If a rule is Bayes, it is likely efficient, provided the prior doesn't ignore parts of the parameter space.\n\n::: {#thm-admissibility-finite}\n## Admissibility of Bayes Rules (Finite Support)\n\nIf the parameter space $\\Theta$ is finite (or countable) and the prior $\\pi$ assigns positive probability to every $\\theta \\in \\Theta$ (i.e., $\\pi(\\theta) > 0$ for all $\\theta$), then any Bayes rule $\\delta_\\pi$ is admissible.\n:::\n\n::: {.proof}\n\n1.  **Contradiction Setup:** Suppose $\\delta_\\pi$ is inadmissible. Then there exists a rule $\\delta'$ that dominates it. By definition of domination:\n    * $R(\\theta, \\delta') \\le R(\\theta, \\delta_\\pi)$ for all $\\theta$.\n    * $R(\\theta_k, \\delta') < R(\\theta_k, \\delta_\\pi)$ for at least one $\\theta_k$.\n\n2.  **Bayes Risk Difference:** Consider the difference in Bayes risk:\n    $$r(\\pi, \\delta_\\pi) - r(\\pi, \\delta') = \\sum_{\\theta \\in \\Theta} \\pi(\\theta) [R(\\theta, \\delta_\\pi) - R(\\theta, \\delta')]$$\n\n3.  **Strict Positivity:**\n    * Since $\\delta'$ dominates $\\delta_\\pi$, each term $[R(\\theta, \\delta_\\pi) - R(\\theta, \\delta')]$ is non-negative ($\\ge 0$).\n    * At $\\theta_k$, the term is strictly positive ($> 0$).\n    * We assumed the prior has full support, so $\\pi(\\theta) > 0$ for all $\\theta$.\n\n4.  **Summation:** A sum of non-negative terms where at least one term is strictly positive must be strictly positive.\n    $$r(\\pi, \\delta_\\pi) - r(\\pi, \\delta') > 0 \\implies r(\\pi, \\delta') < r(\\pi, \\delta_\\pi)$$\n\n5.  **Conclusion:** This contradicts the definition that $\\delta_\\pi$ is a Bayes rule (which must minimize Bayes risk). Therefore, $\\delta_\\pi$ is admissible. $\\blacksquare$\n:::\n\n### Admissibility of Unique Bayes Rules\n\nIf the Bayes rule is unique, we can drop the requirement that the parameter space be discrete or finite.\n\n::: {#thm-admissibility-unique}\n### Admissibility of Unique Bayes Rules\n\nLet $\\delta_\\pi$ be a Bayes rule with respect to $\\pi$. If $\\delta_\\pi$ is the **unique** Bayes rule (up to risk equivalence), then $\\delta_\\pi$ is admissible.\n:::\n\n::: {.proof}\n\n1.  **Contradiction Setup:** Suppose $\\delta_\\pi$ is inadmissible. Then there exists a rule $\\delta'$ such that:\n    $R(\\theta, \\delta') \\le R(\\theta, \\delta_\\pi)$ for all $\\theta$, with strict inequality for some set of $\\theta$.\n\n2.  **Bayes Risk Inequality:** Taking the expectation with respect to $\\pi$:\n    $$r(\\pi, \\delta') = \\int R(\\theta, \\delta') \\pi(\\theta) d\\theta \\le \\int R(\\theta, \\delta_\\pi) \\pi(\\theta) d\\theta = r(\\pi, \\delta_\\pi)$$\n\n3.  **Minimality:** Since $\\delta_\\pi$ is Bayes, it minimizes the risk, so $r(\\pi, \\delta_\\pi) \\le r(\\pi, \\delta')$.\n    Combining these gives $r(\\pi, \\delta') = r(\\pi, \\delta_\\pi)$.\n\n4.  **Uniqueness:** This implies that $\\delta'$ is also a Bayes rule.\n    However, we assumed that $\\delta_\\pi$ is the **unique** Bayes rule. Therefore, $\\delta'$ must be equal to $\\delta_\\pi$ (in terms of risk functions).\n\n5.  **Conclusion:** If $\\delta'$ and $\\delta_\\pi$ have identical risk functions, then $\\delta'$ cannot strictly dominate $\\delta_\\pi$. This contradicts the assumption of inadmissibility. Thus, $\\delta_\\pi$ is admissible. $\\blacksquare$\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}