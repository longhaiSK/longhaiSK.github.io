{
  "hash": "2855b5aba9f5badf137a3aad668a4a3d",
  "result": {
    "engine": "knitr",
    "markdown": "# Bayesian Methods\n\n## Fundamental Elements of Bayesian Inference\n\nThe foundation of Bayesian inference relies on the relationship between the prior distribution, the likelihood of the data, and the posterior distribution. This relationship is governed by Bayes' Theorem (or Law).\n\n::: {#def-posterior}\n### Posterior Distribution\n\nSuppose we have a parameter $\\theta$ with a prior distribution denoted by $\\pi(\\theta)$. If we observe data $x$ drawn from a distribution with probability density function (pdf) $f(x; \\theta)$, then the **posterior density** of $\\theta$ given the data $x$ is defined as:\n\n$$\n\\pi(\\theta|x) = \\frac{\\pi(\\theta) f(x;\\theta)}{m(x)}\n$$\n\nwhere $m(x)$ is the **marginal distribution** (or marginal likelihood) of the data, calculated as:\n$$\nm(x) = \\int_{\\Theta} \\pi(\\theta) f(x;\\theta) d\\theta\n$$\n\nIn this context, $m(x)$ acts as a normalizing constant. Since it depends only on the data $x$ and not on the parameter $\\theta$, it ensures that the posterior density integrates to 1 but does not influence the **shape** of the posterior distribution.\n\nThus, we often state the proportional relationship:\n\n$$\n\\pi(\\theta|x) \\propto \\pi(\\theta) f(x;\\theta)\n$$\n:::\n\n\n\n::: {#exm-binomial-beta}\n### Binomial-beta Conjugacy\n\nConsider an experiment where $x|\\theta \\sim \\text{Bin}(n, \\theta)$. The likelihood function is:\n\n$$\nf(x|\\theta) = \\binom{n}{x} \\theta^x (1-\\theta)^{n-x}\n$$\n\nSuppose we choose a Beta distribution as the prior for $\\theta$, such that $\\theta \\sim \\text{Beta}(a, b)$. The prior density is:\n\n$$\n\\pi(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n$$\n\nwhere $B(a,b)$ is the Beta function defined as $\\int_{0}^{1} \\theta^{a-1}(1-\\theta)^{b-1} d\\theta$.\n\nTo find the posterior, we multiply the prior and the likelihood:\n\n$$\n\\pi(\\theta|x) \\propto \\theta^{a-1}(1-\\theta)^{b-1} \\cdot \\theta^x (1-\\theta)^{n-x}\n$$\n\nCombining terms with the same base:\n\n$$\n\\pi(\\theta|x) \\propto \\theta^{a+x-1} (1-\\theta)^{b+n-x-1}\n$$\n\nWe can recognize this kernel as a Beta distribution. Therefore, we conclude that the posterior distribution is:\n\n$$\n\\theta|x \\sim \\text{Beta}(a+x, b+n-x)\n$$\n\n**Properties of the Posterior:**\n\n* The posterior mean is:\n    $$E(\\theta|x) = \\frac{a+x}{a+b+n}$$\n    As $n \\to \\infty$, this approximates the maximum likelihood estimate $\\frac{x}{n}$.\n\n* The posterior variance is:\n    $$\\text{Var}(\\theta|x) = \\frac{(a+x)(n+b-x)}{(a+b+n)^2(a+b+n+1)}$$\n    For large $n$, this approximates $\\frac{x(n-x)}{n^3} = \\frac{\\hat{p}(1-\\hat{p})}{n}$.\n\n**Numerical Illustration:**\n\nSuppose we are estimating a probability $\\theta$.\n\n* **Prior:** $\\theta \\sim \\text{Beta}(2, 2)$ (Mean = 0.5).\n* **Data:** 10 trials, 8 successes ($n=10, x=8$).\n* **Posterior:** $\\theta|x \\sim \\text{Beta}(2+8, 2+2) = \\text{Beta}(10, 4)$ (Mean $\\approx$ 0.71).\n\nThe plot below shows the prior (dashed) and posterior (solid) densities.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- seq(0, 1, length.out = 200)\n\n# Prior: Beta(2, 2)\nprior <- dbeta(theta, shape1 = 2, shape2 = 2)\n\n# Posterior: Beta(10, 4)\nposterior <- dbeta(theta, shape1 = 10, shape2 = 4)\n\nplot(theta, posterior, type = 'l', lwd = 2, col = \"blue\",\n     xlab = expression(theta), ylab = \"Density\",\n     main = \"Beta Prior vs Posterior\", ylim = c(0, max(c(prior, posterior))))\nlines(theta, prior, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"Prior Beta(2,2)\", \"Posterior Beta(10,4)\"),\n       col = c(\"red\", \"blue\"), lty = c(2, 1), lwd = 2)\n```\n\n::: {.cell-output-display}\n![Prior vs Posterior for Beta-Binomial Example](bayesian_files/figure-html/fig-beta-conjugacy-1.png){#fig-beta-conjugacy width=576}\n:::\n:::\n\n\n\n\n\n\n\n:::\n\n::: {#exm-normal-normal}\n### Normal-normal Conjugacy (known Variance)\n\nLet $X_1, X_2, \\dots, X_n$ be independent and identically distributed (i.i.d.) variables such that $X_i \\sim N(\\mu, \\sigma^2)$, where $\\sigma^2$ is known.\n\nWe assign a Normal prior to the mean $\\mu$: $\\mu \\sim N(\\mu_0, \\sigma_0^2)$.\n\nTo find the posterior $\\pi(\\mu|x_1, \\dots, x_n)$, let $x = (x_1, \\dots, x_n)$. The posterior is proportional to:\n\n$$\n\\pi(\\mu|x) \\propto \\pi(\\mu) \\cdot f(x|\\mu)\n$$\n\n$$\n\\propto \\exp\\left\\{-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2}\\right\\} \\cdot \\exp\\left\\{-\\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right\\}\n$$\n\n\n\n**Posterior Precision:**\n\nIt is often more convenient to work with **precision** (the inverse of variance). Let:\n\n* $\\tau_0 = 1/\\sigma_0^2$ (Prior precision)\n* $\\tau = 1/\\sigma^2$ (Data precision)\n* $\\tau_1 = 1/\\sigma_1^2$ (Posterior precision)\n\nThe relationship is additive:\n\n$$\n\\tau_1 = \\tau_0 + n\\tau\n$$\n\n$$\n\\text{Posterior Precision} = \\text{Prior Precision} + \\text{Precision of Data}\n$$\n\nThe posterior mean $\\mu_1$ is a weighted average of the prior mean and the sample mean:\n\n$$\n\\mu_1 = \\frac{\\mu_0 \\tau_0 + n\\bar{x}\\tau}{\\tau_0 + n\\tau}\n$$\n\nSo, the posterior distribution is:\n\n$$\n\\mu|x_1, \\dots, x_n \\sim N\\left( \\frac{\\mu_0 \\tau_0 + n\\bar{x}\\tau}{\\tau_0 + n\\tau}, \\frac{1}{\\tau_0 + n\\tau} \\right)\n$$\n\n**Numerical Illustration:**\n\nSuppose we estimate a mean height $\\mu$.\n\n* **Known Variance:** $\\sigma^2 = 100$ ($\\tau = 0.01$).\n* **Prior:** $\\mu \\sim N(175, 25)$ (Precision $\\tau_0 = 0.04$).\n* **Data:** $n=10, \\bar{x}=180$. (Total data precision $n\\tau = 0.1$).\n* **Posterior:**\n  * Precision $\\tau_1 = 0.04 + 0.1 = 0.14$.\n  * Variance $\\sigma_1^2 \\approx 7.14$.\n  * Mean $\\mu_1 = \\frac{175(0.04) + 180(0.1)}{0.14} \\approx 178.6$.\n\nThe plot below illustrates the prior (dashed) and posterior (solid) normal densities.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_vals <- seq(150, 200, length.out = 200)\n\n# Prior: N(175, 25) -> SD = 5\nprior_norm <- dnorm(mu_vals, mean = 175, sd = 5)\n\n# Posterior: N(178.6, 7.14) -> SD = Sqrt(7.14) Approx 2.67\nposterior_norm <- dnorm(mu_vals, mean = 178.6, sd = sqrt(7.14))\n\nplot(mu_vals, posterior_norm, type = 'l', lwd = 2, col = \"blue\",\n     xlab = expression(mu), ylab = \"Density\",\n     main = \"Normal Prior vs Posterior\",\n     ylim = c(0, max(c(prior_norm, posterior_norm))))\nlines(mu_vals, prior_norm, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"Prior N(175, 25)\", \"Posterior N(178.6, 7.14)\"),\n       col = c(\"red\", \"blue\"), lty = c(2, 1), lwd = 2)\n```\n\n::: {.cell-output-display}\n![Prior vs Posterior for Normal-Normal Example](bayesian_files/figure-html/fig-normal-conjugacy-1.png){#fig-normal-conjugacy width=576}\n:::\n:::\n\n\n\n\n\n\n\n:::\n\n::: {#exm-discrete-posterior}\n### Discrete Posterior Calculation\n\nConsider the following table where we calculate the posterior probabilities for a discrete parameter space.\n\nLet the parameter $\\theta$ take values $\\{1, 2, 3\\}$ with prior probabilities $\\pi(\\theta)$. Let the data $x$ take values $\\{0, 1, 2, \\dots\\}$.\n\nGiven:\n\n* Prior $\\pi(\\theta)$: $\\pi(1)=1/3, \\pi(2)=1/3, \\pi(3)=1/3$.\n* Likelihood $\\pi(x|\\theta)$:\n    * If $\\theta=1$, $x \\sim \\text{Uniform on } \\{0, 1\\}$ (Prob = 1/2).\n    * If $\\theta=2$, $x \\sim \\text{Uniform on } \\{0, 1, 2\\}$ (Prob = 1/3).\n    * If $\\theta=3$, $x \\sim \\text{Uniform on } \\{0, 1, 2, 3\\}$ (Prob = 1/4).\n\nSuppose we observe $x=2$. The calculation of the posterior probabilities is summarized in the table below:\n\n| | $\\theta=1$ | $\\theta=2$ | $\\theta=3$ | Sum |\n|:---|:---:|:---:|:---:|:---:|\n| **Prior** $\\pi(\\theta)$ | $1/3$ | $1/3$ | $1/3$ | $1$ |\n| **Likelihood** $\\pi(x=2|\\theta)$ | $0$ | $1/3$ | $1/4$ | - |\n| **Product** $\\pi(\\theta)\\pi(x|\\theta)$ | $0$ | $1/9$ | $1/12$ | $7/36$ |\n| **Posterior** $\\pi(\\theta|x)$ | $0$ | $4/7$ | $3/7$ | $1$ |\n\nThe marginal sum (evidence) is calculated as $0 + 1/9 + 1/12 = 4/36 + 3/36 = 7/36$. The posterior values are obtained by dividing the product row by this sum.\n:::\n\n::: {#exm-Normal-with-Unknown-Mean-and-Variance}\n### Normal with Unknown Mean and Variance\n\nConsider $X_1, \\dots, X_n \\sim N(\\mu, 1/\\tau)$, where both $\\mu$ and the precision $\\tau$ are unknown.\n\nWe use a **Normal-Gamma** conjugate prior:\n\n1.  $\\tau \\sim \\text{Gamma}(\\alpha, \\beta)$\n    $$\\pi(\\tau) \\propto \\tau^{\\alpha-1} e^{-\\beta\\tau}$$\n\n2.  $\\mu|\\tau \\sim N(\\nu, 1/(k\\tau))$\n    $$\\pi(\\mu|\\tau) \\propto \\tau^{1/2} e^{-\\frac{k\\tau}{2}(\\mu-\\nu)^2}$$\n\nThe joint prior is the product of the conditional and the marginal:\n$$\n\\pi(\\mu, \\tau) \\propto \\tau^{\\alpha - 1/2} \\exp\\left\\{ -\\tau \\left( \\beta + \\frac{k}{2}(\\mu - \\nu)^2 \\right) \\right\\}\n$$\n\n**Derivation of the Posterior:**\n\nFirst, we write the likelihood in terms of the sufficient statistics $\\bar{x}$ and $S_{xx} = \\sum (x_i - \\bar{x})^2$:\n$$\nL(\\mu, \\tau|x) \\propto \\tau^{n/2} \\exp\\left\\{ -\\frac{\\tau}{2} \\left[ S_{xx} + n(\\bar{x}-\\mu)^2 \\right] \\right\\}\n$$\n\nMultiplying the prior by the likelihood gives the joint posterior:\n$$\n\\begin{aligned}\n\\pi(\\mu, \\tau | x) &\\propto \\tau^{\\alpha - 1/2} e^{-\\beta\\tau} e^{-\\frac{k\\tau}{2}(\\mu-\\nu)^2} \\cdot \\tau^{n/2} e^{-\\frac{\\tau}{2}S_{xx}} e^{-\\frac{n\\tau}{2}(\\mu-\\bar{x})^2} \\\\\n&\\propto \\tau^{\\alpha + n/2 - 1/2} \\exp\\left\\{ -\\tau \\left[ \\beta + \\frac{S_{xx}}{2} + \\frac{1}{2}\\left( k(\\mu-\\nu)^2 + n(\\mu-\\bar{x})^2 \\right) \\right] \\right\\}\n\\end{aligned}\n$$\n\nNext, we complete the square for the terms involving $\\mu$ inside the brackets. It can be shown that:\n$$\nk(\\mu-\\nu)^2 + n(\\mu-\\bar{x})^2 = (k+n)\\left(\\mu - \\frac{k\\nu+n\\bar{x}}{k+n}\\right)^2 + \\frac{nk}{n+k}(\\bar{x}-\\nu)^2\n$$\n\nSubstituting this back into the joint density and grouping terms that do not depend on $\\mu$:\n$$\n\\pi(\\mu, \\tau | x) \\propto \\underbrace{\\tau^{\\alpha + n/2 - 1} \\exp\\left\\{ -\\tau \\left[ \\beta + \\frac{S_{xx}}{2} + \\frac{nk}{2(n+k)}(\\bar{x}-\\nu)^2 \\right] \\right\\}}_{\\text{Marginal of } \\tau} \\cdot \\underbrace{\\tau^{1/2} \\exp\\left\\{ -\\frac{(k+n)\\tau}{2} \\left( \\mu - \\frac{k\\nu+n\\bar{x}}{k+n} \\right)^2 \\right\\}}_{\\text{Conditional of } \\mu|\\tau}\n$$\n\n**Results:**\n\nBy inspecting the factored equation above, we identify the updated parameters:\n\n* **Marginal Posterior of $\\tau$:**\n    The first part corresponds to a Gamma kernel $\\tau^{\\alpha' - 1} e^{-\\beta'\\tau}$.\n    $$\\tau|x \\sim \\text{Gamma}(\\alpha', \\beta')$$\n    where $\\alpha' = \\alpha + n/2$ and $\\beta' = \\beta + \\frac{1}{2}\\sum(x_i-\\bar{x})^2 + \\frac{nk}{2(n+k)}(\\bar{x}-\\nu)^2$.\n\n* **Conditional Posterior of $\\mu$:**\n    The second part corresponds to a Normal kernel with precision $k'\\tau$.\n    $$\\mu|\\tau, x \\sim N(\\nu', 1/(k'\\tau))$$\n    where $k' = k + n$ and $\\nu' = \\frac{k\\nu + n\\bar{x}}{k+n}$.\n:::\n\n## Paradigm to Find Bayes Rules\n\nThe general form of Bayes rule is derived by minimizing risk.\n\n::: {#def-risk}\n### Risk Function and Bayes Risk\n\n* **Risk Function:** $R(\\theta, d) = \\int_{X} L(\\theta, d(x)) f(x;\\theta) dx$\n* **Bayes Risk:** The expected risk with respect to the prior.\n    $$r(\\pi, d) = \\int_{\\Theta} R(\\theta, d) \\pi(\\theta) d\\theta$$\n:::\n\n::: {#thm-bayes-rule-minimization}\n### Minimization of Bayes Risk\n\nMinimizing the Bayes risk $r(\\pi, d)$ is equivalent to minimizing the posterior expected loss for each observed $x$. That is, the Bayes rule $d(x)$ satisfies:\n$$\nd(x) = \\underset{a}{\\arg\\min} \\ E_{\\theta|x} [ L(\\theta, a) ]\n$$\n:::\n\n::: {.proof}\nWe start by writing the Bayes risk essentially as a double integral over the parameters and the data. Substituting the definition of the risk function $R(\\theta, d)$:\n\n$$\n\\begin{aligned}\nr(\\pi, d) &= \\int_{\\Theta} R(\\theta, d) \\pi(\\theta) d\\theta \\\\\n&= \\int_{\\Theta} \\left[ \\int_{X} L(\\theta, d(x)) f(x|\\theta) dx \\right] \\pi(\\theta) d\\theta\n\\end{aligned}\n$$\n\nAssuming the conditions for Fubini's Theorem are met, we switch the order of integration:\n\n$$\nr(\\pi, d) = \\int_{X} \\left[ \\int_{\\Theta} L(\\theta, d(x)) f(x|\\theta) \\pi(\\theta) d\\theta \\right] dx\n$$\n\nRecall that the joint density can be factored as $f(x, \\theta) = f(x|\\theta)\\pi(\\theta) = \\pi(\\theta|x)m(x)$, where $m(x)$ is the marginal density of the data. Substituting this into the inner integral:\n\n$$\n\\begin{aligned}\nr(\\pi, d) &= \\int_{X} \\left[ \\int_{\\Theta} L(\\theta, d(x)) \\pi(\\theta|x) m(x) d\\theta \\right] dx \\\\\n&= \\int_{X} m(x) \\left[ \\int_{\\Theta} L(\\theta, d(x)) \\pi(\\theta|x) d\\theta \\right] dx\n\\end{aligned}\n$$\n\nSince the marginal density $m(x)$ is non-negative, minimizing the total integral $r(\\pi, d)$ with respect to the decision rule $d(\\cdot)$ is equivalent to minimizing the term inside the brackets for every $x$ (specifically where $m(x) > 0$).\n\nThe term inside the brackets is the **Posterior Expected Loss**:\n\n$$\n\\int_{\\Theta} L(\\theta, d(x)) \\pi(\\theta|x) d\\theta = E_{\\theta|x} [ L(\\theta, d(x)) ]\n$$\n\n\n:::\n\n\n\n:::{.callout-important}\nTherefore, to minimize the Bayes risk, one just need to  choose $d(x)$ to minimize the posterior expected loss for each $x$.\n:::\n\nThe following diagram summarizes the general workflow for deriving a Bayes estimator:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Workflow for Finding the Bayes Rule](bayesian_files/figure-html/fig-bayes-workflow-1.png){#fig-bayes-workflow fig-align='center' width=576 style=\"width: 80% !important;\"}\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Common Loss Functions and Bayes Estimators\n\n### Squared Error Loss (point Estimate)\n\n$$L(\\theta, a) = (\\theta - a)^2$$\n\nTo find the optimal estimator $d(x)$, we minimize the posterior expected loss $E_{\\theta|x}[(\\theta - d(x))^2]$. Taking the derivative with respect to $d$ and setting it to 0:\n\n$$-2 E_{\\theta|x}(\\theta - d) = 0 \\implies d(x) = E(\\theta|x)$$\n\n**Result:** The Bayes rule under squared error loss is the **posterior mean**.\n\n### Absolute Error Loss\n\n$$L(\\theta, d) = |\\theta - d|$$\n\nTo find the Bayes rule, we minimize the posterior expected loss:\n\n$$\n\\psi(d) = E_{\\theta|x} [ |\\theta - d| ] = \\int_{-\\infty}^{\\infty} |\\theta - d| \\, dF(\\theta|x)\n$$\n\nwhere $F(\\theta|x)$ is the cumulative distribution function (CDF) of the posterior. Splitting the integral at the decision point $d$:\n\n$$\n\\psi(d) = \\int_{-\\infty}^{d} (d - \\theta) \\, dF(\\theta|x) + \\int_{d}^{\\infty} (\\theta - d) \\, dF(\\theta|x)\n$$\n\nWe find the minimum by analyzing the rate of change of $\\psi(d)$ with respect to $d$. Differentiating (or taking the subgradient for non-differentiable points):\n\n$$\n\\frac{d}{dd} \\psi(d) = \\int_{-\\infty}^{d} 1 \\, dF(\\theta|x) - \\int_{d}^{\\infty} 1 \\, dF(\\theta|x) = P(\\theta \\le d|x) - P(\\theta > d|x)\n$$\n\nSetting this derivative to zero implies we seek a point where the probability mass to the left equals the probability mass to the right:\n\n$$\nP(\\theta \\le d|x) = P(\\theta > d|x)\n$$\n\nSince the total probability is 1, this condition simplifies to finding $d$ such that the cumulative probability is $1/2$.\n\n**General Case (Discrete or Mixed Distributions)**\n\nIn cases where the posterior distribution is discrete or has jump discontinuities (e.g., the CDF jumps from 0.4 to 0.6 at a specific value), an exact solution to $F(d) = 0.5$ may not exist. To generalize, the Bayes rule is defined as any **median** $m$ of the posterior distribution.\n\nA median is formally defined as any value $m$ that satisfies the following two conditions simultaneously:\n\n* $P(\\theta \\le m|x) \\ge \\frac{1}{2}$\n* $P(\\theta \\ge m|x) \\ge \\frac{1}{2}$\n\n**Result:** The Bayes rule under absolute error loss is the **posterior median**.\n\n### Hypothesis Testing (0-1 Loss)\n\nConsider the hypothesis test $H_0: \\theta \\in \\Theta_0$ versus $H_1: \\theta \\in \\Theta_1$. We define the decision space as $\\mathcal{A} = \\{0, 1\\}$, where $a=0$ means accepting $H_0$ and $a=1$ means rejecting $H_0$ (accepting $H_1$).\n\n**Case 1: 0-1 Loss**\n\nThe standard 0-1 loss function assigns a penalty of 1 for an incorrect decision and 0 for a correct one:\n$$L(\\theta, a) = \\begin{cases} 0 & \\text{if } \\theta \\in \\Theta_0, a=0 \\ (\\text{Correct } H_0) \\\\ 1 & \\text{if } \\theta \\in \\Theta_0, a=1 \\ (\\text{Type I Error}) \\\\ 1 & \\text{if } \\theta \\in \\Theta_1, a=0 \\ (\\text{Type II Error}) \\\\ 0 & \\text{if } \\theta \\in \\Theta_1, a=1 \\ (\\text{Correct } H_1) \\end{cases}$$\n\nTo find the Bayes rule, we minimize the **posterior expected loss** for a given $x$, denoted as $E_{\\theta|x}[L(\\theta, a)]$.\n\n* **Expected Loss for choosing $a=0$ (Accept $H_0$):**\n    $$\n    E_{\\theta|x}[L(\\theta, 0)] = 0 \\cdot P(\\theta \\in \\Theta_0|x) + 1 \\cdot P(\\theta \\in \\Theta_1|x) = P(\\theta \\in \\Theta_1|x)\n    $$\n\n* **Expected Loss for choosing $a=1$ (Reject $H_0$):**\n    $$\n    E_{\\theta|x}[L(\\theta, 1)] = 1 \\cdot P(\\theta \\in \\Theta_0|x) + 0 \\cdot P(\\theta \\in \\Theta_1|x) = P(\\theta \\in \\Theta_0|x)\n    $$\n\nThe Bayes rule selects the action with the smaller expected loss. Thus, we choose $a=1$ if:\n$$\nP(\\theta \\in \\Theta_0|x) \\le P(\\theta \\in \\Theta_1|x)\n$$\nThis confirms that under 0-1 loss, the Bayes rule simply selects the hypothesis with the higher posterior probability.\n\n**Case 2: General Loss (Asymmetric Costs)**\n\nIn many practical applications, the cost of errors is not symmetric. For example, a Type I error (false rejection) might be more costly than a Type II error. Let $c_1$ be the cost of a Type I error and $c_2$ be the cost of a Type II error. Usually, we normalize one cost to 1.\n\nSuppose the loss function is:\n$$L(\\theta, a) = \\begin{cases} 0 & \\text{if } \\theta \\in \\Theta_0, a=0 \\\\ c & \\text{if } \\theta \\in \\Theta_0, a=1 \\ (\\text{Cost of Type I Error}) \\\\ 1 & \\text{if } \\theta \\in \\Theta_1, a=0 \\ (\\text{Cost of Type II Error}) \\\\ 0 & \\text{if } \\theta \\in \\Theta_1, a=1 \\end{cases}$$\n\nWe again calculate the posterior expected loss:\n\n* **Expected Loss for $a=0$:**\n    $$E[L(\\theta, 0)|x] = 0 \\cdot P(\\Theta_0|x) + 1 \\cdot P(\\Theta_1|x) = P(\\Theta_1|x)$$\n\n* **Expected Loss for $a=1$:**\n    $$E[L(\\theta, 1)|x] = c \\cdot P(\\Theta_0|x) + 0 \\cdot P(\\Theta_1|x) = c P(\\Theta_0|x)$$\n\nWe reject $H_0$ ($a=1$) if the expected loss of doing so is lower:\n$$\nc P(\\Theta_0|x) \\le P(\\Theta_1|x)\n$$\n\nSince $P(\\Theta_1|x) = 1 - P(\\Theta_0|x)$, we can rewrite this condition as:\n$$\nc P(\\Theta_0|x) \\le 1 - P(\\Theta_0|x) \\implies (1+c) P(\\Theta_0|x) \\le 1\n$$\n$$\nP(\\Theta_0|x) \\le \\frac{1}{1+c}\n$$\n\n**Result:** With asymmetric costs, we accept $H_1$ only if the posterior probability of the null hypothesis is sufficiently small (below the threshold $\\frac{1}{1+c}$). If the cost of false rejection $c$ is high, we require stronger evidence against $H_0$.\n\n### Classification Prediction (categorical Parameter)\n\nIn classification problems, the parameter of interest is a discrete class label $\\theta$ (often denoted as $y$) taking values in a set of categories $\\{1, 2, \\dots, K\\}$. The goal is to predict the true class label based on observed features $x$.\n\nWe typically employ the **0-1 loss function**, which assigns a penalty of 1 for a misclassification and 0 for a correct prediction:\n\n$$L(\\theta, \\hat{\\theta}) = \\begin{cases} 0 & \\text{if } \\hat{\\theta} = \\theta \\ (\\text{Correct Classification}) \\\\ 1 & \\text{if } \\hat{\\theta} \\neq \\theta \\ (\\text{Misclassification}) \\end{cases}$$\n\nTo find the optimal classification rule (the Bayes Classifier), we minimize the posterior expected loss, which is equivalent to minimizing the probability of misclassification.\n\n$$\nE_{\\theta|x}[L(\\theta, \\hat{\\theta})] = \\sum_{\\theta} L(\\theta, \\hat{\\theta}) \\pi(\\theta|x)\n$$\n\nSince the loss is 1 only when the predicted class $\\hat{\\theta}$ differs from the true class $\\theta$, this sum simplifies to:\n\n$$\nE_{\\theta|x}[L(\\theta, \\hat{\\theta})] = \\sum_{\\theta \\neq \\hat{\\theta}} 1 \\cdot \\pi(\\theta|x) = P(\\theta \\neq \\hat{\\theta} | x) = 1 - P(\\theta = \\hat{\\theta} | x)\n$$\n\nMinimizing the misclassification rate $1 - P(\\theta = \\hat{\\theta} | x)$ is mathematically equivalent to maximizing the probability of being correct, $P(\\theta = \\hat{\\theta} | x)$.\n\n**Result:** The Bayes rule for classification is to predict the class with the highest posterior probability. While this is technically the **Maximum A Posteriori (MAP)** estimator, in the context of machine learning and pattern recognition, this decision rule is known as the **Bayes Optimal Classifier**.\n\n$$\n\\hat{\\theta}_{\\text{Bayes}}(x) = \\underset{k \\in \\{1, \\dots, K\\}}{\\arg\\max} \\ P(\\theta = k | x)\n$$\n\n\n### Interval Estimation and Highest Posterior Density (HPD)\n\nIn interval estimation, our goal is typically to find a set $C(x)$ with a specified probability coverage $1-\\alpha$ (i.e., $P(\\theta \\in C(x)|x) = 1-\\alpha$) that minimizes the \"size\" or length of the interval.\n\n**Loss Function for HPD:**\nThe HPD interval can be formally derived as the Bayes rule under a loss function that linearly combines the size of the interval and the error of non-coverage:\n\n$$\nL(\\theta, C) = \\text{Length}(C) + k \\cdot I(\\theta \\notin C)\n$$\n\nwhere $k$ is a positive constant representing the penalty for failing to include the true parameter $\\theta$. Minimizing the posterior expected loss leads to including all values of $\\theta$ where the posterior density $\\pi(\\theta|x)$ exceeds $1/k$. By adjusting $k$, we control the credibility level $1-\\alpha$.\n\n**Justification for HPD:**\nTo minimize the length of the interval for a fixed probability mass (or equivalently, minimize this loss function), we should include the values of $\\theta$ that have the highest probability density. If we include a value with low density while excluding a value with higher density, we could swap them to increase the probability mass without increasing the interval length (or conversely, shrink the length while maintaining the mass).\n\nTherefore, the **Highest Posterior Density (HPD)** interval is defined as:\n$$C_{HPD} = \\{ \\theta : \\pi(\\theta|x) \\ge k_\\alpha \\}$$\nwhere $k_\\alpha$ is a threshold chosen such that the posterior probability of the set is $1-\\alpha$.\n\n**Comparison with Equal-Tailed Intervals:**\n\n* **Equal-Tailed Interval:** We simply cut off $\\alpha/2$ probability from each tail of the distribution. This is easy to compute but may not be the shortest interval if the distribution is skewed.\n* **HPD Interval:** This is the shortest possible interval for the given coverage. For unimodal distributions, the probability density at the two endpoints of the HPD interval is identical.\n\nThe plot below illustrates a skewed posterior distribution (Gamma). Notice how the **HPD Interval (Blue)** is shifted toward the mode (the peak) to capture the highest density values, resulting in a shorter interval length compared to the **Equal-Tailed Interval (Red)**.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a Skewed Distribution: Gamma(shape=2, Rate=0.5)\nx_vals <- seq(0, 15, length.out = 1000)\ny_vals <- dgamma(x_vals, shape = 2, rate = 0.5)\n\n# Target Coverage\nalpha <- 0.10\ntarget_prob <- 1 - alpha\n\n# 1. Equal-tailed Interval (quantiles)\neq_lower <- qgamma(alpha/2, shape = 2, rate = 0.5)\neq_upper <- qgamma(1 - alpha/2, shape = 2, rate = 0.5)\n\n# 2. HPD Interval (density Threshold Optimization)\n# We Look for a Density Threshold K Such That the Area Above K Is 0.90\nfind_hpd <- function(dist_vals, density_vals, probability) {\n  # Sort density values\n  ord <- order(density_vals, decreasing = TRUE)\n  sorted_dens <- density_vals[ord]\n  sorted_dist <- dist_vals[ord]\n  \n  # Accumulate probability (approximation)\n  dx <- diff(dist_vals)[1]\n  cum_prob <- cumsum(sorted_dens * dx)\n  \n  # Find cutoff index\n  cutoff_idx <- which(cum_prob >= probability)[1]\n  \n  # Get the subset of x values\n  hpd_set <- sorted_dist[1:cutoff_idx]\n  return(c(min(hpd_set), max(hpd_set)))\n}\n\nhpd_bounds <- find_hpd(x_vals, y_vals, target_prob)\nhpd_lower <- hpd_bounds[1]\nhpd_upper <- hpd_bounds[2]\n\n# Plotting\nplot(x_vals, y_vals, type = 'l', lwd = 2, col = \"black\",\n     main = \"90% Credible Intervals (Skewed Posterior)\",\n     xlab = expression(theta), ylab = \"Density\",\n     ylim = c(0, max(y_vals) * 1.2))\n\n# Shade HPD\npolygon(c(x_vals[x_vals >= hpd_lower & x_vals <= hpd_upper], hpd_upper, hpd_lower),\n        c(y_vals[x_vals >= hpd_lower & x_vals <= hpd_upper], 0, 0),\n        col = rgb(0, 0, 1, 0.2), border = NA)\n\n# Draw Equal-tailed Lines (red)\nabline(v = c(eq_lower, eq_upper), col = \"red\", lwd = 2, lty = 2)\n# Draw HPD Lines (blue)\nabline(v = c(hpd_lower, hpd_upper), col = \"blue\", lwd = 2, lty = 1)\n\nlegend(\"topright\", \n       legend = c(\"Posterior Density\", \n                  paste0(\"Equal-Tailed (Len: \", round(eq_upper - eq_lower, 2), \")\"), \n                  paste0(\"HPD (Len: \", round(hpd_upper - hpd_lower, 2), \")\")),\n       col = c(\"black\", \"red\", \"blue\"), \n       lty = c(1, 2, 1), lwd = 2,\n       fill = c(NA, NA, rgb(0, 0, 1, 0.2)), border = NA)\n```\n\n::: {.cell-output-display}\n![Comparison of HPD and Equal-Tailed Intervals for a Skewed Distribution](bayesian_files/figure-html/fig-hpd-vs-equal-1.png){#fig-hpd-vs-equal width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Constant Risk Bayes Estimator Is Minimax\n\nA decision rule $d(x)$ is **minimax** if it minimizes the maximum possible risk: $\\sup_\\theta R(\\theta, d)$.\n\n::: {#thm-minimax-constant}\n### Constant Risk Bayes Estimator Is Minimax\n\nLet $\\delta^\\pi$ be a Bayes estimator with respect to a prior $\\pi$. If the risk function of $\\delta^\\pi$ is constant on the parameter space $\\Theta$, such that $R(\\theta, \\delta^\\pi) = c$ for all $\\theta \\in \\Theta$, then $\\delta^\\pi$ is a minimax estimator.\n:::\n\n::: {.proof}\nLet $\\delta^\\pi$ be the Bayes estimator with constant risk $c$. First, we compute its Bayes risk $r(\\pi, \\delta^\\pi)$. Since the risk is constant:\n\n$$\nr(\\pi, \\delta^\\pi) = \\int_\\Theta R(\\theta, \\delta^\\pi) \\pi(\\theta) d\\theta = \\int_\\Theta c \\, \\pi(\\theta) d\\theta = c\n$$\n\nNow, let $\\delta'$ be any arbitrary estimator. By the definition of a Bayes estimator, $\\delta^\\pi$ minimizes the Bayes risk among all estimators:\n\n$$\nr(\\pi, \\delta^\\pi) \\le r(\\pi, \\delta')\n$$\n\nNext, we observe that the Bayes risk of $\\delta'$ is the expectation of its risk function with respect to the prior $\\pi$. An average cannot exceed the maximum value of the function being averaged (the supremum):\n\n$$\nr(\\pi, \\delta') = \\int_\\Theta R(\\theta, \\delta') \\pi(\\theta) d\\theta \\le \\sup_{\\theta \\in \\Theta} R(\\theta, \\delta') \\cdot \\int_\\Theta \\pi(\\theta) d\\theta = \\sup_{\\theta \\in \\Theta} R(\\theta, \\delta')\n$$\n\nCombining these inequalities, we have:\n\n$$\n\\sup_{\\theta \\in \\Theta} R(\\theta, \\delta^\\pi) = c = r(\\pi, \\delta^\\pi) \\le r(\\pi, \\delta') \\le \\sup_{\\theta \\in \\Theta} R(\\theta, \\delta')\n$$\n\nSince $\\sup_\\theta R(\\theta, \\delta^\\pi) \\le \\sup_\\theta R(\\theta, \\delta')$ holds for any estimator $\\delta'$, $\\delta^\\pi$ minimizes the maximum risk. Therefore, it is minimax.\n:::\n\nThe plot below visualizes the logic of the proof. The red line represents the **Constant Risk Bayes Estimator** ($\\delta^\\pi$), which has a constant height $c$. The blue curve represents an **Arbitrary Estimator** ($\\delta'$).\n\nBecause $\\delta^\\pi$ minimizes the *weighted average* risk (Bayes risk), the average height of the blue curve cannot be lower than the red line (with respect to the prior). Consequently, the blue curve must rise above the red line at some point, making its maximum risk ($\\sup R$) strictly greater than or equal to $c$. Thus, the constant risk estimator has the lowest possible maximum.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define Parameter Space Theta\ntheta <- seq(0, 1, length.out = 200)\n\n# 1. Constant Risk Bayes Estimator (risk = C)\nc_val <- 0.5\nrisk_bayes <- rep(c_val, length(theta))\n\n# 2. Arbitrary Alternative Estimator\n# This Function Is Chosen Such That It Dips Below C but Rises Above It Elsewhere\nrisk_alt <- c_val + 0.2 * sin(2 * pi * theta) - 0.05\n\n# Plotting\nplot(theta, risk_alt, type = 'l', lwd = 2, col = \"blue\",\n     ylim = c(0, 1), ylab = \"Risk R(theta, d)\", xlab = expression(theta),\n     main = \"Geometry of the Minimax Theorem\")\n\n# Add Constant Risk Line\nlines(theta, risk_bayes, col = \"red\", lwd = 2)\n\n# Mark the Maximum of the Alternative\nmax_alt <- max(risk_alt)\nmax_theta <- theta[which.max(risk_alt)]\npoints(max_theta, max_alt, pch = 19, col = \"blue\")\ntext(max_theta, max_alt, labels = expression(sup~R(theta, delta^\"'\")), pos = 3, col = \"blue\")\n\n# Label the Constant Risk\ntext(0.1, c_val, labels = expression(R(theta, delta^pi) == c), pos = 3, col = \"red\")\n\n# Add Legend\nlegend(\"bottomright\", legend = c(\"Arbitrary Estimator\", \"Constant Risk Bayes Est.\"),\n       col = c(\"blue\", \"red\"), lwd = 2, lty = 1)\n```\n\n::: {.cell-output-display}\n![Visual Proof: Any alternative estimator (Blue) with Bayes risk comparable to the Constant Risk estimator (Red) must have a higher maximum risk.](bayesian_files/figure-html/fig-minimax-proof-1.png){#fig-minimax-proof width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n::: {#exm-binomial-minimax}\n### Binomial Minimax Estimator\n\nLet $X \\sim \\text{Bin}(n, \\theta)$ and $\\theta \\sim \\text{Beta}(a, b)$.\nThe squared error loss is $L(\\theta, d) = (\\theta - d)^2$.\nThe Bayes estimator is the posterior mean:\n$$d(x) = \\frac{a+x}{a+b+n}$$\n\nWe calculate the risk $R(\\theta, d)$:\n\n$$\nR(\\theta, d) = E_x \\left[ \\left( \\theta - \\frac{a+x}{a+b+n} \\right)^2 \\right]\n$$\n\nLet $c = a+b+n$.\n$$R(\\theta, d) = \\frac{1}{c^2} E \\left[ (c\\theta - a - x)^2 \\right]$$\n\nUsing the bias-variance decomposition and knowing $E(x) = n\\theta$ and $E(x^2) = (n\\theta)^2 + n\\theta(1-\\theta)$, we expand the risk function. To make the risk constant (independent of $\\theta$), we set the coefficients of $\\theta$ and $\\theta^2$ to zero.\n\nSolving the resulting system of equations yields:\n$$a = b = \\frac{\\sqrt{n}}{2}$$\n\nThus, the minimax estimator is:\n$$d(x) = \\frac{x + \\sqrt{n}/2}{n + \\sqrt{n}}$$\n\nThis differs from the standard MLE $\\hat{p} = x/n$ and the uniform prior Bayes estimator ($a=b=1$).\n:::\n\n## Stein's Paradox and the James-stein Estimator\n\nIn high-dimensional estimation ($p \\ge 3$), the Maximum Likelihood Estimator (MLE) is inadmissible under squared error loss. The **James-Stein Estimator** dominates the MLE, meaning it achieves lower risk for all values of $\\theta$.\n\n\n\nConsider the setting:\n\n* Data: $X \\sim N_p(\\theta, I)$\n* Prior: $\\theta \\sim N_p(0, \\tau^2 I)$\n* Estimator: $d^{JS}(x) = \\left( 1 - \\frac{p-2}{||x||^2} \\right) x$\n\nWe can derive the Bayes Risk $r(\\pi, d^{JS})$ of this estimator using two equivalent methods: minimizing the expected frequentist risk, or minimizing the expected posterior loss.\n\n::: {#thm-js-bayes-risk}\n### Bayes Risk of James-stein Estimator\n\nFor $p \\ge 3$, the Bayes risk of the James-Stein estimator $d^{JS}$ with respect to the prior $\\theta \\sim N(0, \\tau^2 I)$ is:\n\n$$\nr(\\pi, d^{JS}) = \\frac{p\\tau^2 + 2}{\\tau^2 + 1}\n$$\n:::\n\n::: {.proof}\n**Method 1: Integration over the Prior (Frequentist Risk approach)** \n\nThe Bayes risk is defined as $r(\\pi, d) = E_\\pi [ R(\\theta, d) ]$.\n\nFirst, recall the frequentist risk of the James-Stein estimator for a fixed $\\theta$. Using Stein's Lemma, the risk is given by:\n$$\nR(\\theta, d^{JS}) = p - (p-2)^2 E_\\theta \\left[ \\frac{1}{||X||^2} \\right]\n$$\n\nTo find the Bayes risk, we take the expectation of this risk with respect to the prior $\\pi(\\theta)$:\n$$\nr(\\pi, d^{JS}) = \\int R(\\theta, d^{JS}) \\pi(\\theta) d\\theta = p - (p-2)^2 E_\\pi \\left[ E_\\theta \\left( \\frac{1}{||X||^2} \\right) \\right]\n$$\n\nBy the law of iterated expectations, $E_\\pi [ E_\\theta (\\cdot) ]$ is equivalent to the expectation with respect to the marginal distribution of $X$, denoted as $m(x)$.\nUnder the conjugate prior, the marginal distribution is $X \\sim N(0, (1+\\tau^2)I)$.\n\nConsequently, the quantity $\\frac{||X||^2}{1+\\tau^2}$ follows a Chi-squared distribution with $p$ degrees of freedom ($\\chi^2_p$). The expectation of the inverse chi-square is:\n$$\nE \\left[ \\frac{1}{||X||^2} \\right] = \\frac{1}{1+\\tau^2} E \\left[ \\frac{1}{\\chi^2_p} \\right] = \\frac{1}{1+\\tau^2} \\cdot \\frac{1}{p-2}\n$$\n\nSubstituting this back into the risk equation:\n$$\n\\begin{aligned}\nr(\\pi, d^{JS}) &= p - (p-2)^2 \\cdot \\frac{1}{(p-2)(1+\\tau^2)} \\\\\n&= p - \\frac{p-2}{1+\\tau^2} \\\\\n&= \\frac{p(1+\\tau^2) - (p-2)}{1+\\tau^2} \\\\\n&= \\frac{p\\tau^2 + p - p + 2}{1+\\tau^2} = \\frac{p\\tau^2 + 2}{\\tau^2 + 1}\n\\end{aligned}\n$$\n:::\n\n::: {.proof}\n**Method 2: Integration over the Marginal (Posterior Loss approach)** \n\nAlternatively, we can compute the Bayes risk by first finding the posterior expected loss for a given $x$, and then averaging over the marginal distribution of $x$:\n$$\nr(\\pi, d) = E_m [ E_{\\theta|x} [ L(\\theta, d(x)) ] ]\n$$\n\n**Step 1: Posterior Expected Loss**\n\nThe posterior distribution of $\\theta$ given $x$ is:\n$$\n\\theta | x \\sim N \\left( \\frac{\\tau^2}{1+\\tau^2}x, \\frac{\\tau^2}{1+\\tau^2}I \\right)\n$$\n\nThe expected squared error loss can be decomposed into the variance (trace) and the squared bias:\n$$\nE_{\\theta|x} [ ||\\theta - d^{JS}(x)||^2 ] = \\text{tr}(\\text{Var}(\\theta|x)) + || E[\\theta|x] - d^{JS}(x) ||^2\n$$\n\n* **Trace term:**\n    $$\\text{tr} \\left( \\frac{\\tau^2}{1+\\tau^2} I_p \\right) = \\frac{p\\tau^2}{1+\\tau^2}$$\n\n* **Squared Bias term:**\n    Let $B = \\frac{1}{1+\\tau^2}$. Then $E[\\theta|x] = (1-B)x$.\n    The estimator is $d^{JS}(x) = (1 - \\frac{p-2}{||x||^2})x$.\n    The difference is:\n    $$\n    E[\\theta|x] - d^{JS}(x) = \\left( (1-B) - \\left( 1 - \\frac{p-2}{||x||^2} \\right) \\right) x = \\left( \\frac{p-2}{||x||^2} - B \\right) x\n    $$\n    Squaring the norm gives:\n    $$\n    \\left( \\frac{p-2}{||x||^2} - B \\right)^2 ||x||^2 = \\frac{(p-2)^2}{||x||^2} - 2B(p-2) + B^2 ||x||^2\n    $$\n\n**Step 2: Expectation with respect to Marginal $X$** \n\nWe now take the expectation $E_m[\\cdot]$ of the posterior loss. Recall $X \\sim N(0, (1+\\tau^2)I)$, so $E[||X||^2] = p(1+\\tau^2)$ and $E[1/||X||^2] = \\frac{1}{(p-2)(1+\\tau^2)}$.\n\n* **Expectation of Trace term:** Constant, remains $\\frac{p\\tau^2}{1+\\tau^2}$.\n* **Expectation of Bias term:**\n    $$\n    \\begin{aligned}\n    E_m \\left[ \\frac{(p-2)^2}{||X||^2} - \\frac{2(p-2)}{1+\\tau^2} + \\frac{||X||^2}{(1+\\tau^2)^2} \\right] &= (p-2)^2 \\frac{1}{(p-2)(1+\\tau^2)} - \\frac{2(p-2)}{1+\\tau^2} + \\frac{p(1+\\tau^2)}{(1+\\tau^2)^2} \\\\\n    &= \\frac{p-2}{1+\\tau^2} - \\frac{2p-4}{1+\\tau^2} + \\frac{p}{1+\\tau^2} \\\\\n    &= \\frac{p - 2 - 2p + 4 + p}{1+\\tau^2} \\\\\n    &= \\frac{2}{1+\\tau^2}\n    \\end{aligned}\n    $$\n\n**Step 3: Combine Terms** \n\n$$\nr(\\pi, d^{JS}) = \\underbrace{\\frac{p\\tau^2}{1+\\tau^2}}_{\\text{Variance Part}} + \\underbrace{\\frac{2}{1+\\tau^2}}_{\\text{Bias Part}} = \\frac{p\\tau^2 + 2}{\\tau^2 + 1}\n$$\n\nBoth methods yield the same result.\n:::\n\n::: {#thm-mle-inadmissible}\n### Inadmissibility of the MLE in High Dimensions (stein's Phenomenon)\n\nLet $X \\sim N_p(\\theta, I)$ be a $p$-dimensional random vector with $p \\ge 3$. Under the squared error loss function $L(\\theta, d) = ||\\theta - d||^2$, the standard Maximum Likelihood Estimator $d^0(X) = X$ is **inadmissible**.\n:::\n\n::: {.proof}\nTo show that $d^0(X) = X$ is inadmissible, we must find another estimator that dominates it (i.e., has equal or lower risk for all $\\theta$, and strictly lower risk for at least one $\\theta$).\n\nFirst, consider the risk of the standard estimator $d^0$. Since $X_i \\sim N(\\theta_i, 1)$ are independent:\n\n$$\nR(\\theta, d^0) = E_\\theta [ ||X - \\theta||^2 ] = \\sum_{i=1}^p E [ (X_i - \\theta_i)^2 ] = \\sum_{i=1}^p \\text{Var}(X_i) = p\n$$\n\nNow consider the James-Stein estimator $d^{JS}(X) = \\left( 1 - \\frac{p-2}{||X||^2} \\right) X$. As established in the derivation of the Bayes Risk in @thm-js-bayes-risk, the frequentist risk function of $d^{JS}$ is:\n\n$$\nR(\\theta, d^{JS}) = p - (p-2)^2 E_\\theta \\left[ \\frac{1}{||X||^2} \\right]\n$$\n\nSince the random variable $||X||^2$ is non-negative and not identically infinity, the expectation $E_\\theta [ 1/||X||^2 ]$ is strictly positive for all $\\theta$. Therefore:\n\n$$\nR(\\theta, d^{JS}) < p = R(\\theta, d^0) \\quad \\text{for all } \\theta \\in \\mathbb{R}^p\n$$\n\nBecause $d^{JS}$ achieves a strictly lower risk than $d^0$ everywhere in the parameter space, $d^0$ is dominated by $d^{JS}$ and is thus inadmissible.\n:::\n\n### Practical Application: One-way ANOVA and \"borrowing Strength\"\n\n::: {#exm-anova-js}\n\nConsider a One-Way ANOVA setting where we wish to estimate the means of $p$ different independent groups (e.g., the true batting averages of $p=10$ baseball players, or the efficacy of $p=5$ different hospital treatments).\n\n* **Model:** Let $X_i \\sim N(\\theta_i, \\sigma^2)$ be the observed sample mean for group $i$, for $i = 1, \\dots, p$.\n* **Goal:** Estimate the vector of true means $\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_p)$ simultaneously. The loss is the sum of squared errors: $L(\\boldsymbol{\\theta}, \\hat{\\boldsymbol{\\theta}}) = \\sum (\\theta_i - \\hat{\\theta}_i)^2$.\n\n**The MLE Approach (Total Separation):**\nThe standard estimator is $\\hat{\\theta}_i^{\\text{MLE}} = X_i$. This estimates each group entirely independently, using only data from that specific group. If a specific player has a lucky streak, their estimate is very high; if they are unlucky, it is very low.\n\n**The James-Stein Approach (Shrinkage / Pooling):**\nIn this context, the James-Stein estimator (specifically the variation shrinking toward the grand mean $\\bar{X}$) is:\n$$\n\\hat{\\theta}_i^{JS} = \\bar{X} + \\left( 1 - \\frac{(p-3)\\sigma^2}{\\sum (X_i - \\bar{X})^2} \\right) (X_i - \\bar{X})\n$$\n\n**Why is this better?**\nEven though the groups might be physically independent (e.g., distinct hospitals), the James-Stein estimator **\"borrows strength\"** from the ensemble.\n\n1.  **Noise Reduction:** Extreme observations $X_i$ are likely to contain more positive noise than signal. Shrinking them toward the global average $\\bar{X}$ reduces this variance.\n2.  **Stein's Paradox:** While $\\hat{\\theta}_i^{JS}$ introduces bias (estimates are pulled toward the center), the reduction in variance is so significant that the **Total Risk** (sum of squared errors over all groups) is strictly lower than that of the MLE, provided $p \\ge 3$.\n\nThus, estimating the groups *together* yields a more accurate global picture than estimating them *separately*, even if the groups are independent.\n:::\n\n### Why is this Paradoxical?\n\nThe result that $d^{JS}$ dominates $d^0$ is called **Stein's Paradox** because it defies intuition in several ways:\n\n1.  **Independence Irrelevance:** The result holds even if the components $X_i$ are completely unrelated (e.g., $X_1$ is the price of tea in China, $X_2$ is the temperature in Saskatoon, and $X_3$ is the weight of a local cat). It seems absurd that combining unrelated data improves the estimate of each, but the combined risk is indeed lower.\n2.  **No \"Free Lunch\":** The James-Stein estimator does not improve every individual component $\\theta_i$ simultaneously for every realization. Instead, it minimizes the **total** risk $\\sum E(\\hat{\\theta}_i - \\theta_i)^2$. It sacrifices accuracy on outliers (by biasing them) to gain significant stability on the bulk of the data.\n3.  **Destruction of Symmetry:** The MLE is invariant under translation and rotation. The James-Stein estimator breaks this symmetry by shrinking toward an arbitrary point (usually the origin or the grand mean), yet it yields a better objective performance.\n\n### What We Learned\n\n1.  **Bias-Variance Tradeoff:** This is the most famous example where introducing **bias** (shrinkage) leads to a massive reduction in **variance**, thereby reducing the overall Mean Squared Error (MSE). Unbiasedness is not always a virtue in estimation.\n2.  **Inadmissibility in High Dimensions:** Intuitions formed in 1D or 2D (where MLE is admissible) fail in higher dimensions ($p \\ge 3$). The volume of space grows so fast that \"standard\" diffuse priors or MLEs become inefficient.\n3.  **Hierarchical Modeling:** Stein's result provides the theoretical foundation for **Hierarchical Bayesian Models**. When we assume parameters come from a common distribution (e.g., $\\theta_i \\sim N(\\mu, \\tau^2)$), we naturally derive shrinkage estimators that \"borrow strength\" across groups, formalized as Empirical Bayes or fully Bayesian methods.\n\n## Empirical Bayes\n\nThe James-Stein estimator provides a natural entry point into the concept of **Empirical Bayes (EB)**. While the Stein estimator was originally derived using frequentist risk arguments, it can be intuitively understood as a Bayesian estimator where the parameters of the prior distribution are estimated from the data itself.\n\n### The General Empirical Bayes Framework\n\nIn a standard Bayesian analysis, the hyperparameters of the prior are fixed based on subjective belief or external information. In contrast, Empirical Bayes uses the observed data to \"learn\" the prior.\n\nThe workflow typically follows these steps:\n\n1.  **Hierarchical Model:**\n    We assume the data $X$ comes from a distribution $f(x|\\theta)$, and the parameter $\\theta$ comes from a prior $\\pi(\\theta|\\eta)$ controlled by hyperparameters $\\eta$.\n\n2.  **Marginal Likelihood (Evidence):**\n    We integrate out the parameter $\\theta$ to obtain the marginal distribution of the data given the hyperparameters:\n    $$m(x|\\eta) = \\int f(x|\\theta) \\pi(\\theta|\\eta) d\\theta$$\n\n3.  **Estimation of Hyperparameters:**\n    Instead of fixing $\\eta$, we estimate it by maximizing the marginal likelihood (Type-II Maximum Likelihood) or using method-of-moments:\n    $$\\hat{\\eta} = \\underset{\\eta}{\\arg\\max} \\ m(x|\\eta)$$\n\n4.  **Posterior Inference:**\n    We proceed with standard Bayesian inference, but we substitute the estimated estimate $\\hat{\\eta}$ into the posterior:\n    $$\\pi(\\theta|x, \\hat{\\eta}) \\propto f(x|\\theta) \\pi(\\theta|\\hat{\\eta})$$\n\n**Discussion:**\n\n* **\"Borrowing Strength\":** EB allows us to pool information across independent groups to estimate the common structure (the prior) governing them.\n* **The Critique:** A purist Bayesian might object that using the data twice (once to estimate the prior, once to estimate $\\theta$) underestimates the uncertainty. A fully Bayesian Hierarchical model would instead place a \"hyperprior\" on $\\eta$ and integrate it out.\n\n### Deriving James-Stein as Empirical Bayes\n\nWe can derive the James-Stein rule explicitly using this framework.\n\n**Model:**\n\n1.  Likelihood: $X_i | \\mu_i \\sim N(\\mu_i, 1)$ for $i=1, \\dots, p$.\n2.  Prior: $\\mu_i \\sim N(0, \\tau^2)$. Here, $\\tau^2$ is the unknown hyperparameter.\n\n**Step 1: The Ideal Bayes Estimator**\n\nIf we knew $\\tau^2$, the posterior distribution of $\\mu_i$ would be Normal with mean:\n$$E(\\mu_i|x_i, \\tau^2) = \\frac{\\tau^2}{1+\\tau^2} x_i = \\left( 1 - \\frac{1}{1+\\tau^2} \\right) x_i$$\nWe define the shrinkage factor $B = \\frac{1}{1+\\tau^2}$.\n\n**Step 2: Marginal Estimation**\n\nSince $\\mu_i$ and $X_i-\\mu_i$ are independent normals, the marginal distribution of the data is:\n$$X_i \\sim N(0, 1+\\tau^2)$$\nConsequently, the sum of squares $S = ||X||^2 = \\sum X_i^2$ follows a scaled Chi-squared distribution:\n$$S \\sim (1+\\tau^2) \\chi^2_p$$\n\n**Step 3: Estimating the Shrinkage Factor**\n\nWe need to estimate $B = \\frac{1}{1+\\tau^2}$. Note that the expected value of an inverse Chi-square variable is $E[1/\\chi^2_p] = \\frac{1}{p-2}$. Therefore:\n$$E \\left[ \\frac{p-2}{S} \\right] = \\frac{p-2}{1+\\tau^2} E\\left[\\frac{1}{\\chi^2_p}\\right] = \\frac{p-2}{1+\\tau^2} \\cdot \\frac{1}{p-2} = \\frac{1}{1+\\tau^2} = B$$\n\nThus, $\\hat{B} = \\frac{p-2}{||X||^2}$ is an unbiased estimator of the optimal shrinkage factor.\n\n**Step 4: The Empirical Bayes Rule**\n\nPlugging $\\hat{B}$ into the ideal Bayes estimator recovers the James-Stein rule:\n$$\\delta^{EB}(X) = \\left( 1 - \\hat{B} \\right) X = \\left( 1 - \\frac{p-2}{||X||^2} \\right) X$$\n\n\n\n# Hierarchical Modeling and MCMC\n\nIn complex Bayesian settings where the posterior distribution cannot be derived analytically, we utilize hierarchical structures to represent levels of uncertainty and Markov Chain Monte Carlo (MCMC) to approximate the resulting distributions.\n\n\n## Hierarchical Model Structure\n\nA hierarchical model decomposes a complex joint distribution into a series of conditional levels. The general mathematical form is:\n\n$$\n\\begin{aligned}\n\\text{Level 1 (Data Likelihood):} & \\quad X_i | \\mu_i, \\sigma^2 \\sim f(x_i | \\mu_i, \\sigma^2) \\\\\n\\text{Level 2 (Parameters):} & \\quad \\mu_i | \\theta, \\tau^2 \\sim \\pi(\\mu_i | \\theta, \\tau^2) \\\\\n\\text{Level 3 (Hyperparameters):} & \\quad \\theta, \\tau^2 \\sim \\pi(\\theta, \\tau^2)\n\\end{aligned}\n$$\n\nThe goal is to compute the joint posterior distribution of all unobserved parameters given the data $X = \\{X_1, \\dots, X_n\\}$:\n\n$$\np(\\boldsymbol{\\mu}, \\theta, \\tau^2 | X) \\propto \\left[ \\prod_{i=1}^n f(x_i | \\mu_i, \\sigma^2) \\pi(\\mu_i | \\theta, \\tau^2) \\right] \\pi(\\theta, \\tau^2)\n$$\n\n\n## Graphical Model Representation (Tree Structure)\n\nThe following tree diagram illustrates the conditional dependencies. Note that the parameters $\\mu_i$ are conditionally independent given the hyperparameter $\\theta$, which facilitates \"borrowing strength\" across groups.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Hierarchical Tree Structure](bayesian_files/figure-html/fig-hierarchical-tree-1.png){#fig-hierarchical-tree fig-align='center' width=576 style=\"width: 80% !important;\"}\n:::\n:::\n\n\n\n\n\n\n\n\n\n## MCMC Estimation\n\nIn hierarchical models, the joint posterior distribution $p(\\boldsymbol{\\mu}, \\theta | X)$ often lacks a closed-form analytical solution due to the integration required for the normalizing constant. We use **Markov Chain Monte Carlo (MCMC)** to draw sequence of samples $\\{\\boldsymbol{\\mu}^{(t)}, \\theta^{(t)}\\}$ that converge to the target posterior distribution.\n\n\n::: {#alg-gibbs-sampling}\n### Gibbs Sampling Algorithm\nGibbs sampling is an algorithm for sampling from a multivariate distribution by sequentially sampling from the **full conditional distributions**. To sample from a target distribution $p(\\theta_1, \\theta_2, \\dots, \\theta_k)$, the algorithm iterates through each variable, updating it conditioned on the current values of all other variables:\n\n$$\n\\begin{aligned}\n\\theta_1^{(t+1)} &\\sim p(\\theta_1 | \\theta_2^{(t)}, \\theta_3^{(t)}, \\dots, \\theta_k^{(t)}) \\\\\n\\theta_2^{(t+1)} &\\sim p(\\theta_2 | \\theta_1^{(t+1)}, \\theta_3^{(t)}, \\dots, \\theta_k^{(t)}) \\\\\n&\\vdots \\\\\n\\theta_k^{(t+1)} &\\sim p(\\theta_k | \\theta_1^{(t+1)}, \\theta_2^{(t+1)}, \\dots, \\theta_{k-1}^{(t+1)})\n\\end{aligned}\n$$\n:::\n\n\n\n::: {#exm-hierarchical-gibbs}\n### Gibbs Sampling for Groups of Normal Data\n**The Model**\n\nTo apply the general Gibbs sampling framework $\\theta_1, \\theta_2, \\dots, \\theta_k$ to our specific hierarchical model, we identify the variables as follows:\n\n* **Data Observations ($X_i$):** These are the known, measured values at the lowest level of the hierarchy (e.g., test scores of students in school $i$). In the Gibbs sampler, these remain fixed and condition the updates of the parameters.\n\n* **Group-Level Parameters ($\\theta_1 = \\mu_i$):** These represent the latent means for each specific group or cluster. In the update step, $\\mu_i$ acts as the first block of variables. It is updated by \"compromising\" between the local data $X_i$ and the global characteristic $\\theta$.\n\n* **Global Hyperparameter ($\\theta_2 = \\theta$):** This represents the common mean across all groups. It acts as the second block in the sampler. Its update depends on the current state of all $\\mu_i$ values, effectively \"pooling\" information from all groups to estimate the overall population center.\n\n**Gibbs Update in Hierarchical Models**\n\nIn the hierarchical tree structure provided earlier, let our parameter vector be $(\\mu_i, \\theta)$. The \"orthogonality\" of the updates becomes clear when we derive the full conditionals for a Gaussian case:\n\n* **Case $\\theta_1 = \\mu_i$:** Sample $\\mu_i^{(t+1)}$ from $p(\\mu_i | X_i, \\theta^{(t)})$. This is a normal distribution with:\n$$\n\\mu_i^{(t+1)} \\sim N\\left( \\frac{\\tau^2 X_i + \\sigma^2 \\theta^{(t)}}{\\sigma^2 + \\tau^2}, \\frac{\\sigma^2 \\tau^2}{\\sigma^2 + \\tau^2} \\right)\n$$\n\n* **Case $\\theta_2 = \\theta$:** Sample $\\theta^{(t+1)}$ from $p(\\theta | \\boldsymbol{\\mu}^{(t+1)})$. Assuming a flat prior $\\pi(\\theta) \\propto 1$:\n$$\n\\theta^{(t+1)} \\sim N\\left( \\frac{1}{n} \\sum_{i=1}^n \\mu_i^{(t+1)}, \\frac{\\tau^2}{n} \\right)\n$$\n:::\n\n\n**Visual Characteristic:** Gibbs sampling moves along the coordinate axes because it updates one parameter at a time while holding others constant.\n\n\n### Metropolis-Hastings (MH) Sampling\n\nWhen the full conditional distributions are not easy to sample from, we use the Metropolis-Hastings algorithm. At each step $t$:\n\n* **Propose:** Draw a candidate state $\\theta^*$ from a proposal distribution $q(\\theta^* | \\theta^{(t)})$.\n* **Accept/Reject:** Calculate the acceptance probability:\n$$\n\\alpha = \\min \\left( 1, \\frac{p(\\theta^* | X) q(\\theta^{(t)} | \\theta^*)}{p(\\theta^{(t)} | X) q(\\theta^* | \\theta^{(t)})} \\right)\n$$\n* Set $\\theta^{(t+1)} = \\theta^*$ with probability $\\alpha$; otherwise, set $\\theta^{(t+1)} = \\theta^{(t)}$.\n\n**Visual Characteristic:** MH sampling moves in arbitrary directions and can \"stay put\" if a proposal is rejected, exploring the space via a random walk.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nrho <- 0.8\nlog_target <- function(x, y) { -0.5 * (x^2 - 2*rho*x*y + y^2) / (1 - rho^2) }\n\n# Gibbs Path (Step-wise update)\ngx <- -2; gy <- -2\ngx_path <- gx; gy_path <- gy\nfor(i in 1:25) {\n  gx <- rnorm(1, rho * gy, sqrt(1 - rho^2))\n  gx_path <- c(gx_path, gx, gx); gy_path <- c(gy_path, gy, gy) # Horizontal move\n  gy <- rnorm(1, rho * gx, sqrt(1 - rho^2))\n  gx_path <- c(gx_path, gx); gy_path <- c(gy_path, gy) # Vertical move\n}\n\n# MH Path (Random Walk)\nmx <- numeric(50); my <- numeric(50)\nmx[1] <- -2; my[1] <- -2\nfor(i in 2:50) {\n  px <- mx[i-1] + rnorm(1, 0, 0.4); py <- my[i-1] + rnorm(1, 0, 0.4)\n  acc <- exp(log_target(px, py) - log_target(mx[i-1], my[i-1]))\n  if(runif(1) < acc) { mx[i] <- px; my[i] <- py } else { mx[i] <- mx[i-1]; my[i] <- my[i-1] }\n}\n\npar(mfrow = c(1, 2))\nt_seq <- seq(-3, 3, length=50); z <- outer(t_seq, t_seq, function(x,y) exp(log_target(x,y)))\nplot(gx_path, gy_path, type=\"l\", col=\"blue\", main=\"Gibbs (Orthogonal Steps)\", xlab=expression(theta[1]), ylab=expression(theta[2]))\ncontour(t_seq, t_seq, z, add=TRUE, col=\"gray\")\nplot(mx, my, type=\"l\", col=\"red\", main=\"Metropolis-Hastings (Random Walk)\", xlab=expression(theta[1]), ylab=expression(theta[2]))\ncontour(t_seq, t_seq, z, add=TRUE, col=\"gray\")\n```\n\n::: {.cell-output-display}\n![Comparison of Sampling Paths](bayesian_files/figure-html/fig-mcmc-comparison-1.png){#fig-mcmc-comparison width=960}\n:::\n:::\n\n\n\n\n\n\n\n\n## Case Study: 1998 Major League Baseball Home Run Race\n\nIn 1998, the baseball world was captivated by Mark McGwire and Sammy Sosa as they chased Roger Maris' 1961 record of 61 home runs in a single season. While McGwire and Sosa finished with 70 and 66 home runs respectively, we consider whether such performance could have been predicted using pre-season exhibition data.\n\nFor a set of $i = 1, \\dots, 17$ players (including McGwire and Sosa), we observe their batting records in pre-season exhibition matches. Our goal is to estimate each player's home run \"strike rate\" for the competitive season.\n\n\n** Transforming Data**\n\nWe utilize the pre-season home runs ($y_i$) and at-bats ($n_i$) for 17 players. The data is transformed using a variance-stabilizing transformation to approximate a normal distribution with known variance $\\sigma^2 = 1$.\n\n$$\nX_i = \\sqrt{n_i} \\arcsin\\left( 2 \\frac{y_i}{n_i} - 1 \\right)\n$$\n\nThe goal is to estimate the latent parameter $\\mu_i$ for each player and compare it to the \"true\" regular season performance.\nThe following table summarizes the pre-season exhibition statistics and the final regular-season results for the 17 players analyzed in the study.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(brms)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Data Source\nni <- c(58, 59, 74, 84, 69, 63, 60, 54, 53, 60, 66, 66, 72, 64, 42, 38, 58)\nyi <- c(7, 9, 4, 7, 3, 6, 2, 10, 2, 2, 4, 3, 2, 5, 3, 2, 6)\nNi <- c(509, 643, 633, 645, 606, 555, 619, 609, 552, 540, 561, 440, 585, 531, 454, 504, 244)\nYi <- c(70, 66, 56, 46, 45, 44, 43, 40, 37, 34, 32, 30, 29, 28, 23, 21, 15)\n\n# Transformations\nx <- sqrt(ni) * asin(2 * yi / ni - 1)           # Transformed Pre-season (Data)\ntrue_mu <- sqrt(ni) * asin(2 * Yi / Ni - 1)     # Transformed Season (Truth)\n\n# Calculate Proportions\np_pre <- yi / ni       # Pre-season home run rate\np_season <- Yi / Ni    # All-season home run rate\n\ndf_baseball <- data.frame(\n  Player = 1:17,\n  x = x,\n  p_pre = p_pre,\n  p_season = p_season,\n  true_mu = true_mu,\n  sei = 1 # Known standard error after transformation\n)\nknitr::kable(df_baseball)\n```\n\n::: {.cell-output-display}\n\n\n| Player|          x|     p_pre|  p_season|   true_mu| sei|\n|------:|----------:|---------:|---------:|---------:|---:|\n|      1|  -6.558654| 0.1206897| 0.1375246| -6.176111|   1|\n|      2|  -5.901440| 0.1525424| 0.1026439| -7.055389|   1|\n|      3|  -9.475559| 0.0540541| 0.0884676| -8.316610|   1|\n|      4|  -9.028690| 0.0833333| 0.0713178| -9.441270|   1|\n|      5|  -9.558306| 0.0434783| 0.0742574| -8.462880|   1|\n|      6|  -7.487533| 0.0952381| 0.0792793| -7.936820|   1|\n|      7|  -9.322955| 0.0333333| 0.0694669| -8.035378|   1|\n|      8|  -5.004869| 0.1851852| 0.0656814| -7.733859|   1|\n|      9|  -8.589045| 0.0377358| 0.0670290| -7.622499|   1|\n|     10|  -9.322955| 0.0333333| 0.0629630| -8.238041|   1|\n|     11|  -8.719662| 0.0606061| 0.0570410| -8.842767|   1|\n|     12|  -9.270313| 0.0454545| 0.0681818| -8.468815|   1|\n|     13| -10.486961| 0.0277778| 0.0495726| -9.518231|   1|\n|     14|  -8.033856| 0.0781250| 0.0527307| -8.859183|   1|\n|     15|  -6.673198| 0.0714286| 0.0506608| -7.237348|   1|\n|     16|  -6.829194| 0.0526316| 0.0416667| -7.148615|   1|\n|     17|  -6.975191| 0.1034483| 0.0614754| -8.146478|   1|\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nIn this analysis, we model the home run strike rates of 17 Major League Baseball players using pre-season exhibition data from 1998. We apply four statistical methods ranging from simple independent estimation to hierarchical Bayesian modeling.\n\n\n\n\n## Method 1: Simple Estimation (MLE)\n\nThe Maximum Likelihood Estimator (MLE) assumes each player's performance is independent. It relies solely on the observed pre-season data.\n\n$$\n\\hat{\\mu}_i^{MLE} = X_i\n$$\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple Estimate is just the data itself\nmu_mle <- df_baseball$x\n\n# MSE Calculation\nmse_mle <- sum((mu_mle - df_baseball$true_mu)^2)\n```\n:::\n\n\n\n\n\n\n\n\n\n## Method 2: Empirical Bayes (James-Stein)\n\nThe James-Stein estimator introduces a global mean $\\bar{X}$ and shrinks individual estimates toward it. This assumes the players come from a common population distribution.\n\n::: {#def-james-stein}\n### James-Stein Estimator\nThe estimator is defined as a convex combination of the individual observation and the global mean:\n\n$$\n\\hat{\\mu}_i^{JS} = \\bar{X} + \\left( 1 - \\frac{k-3}{\\sum (X_i - \\bar{X})^2} \\right) (X_i - \\bar{X})\n$$\n\nwhere $k=17$ is the number of players.\n:::\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta_hat <- mean(x)\nS <- sum((x - theta_hat)^2)\nshrinkage_factor <- 1 - (14 / S)\n\nmu_js <- theta_hat + shrinkage_factor * (x - theta_hat)\n\n# MSE Calculation\nmse_js <- sum((mu_js - df_baseball$true_mu)^2)\n```\n:::\n\n\n\n\n\n\n\n\n\n## Method 3: Fully Bayesian MCMC (brms)\n\nWe use a hierarchical Bayesian model where parameters are treated as random variables. We implement this using `brms`.\n\nModel Specification:\n$$\n\\begin{aligned}\nX_i &\\sim N(\\mu_i, 1) \\\\\n\\mu_i &\\sim N(\\theta, \\tau^2) \\\\\n\\theta &\\sim N(0, 10) \\\\\n\\tau &\\sim \\text{Cauchy}(0, 2)\n\\end{aligned}\n$$\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Random Intercept Model: x | se(1) ~ 1 + (1|Player)\nfit_brms <- brm(\n  formula = x | se(sei, sigma = TRUE) ~ 1 + (1 | Player),\n  data = df_baseball,\n  prior = c(\n    prior(normal(0, 10), class = \"Intercept\"),\n    prior(cauchy(0, 2), class = \"sd\")\n  ),\n  chains = 2, iter = 4000, warmup = 1000, seed = 123,\n  refresh = 0\n)\n\n# Extract Point Estimates (Posterior Means)\npost_means <- fitted(fit_brms)[, \"Estimate\"]\nmu_brms <- post_means\n\n# MSE Calculation\nmse_brms <- sum((mu_brms - df_baseball$true_mu)^2)\n```\n:::\n\n\n\n\n\n\n\n\n\n## Method 4: Rao-Blackwellized Density Estimation\n\nStandard histograms of MCMC samples can be rough. Rao-Blackwellization improves density estimation by exploiting the conditional independence structure.\n\n::: {#thm-rao-blackwell}\n### Rao-Blackwellized Density\nInstead of kernel density estimation on samples of $\\mu_i$, we average the conditional densities. Given samples $(\\theta^{(t)}, \\tau^{(t)})$, the conditional posterior for $\\mu_i$ is Normal:\n\n$$\np(\\mu_i | X) \\approx \\frac{1}{T} \\sum_{t=1}^T N\\left(\\mu_i \\mid m_i^{(t)}, v^{(t)}\\right)\n$$\n\nwhere:\n$$\n\\begin{aligned}\nw^{(t)} &= \\frac{(\\tau^{(t)})^2}{(\\tau^{(t)})^2 + 1} \\\\\nm_i^{(t)} &= w^{(t)} X_i + (1 - w^{(t)}) \\theta^{(t)} \\\\\nv^{(t)} &= w^{(t)}\n\\end{aligned}\n$$\n:::\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract Posterior Samples of Hyperparameters\n# b_Intercept = theta, sd_Player__Intercept = tau\nsamples <- as_draws_df(fit_brms)\ntheta_mc <- samples$b_Intercept\ntau_mc   <- samples$sd_Player__Intercept\n\n# Function to compute RB density for a specific player index i\nget_rb_density <- function(player_idx, x_val, grid_points) {\n  # Calculate weights for every MCMC sample\n  w <- (tau_mc^2) / (tau_mc^2 + 1)\n  \n  # Calculate conditional means and variances\n  cond_mean <- w * x_val + (1 - w) * theta_mc\n  cond_var  <- w # Since sigma^2 = 1, variance is just w\n  \n  # Average densities over the MCMC samples\n  dens_vals <- numeric(length(grid_points))\n  for(k in seq_along(grid_points)) {\n    dens_vals[k] <- mean(dnorm(grid_points[k], mean = cond_mean, sd = sqrt(cond_var)))\n  }\n  return(data.frame(x = grid_points, density = dens_vals))\n}\n```\n:::\n\n\n\n\n\n\n\n\n\n## Comparison and Results\n\n### 1. MSE Performance\n\nThe following table compares the sum of squared errors for the three point-estimation methods.\n\n\n\n\n\n\n\n\n::: {#tbl-mse .cell}\n::: {.cell-output-display}\n\n\nTable: Comparison of Estimation Error (Sum of Squared Differences)\n\n|Method                |    MSE|\n|:---------------------|------:|\n|Simple (MLE)          | 19.679|\n|James-Stein           |  8.066|\n|Fully Bayesian (brms) |  6.570|\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### 2. Shrinkage Plot\n\nThis plot visualizes how the methods adjust the estimates. The MLE lies on the 1:1 line (no adjustment). The Bayesian and James-Stein estimates are pulled horizontally toward the global mean.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(df_baseball$true_mu, df_baseball$x, \n     xlab = \"True Season Rate (Transformed)\", \n     ylab = \"Estimated Rate\", \n     main = \"Shrinkage of Estimators\",\n     pch = 1, col = \"black\", xlim = c(-8, -2), ylim = c(-8, -2))\nabline(0, 1, lty = 2, col = \"gray\")\n\n# Add James-Stein\npoints(df_baseball$true_mu, mu_js, pch = 19, col = \"blue\")\n\n# Add brms (Fully Bayesian)\npoints(df_baseball$true_mu, mu_brms, pch = 17, col = \"red\")\n\nlegend(\"topleft\", legend = c(\"MLE (Data)\", \"James-Stein\", \"Bayesian (brms)\"),\n       col = c(\"black\", \"blue\", \"red\"), pch = c(1, 19, 17))\n\n# Draw arrows for player 1 (McGwire) to show shrinkage\nidx <- 1\narrows(df_baseball$true_mu[idx], df_baseball$x[idx], \n       df_baseball$true_mu[idx], mu_brms[idx], \n       length = 0.1, col = \"red\")\n```\n\n::: {.cell-output-display}\n![Shrinkage Effect: Estimated vs True Strike Rate](bayesian_files/figure-html/fig-shrinkage-1.png){#fig-shrinkage width=576}\n:::\n:::\n\n\n\n\n\n\n\n\n### 3. Posterior Density Comparison (Player 1: McGwire)\n\nHere we compare the raw histogram of posterior samples for Mark McGwire against the smooth Rao-Blackwellized density.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grid for plotting\ngrid <- seq(-6, -2, length.out = 200)\n\n# Calculate RB Density for Player 1\nrb_dens <- get_rb_density(1, x[1], grid)\n\n# Standard Histogram from brms samples\nmu1_samples <- as_draws_df(fit_brms)$`r_Player[1,Intercept]` + samples$b_Intercept\n\nhist(mu1_samples, probability = TRUE, breaks = 30, col = \"lightgray\", border = \"white\",\n     main = \"Posterior Density: Player 1\", xlab = expression(mu[1]))\nlines(rb_dens$x, rb_dens$density, col = \"darkblue\", lwd = 2)\nabline(v = x[1], col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Rao-Blackwell Density\", \"MCMC Histogram\", \"Observed Data\"),\n       col = c(\"darkblue\", \"lightgray\", \"red\"), lty = c(1, 1, 2), lwd = c(2, 10, 2))\n```\n\n::: {.cell-output-display}\n![Posterior Density for Player 1 (McGwire)](bayesian_files/figure-html/fig-density-rb-1.png){#fig-density-rb width=576}\n:::\n:::\n\n\n\n\n\n\n\n\nBecause the strike rates $p_i$ likely share similarities across professional players, we can use a hierarchical model to \"borrow strength\" across the 17 players. To facilitate the use of Normal distributions in our MCMC (Gibbs) framework, we apply a logit transformation to the probabilities:\n\n$$\n\\mu_i = \\text{logit}(p_i) = \\log\\left( \\frac{p_i}{1 - p_i} \\right)\n$$\n\n\n::: {#exm-baseball-hierarchy}\n### Hierarchical Components for Baseball Example\nIn this specific context, the general variables $\\theta_1, \\theta_2$ from the Gibbs sampler are mapped as follows:\n\n* **Data ($X_i$):** Here, our data consists of the pairs $(Y_i, n_i)$ for each of the 17 players.\n\n* **Group-Level Parameters ($\\theta_1 = \\mu_i$):** These are the individual logit-strike rates for each player. A high $\\mu_i$ corresponds to a high probability $p_i$ of hitting a home run.\n\n* **Global Hyperparameter ($\\theta_2 = \\theta$):** This represents the \"league average\" logit-strike rate for top-tier home run hitters. It determines the center of the distribution from which the individual $\\mu_i$ are drawn.\n:::\n\n\n\n\n\n\n## Final Example: Baseball Example with Hierarchical Model\n\n### Empirical Bayes Method with Variance Stability Transformation (Efron & Morris, 1975)\n\nIn their seminal paper *Data Analysis Using Stein's Estimator and its Generalizations*, Efron and Morris applied this method to predict the batting averages of 18 Major League Baseball players.\n\n* **Data:** They used the batting average of each player after their first 45 at-bats ($n=45$) as the initial observation $y_i$.\n* **Goal:** Predict the batting average for the remainder of the season.\n\n**Transformation:**\nSince batting averages are binomial proportions $\\hat{p}_i$, their variance depends on the true mean $p_i(1-p_i)/n$. To apply the homoscedastic Normal model ($X_i \\sim N(\\mu_i, 1)$), they applied a variance-stabilizing transformation:\n$$X_i = \\sqrt{n} \\arcsin(2\\hat{p}_i - 1)$$\n\n**The Result:**\nThe Maximum Likelihood Estimator would simply predict that a player's future performance will match their first 45 at-bats.\nThe James-Stein (Empirical Bayes) estimator shrunk all individual averages toward the **Grand Mean** of all 18 players.\n\n* Players with unusually high initial averages (e.g., Clemente, who started at .400) were predicted to regress downward.\n* Players with unusually low starts were predicted to improve.\n\n**Outcome:**\nThe James-Stein estimator reduced the total squared prediction error by roughly a factor of 3 compared to the MLE. This famously demonstrated that even for real-world independent parameters (different human beings), pooling information improves predictive accuracy.\n\n\n\n* $Y_i \\sim \\text{Bin}(n_i, p_i)$\n* Logit transform: $\\mu_i = \\text{logit}(p_i)$\n* $\\mu_i \\sim N(\\theta, \\tau^2)$\n* Priors on $\\theta$ and $\\tau^2$.\n\nSince the full conditionals for the Binomial-Normal hierarchy are not closed-form, we use **Metropolis-Hastings** steps within the Gibbs sampler.\n\n**Algorithm:**\n\n1.  Initialize parameters $\\mu^{(0)}, \\theta^{(0)}, \\tau^{(0)}$.\n2.  Propose new values based on a candidate distribution.\n3.  Accept or reject based on the acceptance probability ratio (Likelihood $\\times$ Prior ratio).\n4.  Repeat until convergence.\n\nThe marginal posterior density for a specific parameter (e.g., $f(\\mu_j|x)$) can be estimated using Kernel Density Estimation on the MCMC samples or via Rao-Blackwellization.\n\n## Predictive Distributions\n\nA key feature of Bayesian analysis is the predictive distribution for a future observation $x^*$.\n\n$$f(x^*|x) = \\int f(x^*|\\theta) \\pi(\\theta|x) d\\theta$$\n\n::: {#exm-predictive-normal}\n### Normal-normal Predictive Distribution\n\nIf $x_1, \\dots, x_n \\sim N(\\mu, \\sigma^2)$ (with $\\sigma^2$ known) and $\\mu \\sim N(\\mu_0, \\sigma_0^2)$, the predictive distribution for a new observation $x^*$ is:\n\n$$x^*|x \\sim N(\\mu_1, \\sigma^2 + \\sigma_1^2)$$\n\nwhere $\\mu_1$ and $\\sigma_1^2$ are the posterior mean and variance of $\\mu$. The predictive variance includes both the inherent sampling uncertainty ($\\sigma^2$) and the uncertainty about the parameter ($\\sigma_1^2$).\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}