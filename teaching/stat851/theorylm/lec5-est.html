<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Inference for A Multiple Linear Regression Model – Theory of Linear Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ginv.html" rel="next">
<link href="./lec4-qf.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-1b3e43c72e8be34557c75123b0b69e0d.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-d1855ce4d3ca2472244e2456266329f4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.9/fill.css" rel="stylesheet">
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.11.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>
<link href="site_libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet">
<script src="site_libs/crosstalk-1.2.2/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link rel="stylesheet" href="resources/mystyles.css">
<script src="resources/num_eq.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./lec5-est.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inference for A Multiple Linear Regression Model</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Theory of Linear Models</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec1-vecspace.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Projection in Vector Space</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec2-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Matrix Algebra</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec3-mvn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multivariate Normal Distribution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec4-qf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Distribution of Quadratic Forms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lec5-est.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inference for A Multiple Linear Regression Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ginv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Generalized Inverses</span></span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#linear-models-and-least-square-estimator" id="toc-linear-models-and-least-square-estimator" class="nav-link active" data-scroll-target="#linear-models-and-least-square-estimator"><span class="header-section-number">6.1</span> Linear Models and Least Square Estimator</a>
  <ul>
  <li><a href="#assumptions-in-linear-models" id="toc-assumptions-in-linear-models" class="nav-link" data-scroll-target="#assumptions-in-linear-models"><span class="header-section-number">6.1.1</span> Assumptions in Linear Models</a></li>
  <li><a href="#matrix-formulation" id="toc-matrix-formulation" class="nav-link" data-scroll-target="#matrix-formulation"><span class="header-section-number">6.1.2</span> Matrix Formulation</a></li>
  <li><a href="#least-squares-estimator-of-beta-and-fitted-value-hat-y" id="toc-least-squares-estimator-of-beta-and-fitted-value-hat-y" class="nav-link" data-scroll-target="#least-squares-estimator-of-beta-and-fitted-value-hat-y"><span class="header-section-number">6.1.3</span> Least Squares Estimator of <span class="math inline">\(\beta\)</span> and Fitted Value <span class="math inline">\(\hat Y\)</span></a>
  <ul class="collapse">
  <li><a href="#obtaining-hat-y" id="toc-obtaining-hat-y" class="nav-link" data-scroll-target="#obtaining-hat-y">1. Obtaining <span class="math inline">\(\hat Y\)</span></a></li>
  <li><a href="#obtaining-hatbeta-by-solving-xbeta-haty" id="toc-obtaining-hatbeta-by-solving-xbeta-haty" class="nav-link" data-scroll-target="#obtaining-hatbeta-by-solving-xbeta-haty">2. Obtaining <span class="math inline">\(\hat{\beta}\)</span> by Solving <span class="math inline">\(x\beta = \hat{y}\)</span></a></li>
  </ul></li>
  <li><a href="#properties-of-the-estimator-hat-beta" id="toc-properties-of-the-estimator-hat-beta" class="nav-link" data-scroll-target="#properties-of-the-estimator-hat-beta"><span class="header-section-number">6.1.4</span> Properties of the Estimator <span class="math inline">\(\hat \beta\)</span></a></li>
  </ul></li>
  <li><a href="#best-linear-unbiased-estimator-blue" id="toc-best-linear-unbiased-estimator-blue" class="nav-link" data-scroll-target="#best-linear-unbiased-estimator-blue"><span class="header-section-number">6.2</span> Best Linear Unbiased Estimator (BLUE)</a>
  <ul>
  <li><a href="#notes-on-gauss-markov" id="toc-notes-on-gauss-markov" class="nav-link" data-scroll-target="#notes-on-gauss-markov"><span class="header-section-number">6.2.1</span> Notes on Gauss-markov</a>
  <ul class="collapse">
  <li><a href="#limitations-restriction-to-unbiased-estimators" id="toc-limitations-restriction-to-unbiased-estimators" class="nav-link" data-scroll-target="#limitations-restriction-to-unbiased-estimators">Limitations: Restriction to Unbiased Estimators</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#estimator-of-error-variance" id="toc-estimator-of-error-variance" class="nav-link" data-scroll-target="#estimator-of-error-variance"><span class="header-section-number">6.3</span> Estimator of Error Variance</a>
  <ul>
  <li><a href="#unbiasedness-of-s2" id="toc-unbiasedness-of-s2" class="nav-link" data-scroll-target="#unbiasedness-of-s2"><span class="header-section-number">6.3.1</span> Unbiasedness of <span class="math inline">\(s^2\)</span></a></li>
  </ul></li>
  <li><a href="#distributions-under-normality" id="toc-distributions-under-normality" class="nav-link" data-scroll-target="#distributions-under-normality"><span class="header-section-number">6.4</span> Distributions Under Normality</a></li>
  <li><a href="#maximum-likelihood-estimator-mle" id="toc-maximum-likelihood-estimator-mle" class="nav-link" data-scroll-target="#maximum-likelihood-estimator-mle"><span class="header-section-number">6.5</span> Maximum Likelihood Estimator (MLE)</a></li>
  <li><a href="#linear-models-in-centered-form" id="toc-linear-models-in-centered-form" class="nav-link" data-scroll-target="#linear-models-in-centered-form"><span class="header-section-number">6.6</span> Linear Models in Centered Form</a>
  <ul>
  <li><a href="#matrix-formulation-1" id="toc-matrix-formulation-1" class="nav-link" data-scroll-target="#matrix-formulation-1"><span class="header-section-number">6.6.1</span> Matrix Formulation</a></li>
  <li><a href="#estimation-in-centered-form" id="toc-estimation-in-centered-form" class="nav-link" data-scroll-target="#estimation-in-centered-form"><span class="header-section-number">6.6.2</span> Estimation in Centered Form</a></li>
  </ul></li>
  <li><a href="#decomposition-of-sum-of-squares" id="toc-decomposition-of-sum-of-squares" class="nav-link" data-scroll-target="#decomposition-of-sum-of-squares"><span class="header-section-number">6.7</span> Decomposition of Sum of Squares</a>
  <ul>
  <li><a href="#d-visualization-of-decomposition-of-y" id="toc-d-visualization-of-decomposition-of-y" class="nav-link" data-scroll-target="#d-visualization-of-decomposition-of-y"><span class="header-section-number">6.7.1</span> 3D Visualization of Decomposition of <span class="math inline">\(y\)</span></a></li>
  <li><a href="#a-diagram-to-show-decomposition-of-sum-of-squares" id="toc-a-diagram-to-show-decomposition-of-sum-of-squares" class="nav-link" data-scroll-target="#a-diagram-to-show-decomposition-of-sum-of-squares"><span class="header-section-number">6.7.2</span> A Diagram to Show Decomposition of Sum of Squares</a></li>
  <li><a href="#distribution-of-sum-of-squares" id="toc-distribution-of-sum-of-squares" class="nav-link" data-scroll-target="#distribution-of-sum-of-squares"><span class="header-section-number">6.7.3</span> Distribution of Sum of Squares</a></li>
  </ul></li>
  <li><a href="#f-test-for-testing-overall-regression-effect" id="toc-f-test-for-testing-overall-regression-effect" class="nav-link" data-scroll-target="#f-test-for-testing-overall-regression-effect"><span class="header-section-number">6.8</span> F-test for Testing Overall Regression Effect</a>
  <ul>
  <li><a href="#the-f-statistic" id="toc-the-f-statistic" class="nav-link" data-scroll-target="#the-f-statistic">The F-statistic</a></li>
  <li><a href="#understanding-f-via-expectations" id="toc-understanding-f-via-expectations" class="nav-link" data-scroll-target="#understanding-f-via-expectations">Understanding <span class="math inline">\(F\)</span> via Expectations</a></li>
  <li><a href="#distributional-theory" id="toc-distributional-theory" class="nav-link" data-scroll-target="#distributional-theory"><span class="header-section-number">6.8.1</span> Distributional Theory</a></li>
  <li><a href="#visualization-of-the-rejection-region" id="toc-visualization-of-the-rejection-region" class="nav-link" data-scroll-target="#visualization-of-the-rejection-region"><span class="header-section-number">6.8.2</span> Visualization of the Rejection Region</a></li>
  </ul></li>
  <li><a href="#raw-coefficient-of-determination-r2" id="toc-raw-coefficient-of-determination-r2" class="nav-link" data-scroll-target="#raw-coefficient-of-determination-r2"><span class="header-section-number">6.9</span> Raw Coefficient of Determination (<span class="math inline">\(R^2\)</span>)</a>
  <ul>
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition"><span class="header-section-number">6.9.1</span> Definition</a></li>
  <li><a href="#expectation-and-bias" id="toc-expectation-and-bias" class="nav-link" data-scroll-target="#expectation-and-bias"><span class="header-section-number">6.9.2</span> Expectation and Bias</a></li>
  <li><a href="#exact-distribution" id="toc-exact-distribution" class="nav-link" data-scroll-target="#exact-distribution"><span class="header-section-number">6.9.3</span> Exact Distribution</a></li>
  </ul></li>
  <li><a href="#adjusted-r-squared-r2_a" id="toc-adjusted-r-squared-r2_a" class="nav-link" data-scroll-target="#adjusted-r-squared-r2_a"><span class="header-section-number">6.10</span> Adjusted R-squared (<span class="math inline">\(R^2_a\)</span>)</a></li>
  <li><a href="#population-proportion-of-signals-rho2" id="toc-population-proportion-of-signals-rho2" class="nav-link" data-scroll-target="#population-proportion-of-signals-rho2"><span class="header-section-number">6.11</span> Population Proportion of Signals (<span class="math inline">\(\rho^2\)</span>)</a></li>
  <li><a href="#relationship-between-r2-and-f-test" id="toc-relationship-between-r2-and-f-test" class="nav-link" data-scroll-target="#relationship-between-r2-and-f-test"><span class="header-section-number">6.12</span> Relationship between <span class="math inline">\(R^2\)</span> and <span class="math inline">\(F\)</span> Test</a></li>
  <li><a href="#confidence-interval-of-population-rho2" id="toc-confidence-interval-of-population-rho2" class="nav-link" data-scroll-target="#confidence-interval-of-population-rho2"><span class="header-section-number">6.13</span> Confidence Interval of Population <span class="math inline">\(\rho^2\)</span></a></li>
  <li><a href="#an-animation-for-illustrating-r2_a-under-h_0-and-h_1" id="toc-an-animation-for-illustrating-r2_a-under-h_0-and-h_1" class="nav-link" data-scroll-target="#an-animation-for-illustrating-r2_a-under-h_0-and-h_1"><span class="header-section-number">6.14</span> An Animation for Illustrating <span class="math inline">\(R^2_a\)</span> Under <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></a></li>
  <li><a href="#a-data-example-with-house-price-valuation" id="toc-a-data-example-with-house-price-valuation" class="nav-link" data-scroll-target="#a-data-example-with-house-price-valuation"><span class="header-section-number">6.15</span> A Data Example with House Price Valuation</a>
  <ul>
  <li><a href="#visualize-the-data" id="toc-visualize-the-data" class="nav-link" data-scroll-target="#visualize-the-data"><span class="header-section-number">6.15.1</span> Visualize the Data</a></li>
  <li><a href="#fit-the-model" id="toc-fit-the-model" class="nav-link" data-scroll-target="#fit-the-model"><span class="header-section-number">6.15.2</span> Fit the Model</a>
  <ul class="collapse">
  <li><a href="#method-1-naive-matrix-formula" id="toc-method-1-naive-matrix-formula" class="nav-link" data-scroll-target="#method-1-naive-matrix-formula">Method 1: Naive Matrix Formula</a></li>
  <li><a href="#method-2-centralized-formula" id="toc-method-2-centralized-formula" class="nav-link" data-scroll-target="#method-2-centralized-formula">Method 2: Centralized Formula</a></li>
  <li><a href="#method-3-using-rs-lm-function" id="toc-method-3-using-rs-lm-function" class="nav-link" data-scroll-target="#method-3-using-rs-lm-function">Method 3: Using R’s <code>lm</code> Function</a></li>
  </ul></li>
  <li><a href="#visualization-of-fitted-values-vs-mean" id="toc-visualization-of-fitted-values-vs-mean" class="nav-link" data-scroll-target="#visualization-of-fitted-values-vs-mean"><span class="header-section-number">6.15.3</span> Visualization of Fitted Values vs Mean</a></li>
  <li><a href="#computing-sums-of-squares-sse-sst-ssr" id="toc-computing-sums-of-squares-sse-sst-ssr" class="nav-link" data-scroll-target="#computing-sums-of-squares-sse-sst-ssr"><span class="header-section-number">6.15.4</span> Computing Sums of Squares (SSE, SST, SSR)</a>
  <ul class="collapse">
  <li><a href="#naive-sum-of-squared-errors" id="toc-naive-sum-of-squared-errors" class="nav-link" data-scroll-target="#naive-sum-of-squared-errors"><span class="header-section-number">6.15.4.1</span> 1. Naive Sum of Squared Errors</a></li>
  <li><a href="#pythagorean-shortcut-vector-lengths" id="toc-pythagorean-shortcut-vector-lengths" class="nav-link" data-scroll-target="#pythagorean-shortcut-vector-lengths"><span class="header-section-number">6.15.4.2</span> 2. Pythagorean Shortcut (Vector Lengths)</a></li>
  <li><a href="#matrix-algebra-shortcuts" id="toc-matrix-algebra-shortcuts" class="nav-link" data-scroll-target="#matrix-algebra-shortcuts"><span class="header-section-number">6.15.4.3</span> Matrix Algebra Shortcuts</a></li>
  </ul></li>
  <li><a href="#analysis-of-variance-anova" id="toc-analysis-of-variance-anova" class="nav-link" data-scroll-target="#analysis-of-variance-anova"><span class="header-section-number">6.15.5</span> Analysis of Variance (ANOVA)</a>
  <ul class="collapse">
  <li><a href="#computing-sums-of-squares" id="toc-computing-sums-of-squares" class="nav-link" data-scroll-target="#computing-sums-of-squares">1. Computing Sums of Squares</a></li>
  <li><a href="#manual-anova-construction" id="toc-manual-anova-construction" class="nav-link" data-scroll-target="#manual-anova-construction">2. Manual ANOVA Construction</a></li>
  <li><a href="#standard-r-output-anova" id="toc-standard-r-output-anova" class="nav-link" data-scroll-target="#standard-r-output-anova">3. Standard R Output (<code>anova</code>)</a></li>
  </ul></li>
  <li><a href="#coefficient-of-determination-and-variance-decomposition" id="toc-coefficient-of-determination-and-variance-decomposition" class="nav-link" data-scroll-target="#coefficient-of-determination-and-variance-decomposition"><span class="header-section-number">6.15.6</span> Coefficient of Determination and Variance Decomposition</a>
  <ul class="collapse">
  <li><a href="#calculation" id="toc-calculation" class="nav-link" data-scroll-target="#calculation">1. Calculation</a></li>
  <li><a href="#variance-decomposition-table" id="toc-variance-decomposition-table" class="nav-link" data-scroll-target="#variance-decomposition-table">2. Variance Decomposition Table</a></li>
  </ul></li>
  <li><a href="#confidence-interval-for-population-r2-rho2" id="toc-confidence-interval-for-population-r2-rho2" class="nav-link" data-scroll-target="#confidence-interval-for-population-r2-rho2"><span class="header-section-number">6.15.7</span> Confidence Interval for Population <span class="math inline">\(R^2\)</span> (<span class="math inline">\(\rho^2\)</span>)</a>
  <ul class="collapse">
  <li><a href="#manual-inversion-method" id="toc-manual-inversion-method" class="nav-link" data-scroll-target="#manual-inversion-method">1. Manual Inversion Method</a></li>
  <li><a href="#using-r-package-mbess" id="toc-using-r-package-mbess" class="nav-link" data-scroll-target="#using-r-package-mbess">2. Using R Package <code>MBESS</code></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#underfitting-and-overfitting" id="toc-underfitting-and-overfitting" class="nav-link" data-scroll-target="#underfitting-and-overfitting"><span class="header-section-number">6.16</span> Underfitting and Overfitting</a>
  <ul>
  <li><a href="#notation-and-setup" id="toc-notation-and-setup" class="nav-link" data-scroll-target="#notation-and-setup"><span class="header-section-number">6.16.1</span> Notation and Setup</a></li>
  <li><a href="#case-1-underfitting" id="toc-case-1-underfitting" class="nav-link" data-scroll-target="#case-1-underfitting"><span class="header-section-number">6.16.2</span> Case 1: Underfitting</a></li>
  <li><a href="#case-2-overfitting" id="toc-case-2-overfitting" class="nav-link" data-scroll-target="#case-2-overfitting"><span class="header-section-number">6.16.3</span> Case 2: Overfitting</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inference for A Multiple Linear Regression Model</span></h1>
</div>



<div class="quarto-title-meta column-page-right">

    
  
    
  </div>
  


</header>


<section id="linear-models-and-least-square-estimator" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="linear-models-and-least-square-estimator"><span class="header-section-number">6.1</span> Linear Models and Least Square Estimator</h2>
<section id="assumptions-in-linear-models" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="assumptions-in-linear-models"><span class="header-section-number">6.1.1</span> Assumptions in Linear Models</h3>
<p>Suppose that on a random sample of <span class="math inline">\(n\)</span> units (patients, animals, trees, etc.) we observe a response variable <span class="math inline">\(Y\)</span> and explanatory variables <span class="math inline">\(X_{1},...,X_{k}\)</span>. Our data are then <span class="math inline">\((y_{i},x_{i1},...,x_{ik})\)</span>, <span class="math inline">\(i=1,...,n\)</span>, or in vector/matrix form <span class="math inline">\(y, x_{1},...,x_{k}\)</span> where <span class="math inline">\(y=(y_{1},...,y_{n})\)</span> and <span class="math inline">\(x_{j}=(x_{1j},...,x_{nj})^{T}\)</span> or <span class="math inline">\(y, X\)</span> where <span class="math inline">\(X=(x_{1},...,x_{k})\)</span>.</p>
<p>Either by design or by conditioning on their observed values, <span class="math inline">\(x_{1},...,x_{k}\)</span> are regarded as vectors of known constants. The linear model in its classical form makes the following assumptions:</p>
<p><strong>Assumptions on Linear Models</strong></p>
<ul>
<li><p><strong>A1. (Additive Error)</strong> <span class="math inline">\(y=\mu+e\)</span> where <span class="math inline">\(e=(e_{1},...,e_{n})^{T}\)</span> is an unobserved random vector with <span class="math inline">\(E(e)=0\)</span>. This implies that <span class="math inline">\(\mu=E(y)\)</span> is the unknown mean of <span class="math inline">\(y\)</span>.</p></li>
<li><p><strong>A2. (Linearity)</strong> <span class="math inline">\(\mu=\beta_{1}x_{1}+\cdot\cdot\cdot+\beta_{k}x_{k}=X\beta\)</span> where <span class="math inline">\(\beta_{1},...,\beta_{k}\)</span> are unknown parameters. This assumption says that <span class="math inline">\(E(y)=\mu\in\text{Col}(X)\)</span> (lies in the column space of <span class="math inline">\(X\)</span>); i.e., it is a linear combination of explanatory vectors <span class="math inline">\(x_{1},...,x_{k}\)</span> with coefficients the unknown parameters in <span class="math inline">\(\beta=(\beta_{1},...,\beta_{k})^{T}\)</span>. Note that it is linear in <span class="math inline">\(\beta_{1},...,\beta_{k}\)</span>, not necessarily in the <span class="math inline">\(x\)</span>’s.</p></li>
<li><p><strong>A3. (Independence)</strong> <span class="math inline">\(e_{1},...,e_{n}\)</span> are independent random variables (and therefore so are <span class="math inline">\(y_{1},...,y_{n})\)</span>.</p></li>
<li><p><strong>A4. (Homoscedasticity)</strong> <span class="math inline">\(e_{1},...,e_{n}\)</span> all have the same variance <span class="math inline">\(\sigma^{2}\)</span>; that is, <span class="math inline">\(\text{Var}(e_{1})=\cdot\cdot\cdot=\text{Var}(e_{n})=\sigma^{2}\)</span> which implies <span class="math inline">\(\text{Var}(y_{1})=\cdot\cdot\cdot=\text{Var}(y_{n})=\sigma^{2}\)</span>.</p></li>
<li><p><strong>A5. (Normality)</strong> <span class="math inline">\(e\sim N_{n}(0,\sigma^{2}I_{n})\)</span>.</p></li>
</ul>
</section>
<section id="matrix-formulation" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="matrix-formulation"><span class="header-section-number">6.1.2</span> Matrix Formulation</h3>
<p>The model can be written algebraically as: <span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i1}+\beta_{2}x_{i2}+\cdot\cdot\cdot+\beta_{k}x_{ik}, \quad i=1,...,n\]</span></p>
<p>Or in matrix notation: <span class="math display">\[
\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdot\cdot\cdot &amp; x_{1k}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdot\cdot\cdot &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdot\cdot\cdot &amp; x_{nk}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\
\beta_{1}\\
\vdots\\
\beta_{k}
\end{pmatrix}
+
\begin{pmatrix}
e_{1}\\
e_{2}\\
\vdots\\
e_{n}
\end{pmatrix}
\]</span></p>
<p>This is expressed compactly as: <span class="math display">\[y=X\beta+e\]</span> where <span class="math inline">\(X\)</span> is the design matrix, and <span class="math inline">\(e \sim N_n(0, \sigma^2 I)\)</span>. Alternatively: <span class="math display">\[y=\beta_{0}j_{n}+\beta_{1}x_{1}+\cdot\cdot\cdot+\beta_{k}x_{k}+e\]</span></p>
<p>Taken together, all five assumptions can be stated more succinctly as: <span class="math display">\[y\sim N_{n}(X\beta,\sigma^{2}I)\]</span> with the mean vector <span class="math inline">\(\mu_{y}=X\beta\in \text{Col}(X)\)</span>.</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A Note on Coefficients
</div>
</div>
<div class="callout-body-container callout-body">
<p>The effect of a parameter depends upon what other explanatory variables are present in the model. For example, <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> in the model: <span class="math display">\[y=\beta_{0}j_{n}+\beta_{1}x_{1}+\beta_{2}x_{2}+e\]</span> will typically be different than <span class="math inline">\(\beta_{0}^{*}\)</span> and <span class="math inline">\(\beta_{1}^{*}\)</span> in the model: <span class="math display">\[y=\beta_{0}^{*}j_{n}+\beta_{1}^{*}x_{1}+e^{*}\]</span> In this context, <span class="math inline">\(\beta_0^*\)</span> and <span class="math inline">\(\beta_1^*\)</span> are the population-projected coefficients of the full model, that is, <span class="math inline">\(\beta_0^*\)</span> and <span class="math inline">\(\beta_1^*\)</span> are the parameters that can best approximate the full model.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will first consider the case that <span class="math inline">\(\text{rank}(X)=k+1\)</span>.</p>
</div>
</div>
</section>
<section id="least-squares-estimator-of-beta-and-fitted-value-hat-y" class="level3" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="least-squares-estimator-of-beta-and-fitted-value-hat-y"><span class="header-section-number">6.1.3</span> Least Squares Estimator of <span class="math inline">\(\beta\)</span> and Fitted Value <span class="math inline">\(\hat Y\)</span></h3>
<div id="def-least-squares" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.1 (Least Squares Estimator)</strong></span> The <strong>Least Squares Estimator (LSE)</strong> of <span class="math inline">\(\beta\)</span>, denoted as <span class="math inline">\(\hat{\beta}\)</span>, is the vector that minimizes the Sum of Squared Errors (SSE), which measures the discrepancy between the observed responses <span class="math inline">\(y\)</span> and the fitted values <span class="math inline">\(X\hat{\beta}\)</span>. <span class="math display">\[
Q(\beta) = \sum_{i=1}^n (y_i - x_i^T \beta)^2 = (y - X\beta)'(y - X\beta)
\]</span></p>
</div>
<p>We can derive the closed-form solution for <span class="math inline">\(\hat{\beta}\)</span> using the geometry of projections discussed in previous chapters.</p>
<section id="obtaining-hat-y" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="obtaining-hat-y">1. Obtaining <span class="math inline">\(\hat Y\)</span></h4>
<p>In the linear model <span class="math inline">\(y = X\beta + e\)</span>, the systematic component (the mean <span class="math inline">\(E[y]\)</span>) is constrained to lie in the column space of <span class="math inline">\(X\)</span>, denoted as <span class="math inline">\(\text{Col}(X)\)</span>. We seek the vector in <span class="math inline">\(\text{Col}(X)\)</span> that is “closest” to the observed data vector <span class="math inline">\(y\)</span>. As established in the theory of projections, this closest vector is the <strong>orthogonal projection</strong> of <span class="math inline">\(y\)</span> onto <span class="math inline">\(\text{Col}(X)\)</span>. Let <span class="math inline">\(\hat{y}\)</span> denote this fitted value vector. Using the explicit formula for the projection matrix <span class="math display">\[H = X(X'X)^{-1}X',\]</span> we have: <span class="math display">\[ \hat{y} = Hy = X(X'X)^{-1}X' y.\]</span></p>
</section>
<section id="obtaining-hatbeta-by-solving-xbeta-haty" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="obtaining-hatbeta-by-solving-xbeta-haty">2. Obtaining <span class="math inline">\(\hat{\beta}\)</span> by Solving <span class="math inline">\(x\beta = \hat{y}\)</span></h4>
<p>Since the fitted vector <span class="math inline">\(\hat{y}\)</span> is a projection onto <span class="math inline">\(\text{Col}(X)\)</span>, it must lie entirely within that column space. This guarantees that the linear system for the coefficients <span class="math inline">\(\hat{\beta}\)</span> is consistent (has an exact solution): <span class="math display">\[ X\hat{\beta} = \hat{y} \]</span></p>
<p>To isolate <span class="math inline">\(\hat{\beta}\)</span>, we pre-multiply both sides by the left pseudo-inverse of <span class="math inline">\(X\)</span>, which is <span class="math inline">\((X'X)^{-1}X'\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
(X'X)^{-1}X' (X\hat{\beta}) &amp;= (X'X)^{-1}X' \hat{y} \\
\underbrace{(X'X)^{-1}(X'X)}_{I} \hat{\beta} &amp;= (X'X)^{-1}X' \hat{y}
\end{aligned}
\]</span></p>
<p>This gives us the estimator expressed in terms of the fitted values:</p>
<p><span class="math display">\[
\boxed{\hat{\beta} = (X'X)^{-1}X' \hat{y}}
\]</span></p>
<p>However, we typically calculate the estimator from the observed data <span class="math inline">\(y\)</span>. Recall that because <span class="math inline">\(\hat{y}\)</span> is an orthogonal projection, the difference <span class="math inline">\(y - \hat{y}\)</span> is orthogonal to <span class="math inline">\(X\)</span>. This implies <span class="math inline">\(X'\hat{y} = X'y\)</span>. Substituting this into the equation above yields the standard closed-form solution:</p>
<p><span class="math display">\[
\boxed{\hat{\beta} = (X'X)^{-1}X'y}
\]</span></p>
</section>
</section>
<section id="properties-of-the-estimator-hat-beta" class="level3" data-number="6.1.4">
<h3 data-number="6.1.4" class="anchored" data-anchor-id="properties-of-the-estimator-hat-beta"><span class="header-section-number">6.1.4</span> Properties of the Estimator <span class="math inline">\(\hat \beta\)</span></h3>
<div id="thm-unbiased" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.1 (Unbiasedness of <span class="math inline">\(\hat \beta\)</span>)</strong></span> If <span class="math inline">\(E(y)=X\beta\)</span>, then <span class="math inline">\(\hat{\beta}\)</span> is an unbiased estimator for <span class="math inline">\(\beta\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><span class="math display">\[
\begin{aligned}
E(\hat{\beta}) &amp;= E[(X^{\prime}X)^{-1}X^{\prime}y] \\
&amp;= (X^{\prime}X)^{-1}X^{\prime}E(y) \quad \text{[using linearity of expectation]} \\
&amp;= (X^{\prime}X)^{-1}X^{\prime}X\beta \\
&amp;= \beta
\end{aligned}
\]</span></p>
</div>
<div id="thm-covariance" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.2 (Variance of <span class="math inline">\(\hat \beta\)</span>)</strong></span> If <span class="math inline">\(\text{Var}(y)=\sigma^{2}I\)</span>, the covariance matrix for <span class="math inline">\(\hat{\beta}\)</span> is given by <span class="math inline">\(\sigma^{2}(X^{\prime}X)^{-1}\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><span class="math display">\[
\begin{aligned}
\text{Var}(\hat{\beta}) &amp;= \text{Var}[(X^{\prime}X)^{-1}X^{\prime}y] \\
&amp;= (X^{\prime}X)^{-1}X^{\prime}\text{Var}(y)[(X^{\prime}X)^{-1}X^{\prime}]^{\prime} \quad \text{[using } \text{Var}(Ay) = A \text{Var}(y) A'] \\
&amp;= (X^{\prime}X)^{-1}X^{\prime}(\sigma^{2}I)X(X^{\prime}X)^{-1} \\
&amp;= \sigma^{2}(X^{\prime}X)^{-1}X^{\prime}X(X^{\prime}X)^{-1} \\
&amp;= \sigma^{2}(X^{\prime}X)^{-1}
\end{aligned}
\]</span></p>
</div>
<p><strong>Note:</strong> These theorems require no assumption of normality.</p>
</section>
</section>
<section id="best-linear-unbiased-estimator-blue" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="best-linear-unbiased-estimator-blue"><span class="header-section-number">6.2</span> Best Linear Unbiased Estimator (BLUE)</h2>
<div id="thm-gauss-markov" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.3 (Gauss-Markov Theorem)</strong></span> If <span class="math inline">\(E(y)=X\beta\)</span> and <span class="math inline">\(\text{Var}(y)=\sigma^{2}I\)</span>, the least-squares estimators <span class="math inline">\(\hat{\beta}_{j}, j=0,1,...,k\)</span> have minimum variance among all linear unbiased estimators.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We consider a linear estimator <span class="math inline">\(Ay\)</span> of <span class="math inline">\(\beta\)</span> and seek the matrix <span class="math inline">\(A\)</span> for which <span class="math inline">\(Ay\)</span> is a minimum variance unbiased estimator.</p>
<p><strong>1. Unbiasedness Condition:</strong> In order for <span class="math inline">\(Ay\)</span> to be an unbiased estimator of <span class="math inline">\(\beta\)</span>, we must have <span class="math inline">\(E(Ay)=\beta\)</span>. Using the assumption <span class="math inline">\(E(y)=X\beta\)</span>, this is expressed as: <span class="math display">\[E(Ay) = A E(y) = AX\beta = \beta\]</span> which implies the condition <span class="math inline">\(AX=I_{k+1}\)</span> since the relationship must hold for any <span class="math inline">\(\beta\)</span>.</p>
<p><strong>2. Minimizing Variance:</strong> The covariance matrix for the estimator <span class="math inline">\(Ay\)</span> is: <span class="math display">\[\text{Var}(Ay) = A \text{Var}(y) A' = A(\sigma^2 I) A' = \sigma^2 AA'\]</span> We need to choose <span class="math inline">\(A\)</span> (subject to <span class="math inline">\(AX=I\)</span>) so that the diagonal elements of <span class="math inline">\(AA'\)</span> are minimized.</p>
<p>To relate <span class="math inline">\(Ay\)</span> to <span class="math inline">\(\hat{\beta}=(X'X)^{-1}X'y\)</span>, we define <span class="math inline">\(\hat{A} = (X'X)^{-1}X'\)</span> and write <span class="math inline">\(A = (A - \hat{A}) + \hat{A}\)</span>. Then: <span class="math display">\[AA' = [(A - \hat{A}) + \hat{A}] [(A - \hat{A}) + \hat{A}]'\]</span> Expanding this, the cross terms vanish because <span class="math inline">\((A - \hat{A})\hat{A}' = A\hat{A}' - \hat{A}\hat{A}'\)</span>. Note that <span class="math inline">\(\hat{A}\hat{A}' = (X'X)^{-1}X'X(X'X)^{-1} = (X'X)^{-1}\)</span>. Also, <span class="math inline">\(A\hat{A}' = A X (X'X)^{-1} = I (X'X)^{-1} = (X'X)^{-1}\)</span> (since <span class="math inline">\(AX=I\)</span>). Thus, <span class="math inline">\((A - \hat{A})\hat{A}' = 0\)</span>.</p>
<p>The expansion simplifies to: <span class="math display">\[AA' = (A - \hat{A})(A - \hat{A})' + \hat{A}\hat{A}'\]</span> The matrix <span class="math inline">\((A - \hat{A})(A - \hat{A})'\)</span> is positive semidefinite, meaning its diagonal elements are non-negative. To minimize the diagonal of <span class="math inline">\(AA'\)</span>, we must set <span class="math inline">\(A - \hat{A} = 0\)</span>, which implies <span class="math inline">\(A = \hat{A}\)</span>.</p>
<p>Thus, the minimum variance estimator is: <span class="math display">\[Ay = (X'X)^{-1}X'y = \hat{\beta}\]</span></p>
</div>
<section id="notes-on-gauss-markov" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="notes-on-gauss-markov"><span class="header-section-number">6.2.1</span> Notes on Gauss-markov</h3>
<ol type="1">
<li><p><strong>Distributional Generality:</strong> The remarkable feature of the Gauss-Markov theorem is that it holds for <em>any</em> distribution of <span class="math inline">\(y\)</span>; normality is not required. The only assumptions used are linearity (<span class="math inline">\(E(y)=X\beta\)</span>) and homoscedasticity (<span class="math inline">\(\text{Var}(y)=\sigma^2 I\)</span>).</p></li>
<li><p><strong>Extension to All Linear Combinations:</strong> The theorem extends beyond just the parameter vector <span class="math inline">\(\beta\)</span> to any linear combination of the parameters.</p></li>
</ol>
<div id="cor-linear-combo" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 6.1 (BLUE for All Linear Combinations)</strong></span> If <span class="math inline">\(E(y)=X\beta\)</span> and <span class="math inline">\(\text{Var}(y)=\sigma^{2}I\)</span>, the best linear unbiased estimator of the scalar <span class="math inline">\(a'\beta\)</span> is <span class="math inline">\(a'\hat{\beta}\)</span>, where <span class="math inline">\(\hat{\beta}\)</span> is the least-squares estimator.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(\tilde{\beta} = Ay\)</span> be any other linear unbiased estimator of <span class="math inline">\(\beta\)</span>. The variance of the linear combination <span class="math inline">\(a'\tilde{\beta}\)</span> is: <span class="math display">\[
\frac{1}{\sigma^2}\text{Var}(a'\tilde{\beta}) = \frac{1}{\sigma^2}\text{Var}(a'Ay) = a'AA'a
\]</span> From the proof of the Gauss-Markov theorem, we established that <span class="math inline">\(AA' = (A-\hat{A})(A-\hat{A})' + (X'X)^{-1}\)</span> where <span class="math inline">\(\hat{A} = (X'X)^{-1}X'\)</span>. Substituting this into the variance equation: <span class="math display">\[
a'AA'a = a'(A-\hat{A})(A-\hat{A})'a + a'(X'X)^{-1}a
\]</span> The term <span class="math inline">\(a'(A-\hat{A})(A-\hat{A})'a\)</span> is a quadratic form with a positive semidefinite matrix, so it is always non-negative. Therefore: <span class="math display">\[
a'AA'a \ge a'(X'X)^{-1}a = \frac{1}{\sigma^2}\text{Var}(a'\hat{\beta})
\]</span> The variance is minimized when <span class="math inline">\(A=\hat{A}\)</span> (specifically when the first term is zero), proving that <span class="math inline">\(a'\hat{\beta}\)</span> has the minimum variance among all linear unbiased estimators.</p>
</div>
<ol start="3" type="1">
<li><strong>Scaling Invariance:</strong> The predictions made by the model are invariant to the scaling of the explanatory variables.</li>
</ol>
<div id="thm-scaling" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.4 (Scaling Explanatory Variables)</strong></span> If <span class="math inline">\(x=(1,x_{1},...,x_{k})'\)</span> and <span class="math inline">\(z=(1,c_{1}x_{1},...,c_{k}x_{k})'\)</span>, then the fitted values are identical: <span class="math inline">\(\hat{y} = \hat{\beta}'x = \hat{\beta}_{z}'z\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(D = \text{diag}(1, c_1, ..., c_k)\)</span> such that the design matrix is transformed to <span class="math inline">\(Z = XD\)</span>. The LSE for the transformed data is: <span class="math display">\[
\begin{aligned}
\hat{\beta}_z &amp;= (Z'Z)^{-1}Z'y = [(XD)'(XD)]^{-1}(XD)'y \\
&amp;= D^{-1}(X'X)^{-1}(D')^{-1}D'X'y \\
&amp;= D^{-1}(X'X)^{-1}X'y = D^{-1}\hat{\beta}
\end{aligned}
\]</span> . Then, the prediction is: <span class="math display">\[
\hat{\beta}_z' z = (D^{-1}\hat{\beta})' (Dx) = \hat{\beta}' (D^{-1})' D x = \hat{\beta}'x
\]</span> .</p>
</div>
<section id="limitations-restriction-to-unbiased-estimators" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="limitations-restriction-to-unbiased-estimators">Limitations: Restriction to Unbiased Estimators</h4>
<p>It is crucial to recognize that the Gauss-Markov theorem only guarantees optimality within the class of <strong>linear</strong> and <strong>unbiased</strong> estimators.</p>
<ul>
<li><strong>Assumption Sensitivity:</strong> If the assumptions of linearity (<span class="math inline">\(E(y)=X\beta\)</span>) and homoscedasticity (<span class="math inline">\(\text{Var}(y)=\sigma^2 I\)</span>) do not hold, <span class="math inline">\(\hat{\beta}\)</span> may be biased or may have a larger variance than other estimators.</li>
<li><strong>Unbiasedness Constraint:</strong> The theorem does not compare <span class="math inline">\(\hat{\beta}\)</span> to biased estimators. It is possible for a biased estimator (e.g., shrinkage estimators) to have a smaller Mean Squared Error (MSE) than the BLUE by accepting some bias to significantly reduce variance. The LSE is only “best” (minimum variance) among those estimators that satisfy the unbiasedness constraint.</li>
</ul>
</section>
</section>
</section>
<section id="estimator-of-error-variance" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="estimator-of-error-variance"><span class="header-section-number">6.3</span> Estimator of Error Variance</h2>
<p>We estimate <span class="math inline">\(\sigma^{2}\)</span> by the residual mean square:</p>
<div id="def-s2" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.2 (Residual Variance Estimator)</strong></span> <span class="math display">\[s^{2} = \frac{1}{n-k-1} \sum_{i=1}^{n}(y_{i}-x_{i}'\hat{\beta})^{2} = \frac{\text{SSE}}{n-k-1}\]</span> where <span class="math inline">\(\text{SSE} = (y-X\hat{\beta})'(y-X\hat{\beta})\)</span>.</p>
</div>
<p>Alternatively, SSE can be written as: <span class="math display">\[\text{SSE} = y'y - \hat{\beta}'X'y\]</span> This is often useful for computation (<span class="math inline">\(y'y\)</span> is the total sum of squares of the raw data).</p>
<section id="unbiasedness-of-s2" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="unbiasedness-of-s2"><span class="header-section-number">6.3.1</span> Unbiasedness of <span class="math inline">\(s^2\)</span></h3>
<div id="thm-unbiased-s2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.5 (Unbiasedness of s-squared)</strong></span> If <span class="math inline">\(s^{2}\)</span> is defined as above, and if <span class="math inline">\(E(y)=X\beta\)</span> and <span class="math inline">\(\text{Var}(y)=\sigma^{2}I\)</span>, then <span class="math inline">\(E(s^{2})=\sigma^{2}\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We use the Hat Matrix <span class="math inline">\(H = X(X'X)^{-1}X'\)</span>, which projects <span class="math inline">\(y\)</span> onto <span class="math inline">\(\text{Col}(X)\)</span>. Thus, <span class="math inline">\(\hat{y} = Hy\)</span>. The residuals are <span class="math inline">\(y - \hat{y} = (I - H)y\)</span>. The Sum of Squared Errors is: <span class="math display">\[\text{SSE} = \|(I-H)y\|^2 = y'(I-H)'(I-H)y\]</span> Since <span class="math inline">\(H\)</span> is symmetric and idempotent, <span class="math inline">\((I-H)\)</span> is also symmetric and idempotent. Thus: <span class="math display">\[\text{SSE} = y'(I-H)y\]</span></p>
<p>To find the expectation, we use the trace trick for quadratic forms: <span class="math inline">\(E[y'Ay] = \text{tr}(A\text{Var}(y)) + E[y]'A E[y]\)</span>. <span class="math display">\[
\begin{aligned}
E(\text{SSE}) &amp;= E[y'(I-H)y] \\
&amp;= \text{tr}((I-H)\sigma^2 I) + (X\beta)'(I-H)(X\beta) \\
&amp;= \sigma^2 \text{tr}(I-H) + \beta'X'(I-H)X\beta
\end{aligned}
\]</span> <strong>Trace Term:</strong> <span class="math inline">\(\text{tr}(I_n - H) = \text{tr}(I_n) - \text{tr}(H) = n - (k+1)\)</span>, since <span class="math inline">\(\text{tr}(H) = \text{tr}(X(X'X)^{-1}X') = \text{tr}((X'X)^{-1}X'X) = \text{tr}(I_{k+1}) = k+1\)</span>.</p>
<p><strong>Non-centrality Term:</strong> Since <span class="math inline">\(HX = X\)</span>, we have <span class="math inline">\((I-H)X = 0\)</span>. Therefore, the second term vanishes: <span class="math inline">\(\beta'X'(I-H)X\beta = 0\)</span>.</p>
<p>Combining these: <span class="math display">\[E(\text{SSE}) = \sigma^2(n - k - 1)\]</span> Dividing by the degrees of freedom <span class="math inline">\((n-k-1)\)</span>, we get <span class="math inline">\(E(s^2) = \sigma^2\)</span>.</p>
</div>
</section>
</section>
<section id="distributions-under-normality" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="distributions-under-normality"><span class="header-section-number">6.4</span> Distributions Under Normality</h2>
<p>If we add Assumption A5 (<span class="math inline">\(y \sim N_n(X\beta, \sigma^2 I)\)</span>), we can derive the exact sampling distributions.</p>
<div id="cor-cov-beta" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 6.2 (Estimated Covariance of Beta)</strong></span> An unbiased estimator of <span class="math inline">\(\text{Cov}(\hat{\beta})\)</span> is given by: <span class="math display">\[\widehat{\text{Cov}}(\hat{\beta}) = s^{2}(X'X)^{-1}\]</span></p>
</div>
<div id="thm-sampling-dist" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.6 (Sampling Distributions)</strong></span> Under assumptions A1-A5:</p>
<ol type="1">
<li><span class="math inline">\(\hat{\beta} \sim N_{k+1}(\beta, \sigma^{2}(X'X)^{-1})\)</span>.</li>
<li><span class="math inline">\((n-k-1)s^{2}/\sigma^{2} \sim \chi^{2}(n-k-1)\)</span>.</li>
<li><span class="math inline">\(\hat{\beta}\)</span> and <span class="math inline">\(s^{2}\)</span> are independent.</li>
</ol>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><strong>Part (i):</strong> Since <span class="math inline">\(\hat{\beta} = (X'X)^{-1}X'y\)</span> is a linear transformation of the normal vector <span class="math inline">\(y\)</span>, it is also normally distributed. We already established its mean and variance in <a href="#thm-unbiased" class="quarto-xref">Theorem&nbsp;<span>6.1</span></a> and <a href="#thm-covariance" class="quarto-xref">Theorem&nbsp;<span>6.2</span></a>.</p>
<p><strong>Part (ii):</strong> We showed <span class="math inline">\(\text{SSE} = y'(I-H)y\)</span>. Since <span class="math inline">\((I-H)\)</span> is idempotent with rank <span class="math inline">\(n-k-1\)</span>, and <span class="math inline">\((I-H)X\beta = 0\)</span>, by the theory of quadratic forms in normal variables, <span class="math inline">\(\text{SSE}/\sigma^2 \sim \chi^2(n-k-1)\)</span>.</p>
<p><strong>Part (iii):</strong> <span class="math inline">\(\hat{\beta}\)</span> depends on <span class="math inline">\(Hy\)</span> (or <span class="math inline">\(X'y\)</span>), while <span class="math inline">\(s^2\)</span> depends on <span class="math inline">\((I-H)y\)</span>. Since <span class="math inline">\(H(I-H) = H - H^2 = 0\)</span>, the linear forms defining the estimator and the residuals are orthogonal. For normal vectors, zero covariance implies independence.</p>
</div>
</section>
<section id="maximum-likelihood-estimator-mle" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="maximum-likelihood-estimator-mle"><span class="header-section-number">6.5</span> Maximum Likelihood Estimator (MLE)</h2>
<div id="thm-mle" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.7 (MLE for Linear Regression)</strong></span> If <span class="math inline">\(y \sim N_n(X\beta, \sigma^2 I)\)</span>, the Maximum Likelihood Estimators are: <span class="math display">\[
\hat{\beta}_{\text{MLE}} = (X'X)^{-1}X'y
\]</span> <span class="math display">\[
\hat{\sigma}^2_{\text{MLE}} = \frac{1}{n}(y - X\hat{\beta})'(y - X\hat{\beta}) = \frac{\text{SSE}}{n}
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The log-likelihood function is: <span class="math display">\[ \ln L(\beta, \sigma^2) = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}(y - X\beta)'(y - X\beta) \]</span> Maximizing this with respect to <span class="math inline">\(\beta\)</span> is equivalent to minimizing the quadratic term <span class="math inline">\((y - X\beta)'(y - X\beta)\)</span>, which yields the Least Squares Estimator. Differentiating with respect to <span class="math inline">\(\sigma^2\)</span> and setting to zero yields <span class="math inline">\(\hat{\sigma}^2 = \text{SSE}/n\)</span>.</p>
</div>
<p><strong>Note:</strong> The MLE for <span class="math inline">\(\sigma^2\)</span> is biased (denominator <span class="math inline">\(n\)</span>), whereas <span class="math inline">\(s^2\)</span> is unbiased (denominator <span class="math inline">\(n-k-1\)</span>).</p>
</section>
<section id="linear-models-in-centered-form" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="linear-models-in-centered-form"><span class="header-section-number">6.6</span> Linear Models in Centered Form</h2>
<p>The regression model can be written in a centered form by subtracting the means of the explanatory variables: <span class="math display">\[y_{i}=\alpha+\beta_{1}(x_{i1}-\overline{x}_{1})+\beta_{2}(x_{i2}-\overline{x}_{2})+\cdot\cdot\cdot+\beta_{k}(x_{ik}-\overline{x}_{k})+e_{i}\]</span> for <span class="math inline">\(i=1,...,n\)</span>, where the intercept term is adjusted: <span class="math display">\[\alpha=\beta_{0}+\beta_{1}\overline{x}_{1}+\beta_{2}\overline{x}_{2}+\cdot\cdot\cdot+\beta_{k}\overline{x}_{k}\]</span> and <span class="math inline">\(\overline{x}_{j}=\frac{1}{n}\sum_{i=1}^{n}x_{ij}\)</span>.</p>
<section id="matrix-formulation-1" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="matrix-formulation-1"><span class="header-section-number">6.6.1</span> Matrix Formulation</h3>
<p>In matrix form, the equivalence between the original model and the centered model is: <span class="math display">\[y = X\beta + e = (j_n, X_c)\begin{pmatrix} \alpha \\ \beta_{1} \end{pmatrix} + e\]</span> where <span class="math inline">\(\beta_{1}=(\beta_{1},...,\beta_{k})^{T}\)</span> represents the slope coefficients, and <span class="math inline">\(X_c\)</span> is the centered design matrix: <span class="math display">\[X_c = (I - P_{j_n})X_1\]</span> Here, <span class="math inline">\(X_1\)</span> consists of the original columns of <span class="math inline">\(X\)</span> excluding the intercept column.</p>
<p>To see the structure of <span class="math inline">\(X_c\)</span>, we first calculate the projection of the data onto the intercept space, <span class="math inline">\(P_{j_n}X_1\)</span>: <span class="math display">\[
\begin{aligned}
P_{j_n}X_1 &amp;= \frac{1}{n}j_n j_n' X_1 \\
&amp;= \begin{pmatrix} 1/n &amp; 1/n &amp; \cdots &amp; 1/n \\ 1/n &amp; 1/n &amp; \cdots &amp; 1/n \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1/n &amp; 1/n &amp; \cdots &amp; 1/n \end{pmatrix} \begin{pmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1k} \\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2k} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nk} \end{pmatrix} \\
&amp;= \begin{pmatrix} \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \\ \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \end{pmatrix}
\end{aligned}
\]</span> This results in a matrix where every row is the vector of column means. Subtracting this from <span class="math inline">\(X_1\)</span> gives <span class="math inline">\(X_c\)</span>: <span class="math display">\[
\begin{aligned}
X_c &amp;= X_1 - P_{j_n}X_1 \\
&amp;= \begin{pmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1k} \\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2k} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nk} \end{pmatrix} - \begin{pmatrix} \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \\ \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \bar{x}_1 &amp; \bar{x}_2 &amp; \cdots &amp; \bar{x}_k \end{pmatrix} \\
&amp;= \begin{pmatrix} x_{11} - \bar{x}_1 &amp; x_{12} - \bar{x}_2 &amp; \cdots &amp; x_{1k} - \bar{x}_k \\ x_{21} - \bar{x}_1 &amp; x_{22} - \bar{x}_2 &amp; \cdots &amp; x_{2k} - \bar{x}_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n1} - \bar{x}_1 &amp; x_{n2} - \bar{x}_2 &amp; \cdots &amp; x_{nk} - \bar{x}_k \end{pmatrix}
\end{aligned}
\]</span></p>
</section>
<section id="estimation-in-centered-form" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2" class="anchored" data-anchor-id="estimation-in-centered-form"><span class="header-section-number">6.6.2</span> Estimation in Centered Form</h3>
<p>Because the column space of the intercept <span class="math inline">\(j_n\)</span> is orthogonal to the columns of <span class="math inline">\(X_c\)</span> (since columns of <span class="math inline">\(X_c\)</span> sum to zero), the cross-product matrix becomes block diagonal: <span class="math display">\[
\begin{pmatrix} j_n' \\ X_c' \end{pmatrix} (j_n, X_c) = \begin{pmatrix} j_n'j_n &amp; j_n'X_c \\ X_c'j_n &amp; X_c'X_c \end{pmatrix} = \begin{pmatrix} n &amp; 0 \\ 0 &amp; X_c'X_c \end{pmatrix}
\]</span></p>
<div id="thm-centered-estimators" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.8 (Centered Estimators)</strong></span> The least squares estimators for the centered parameters are: <span class="math display">\[
\begin{pmatrix} \hat{\alpha} \\ \hat{\beta}_{1} \end{pmatrix} = \begin{pmatrix} n &amp; 0 \\ 0 &amp; X_c'X_c \end{pmatrix}^{-1} \begin{pmatrix} j_n'y \\ X_c'y \end{pmatrix} = \begin{pmatrix} \bar{y} \\ (X_c'X_c)^{-1}X_c'y \end{pmatrix}
\]</span> Thus:</p>
<ol type="1">
<li><span class="math inline">\(\hat{\alpha} = \bar{y}\)</span> (The sample mean of <span class="math inline">\(y\)</span>).</li>
<li><span class="math inline">\(\hat{\beta}_{1} = S_{xx}^{-1}S_{xy}\)</span>, using the sample covariance notations.</li>
</ol>
</div>
<p>Recovering the original intercept: <span class="math display">\[ \hat{\beta}_0 = \hat{\alpha} - \hat{\beta}_1 \bar{x}_1 - \dots - \hat{\beta}_k \bar{x}_k = \bar{y} - \hat{\beta}_{1}'\bar{x} \]</span></p>
</section>
</section>
<section id="decomposition-of-sum-of-squares" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="decomposition-of-sum-of-squares"><span class="header-section-number">6.7</span> Decomposition of Sum of Squares</h2>
<p>We partition the total variation based on the orthogonal subspaces.</p>
<div id="def-ss-components" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.3 (Sum of Squares Components)</strong></span> The total variation is decomposed as <span class="math inline">\(\text{SST} = \text{SSR} + \text{SSE}\)</span>.</p>
<ol type="1">
<li><p><strong>Total Sum of Squares (SST):</strong> The squared length of the centered response vector. <span class="math display">\[\text{SST} = \|y - \bar{y}j_n\|^2 = \|(I - P_{j_n})y\|^2\]</span></p></li>
<li><p><strong>Regression Sum of Squares (SSR):</strong> The variation explained by the regressors <span class="math inline">\(X_c\)</span>. <span class="math display">\[\text{SSR} = \|\hat{y} - \bar{y}j_n\|^2 = \|P_{X_c}y\|^2 = \hat{\beta}_1' X_c' X_c \hat{\beta}_1\]</span></p></li>
<li><p><strong>Sum of Squared Errors (SSE):</strong> The residual variation. <span class="math display">\[\text{SSE} = \|y - \hat{y}\|^2 = \|(I - H)y\|^2\]</span></p></li>
</ol>
</div>
<section id="d-visualization-of-decomposition-of-y" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="d-visualization-of-decomposition-of-y"><span class="header-section-number">6.7.1</span> 3D Visualization of Decomposition of <span class="math inline">\(y\)</span></h3>
<p>We partition the total variation in <span class="math inline">\(y\)</span> based on the orthogonal subspaces.</p>
<ol type="1">
<li><strong>Space of the Mean:</strong> <span class="math inline">\(L(j_n)\)</span>, spanned by the intercept vector <span class="math inline">\(j_n\)</span>.</li>
<li><strong>Space of the Regressors:</strong> <span class="math inline">\(L(X_c)\)</span>, spanned by the centered predictors <span class="math inline">\(X_c\)</span>.</li>
<li><strong>Error Space:</strong> <span class="math inline">\(\text{Col}(X)^\perp\)</span>, orthogonal to the model space.</li>
</ol>
<p>The vector <span class="math inline">\(y\)</span> can be decomposed into three orthogonal components: <span class="math display">\[y = \bar{y}j_n + P_{X_c}y + (y - \hat{y})\]</span> Visually, this corresponds to projecting the vector <span class="math inline">\(y\)</span> onto three orthogonal axes.</p>
<p><strong>Interactive Visualization:</strong></p>
<p>We generate a cloud of 100 observations of <span class="math inline">\(y\)</span> from <span class="math inline">\(N(\mu, \sigma=1)\)</span> where <span class="math inline">\(\mu = (5,5,0)\)</span>. The projections onto the Model Plane (<span class="math inline">\(z=0\)</span>) are highlighted in <strong>red</strong>, and the projections onto the error axis (<span class="math inline">\(z\)</span>) are in <strong>yellow</strong>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Effect Exists (signal)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">No Effect (noise)</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-d96970b9501c191ad406" style="width:100%;height:576px;"></div>
<script type="application/json" data-for="htmlwidget-d96970b9501c191ad406">{"x":{"visdat":{"16cb02a6e5d78":["function () ","plotlyVisDat"],"16cb033ba870b":["function () ","data"],"16cb01af7fdb5":["function () ","data"],"16cb0f3183e8":["function () ","data"],"16cb07bcafc22":["function () ","data"],"16cb04b6f5bac":["function () ","data"]},"cur_data":"16cb04b6f5bac","attrs":{"16cb02a6e5d78":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],"type":"surface","x":[0,0.36842105263157893,0.73684210526315785,1.1052631578947367,1.4736842105263157,1.8421052631578947,2.2105263157894735,2.5789473684210527,2.9473684210526314,3.3157894736842102,3.6842105263157894,4.0526315789473681,4.4210526315789469,4.7894736842105257,5.1578947368421053,5.5263157894736841,5.8947368421052628,6.2631578947368416,6.6315789473684204,7],"y":[-4,-3.3684210526315788,-2.736842105263158,-2.1052631578947372,-1.4736842105263159,-0.84210526315789469,-0.21052631578947389,0.4210526315789469,1.0526315789473681,1.6842105263157894,2.3157894736842106,2.947368421052631,3.5789473684210522,4.2105263157894726,4.8421052631578938,5.473684210526315,6.1052631578947363,6.7368421052631575,7.3684210526315788,8],"opacity":0.29999999999999999,"colorscale":[[0,1],["steelblue","steelblue"]],"showscale":false,"name":"Model Space","inherit":true},"16cb033ba870b":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":{},"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"red","symbol":"diamond","opacity":0.80000000000000004},"name":"Proj on Floor","inherit":true},"16cb01af7fdb5":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":{},"z":{},"marker":{"size":4,"color":"black","symbol":"circle","opacity":0.59999999999999998},"name":"Data Cloud","inherit":true},"16cb0f3183e8":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"blue","symbol":"circle-open","opacity":0.59999999999999998},"name":"Proj L(jn)","inherit":true},"16cb07bcafc22":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":{},"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"green","symbol":"circle-open","opacity":0.59999999999999998},"name":"Proj L(Xc)","inherit":true},"16cb04b6f5bac":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":{},"marker":{"size":4,"color":"gold","symbol":"circle-open","opacity":0.80000000000000004},"name":"Error","inherit":true},"16cb04b6f5bac.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[0,3],"y":[0,4],"z":[0,0],"line":{"color":"black","width":6},"name":"Mean Vector","inherit":true},"16cb04b6f5bac.2":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[3,3],"y":[4,0],"z":[0,0],"line":{"color":"blue","width":4,"dash":"dash"},"name":"Link to X","inherit":true},"16cb04b6f5bac.3":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[3,0],"y":[4,4],"z":[0,0],"line":{"color":"green","width":4,"dash":"dash"},"name":"Link to Y","inherit":true}},"layout":{"margin":{"b":0,"l":0,"t":30,"r":0},"title":"Scenario A: Effect Exists","scene":{"xaxis":{"title":"L(j<sub>n<\/sub>)","range":[0,8]},"yaxis":{"title":"L(X<sub>c<\/sub>)","range":[-4,8]},"zaxis":{"title":"Col(X)<sup>&perp;<\/sup>","range":[-4,4]},"aspectmode":"cube","camera":{"eye":{"x":1.6000000000000001,"y":1.6000000000000001,"z":0.59999999999999998}}},"showlegend":false,"hovermode":"closest"},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"colorbar":{"title":"z<br />z","ticklen":2},"colorscale":[[0,"steelblue"],[1,"steelblue"]],"showscale":false,"z":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],"type":"surface","x":[0,0.36842105263157893,0.73684210526315785,1.1052631578947367,1.4736842105263157,1.8421052631578947,2.2105263157894735,2.5789473684210527,2.9473684210526314,3.3157894736842102,3.6842105263157894,4.0526315789473681,4.4210526315789469,4.7894736842105257,5.1578947368421053,5.5263157894736841,5.8947368421052628,6.2631578947368416,6.6315789473684204,7],"y":[-4,-3.3684210526315788,-2.736842105263158,-2.1052631578947372,-1.4736842105263159,-0.84210526315789469,-0.21052631578947389,0.4210526315789469,1.0526315789473681,1.6842105263157894,2.3157894736842106,2.947368421052631,3.5789473684210522,4.2105263157894726,4.8421052631578938,5.473684210526315,6.1052631578947363,6.7368421052631575,7.3684210526315788,8],"opacity":0.29999999999999999,"name":"Model Space","frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[4.1266592569973772,3.9857266223256484,3.9785647713543422,4.6843011420072287,3.8871145071703661,4.7582353022147696,3.2256235978848893,4.2923068748180349,4.0619271219223068,4.1079707843719859,4.1898197413799414,3.7488382734453487,3.8333963081652898,3.4907123084464557,3.4641043867622114,4.1517643207021289,4.2241048893147131,4.0265021133652521,4.4611337339398691,5.0250423428135722,3.7544844169717324,2.8454155621795936,4.5028692622311279,3.6453996187088036,3.655995691766321,4.5127856848483496,3.8576134964744955,3.3896411438727325,4.0906517398745752,3.9305543187804779,4.0028820929499433,4.1926402005631651,3.8146699841037952,4.3221882742594167,3.8897567190906246,4.1658909819578485,4.5484195065746738,4.217590745416901,3.8370342072343866,4.5744038092255472,4.4967519279810597,4.2741984797540349,4.1193658675557208,3.6860469619803142,4.6803262242650039,3.6998702064264366,5.0936664965082885,4.7663053130925945,3.8821498204497615,3.4867895498466099],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"red","size":4,"symbol":"diamond","opacity":0.80000000000000004,"line":{"color":"rgba(255,127,14,1)"}},"name":"Proj on Floor","error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[4.1266592569973772,3.9857266223256484,3.9785647713543422,4.6843011420072287,3.8871145071703661,4.7582353022147696,3.2256235978848893,4.2923068748180349,4.0619271219223068,4.1079707843719859,4.1898197413799414,3.7488382734453487,3.8333963081652898,3.4907123084464557,3.4641043867622114,4.1517643207021289,4.2241048893147131,4.0265021133652521,4.4611337339398691,5.0250423428135722,3.7544844169717324,2.8454155621795936,4.5028692622311279,3.6453996187088036,3.655995691766321,4.5127856848483496,3.8576134964744955,3.3896411438727325,4.0906517398745752,3.9305543187804779,4.0028820929499433,4.1926402005631651,3.8146699841037952,4.3221882742594167,3.8897567190906246,4.1658909819578485,4.5484195065746738,4.217590745416901,3.8370342072343866,4.5744038092255472,4.4967519279810597,4.2741984797540349,4.1193658675557208,3.6860469619803142,4.6803262242650039,3.6998702064264366,5.0936664965082885,4.7663053130925945,3.8821498204497615,3.4867895498466099],"z":[-0.2802378232761063,-0.11508874474163999,0.77935415707456202,0.035254195712287995,0.064643867580473122,0.85753249344164062,0.2304581029946012,-0.63253061730326687,-0.34342642594676298,-0.22283098504997906,0.61204089871973089,0.17990691352868191,0.20038572529702606,0.055341357972559839,-0.27792056737703746,0.89345656840153909,0.24892523911461972,-0.9833085783148191,0.35067795078184272,-0.23639570386396702,-0.53391185299342259,-0.10898745732914752,-0.51300222415361985,-0.36444561464557002,-0.31251963392462845,-0.84334665537120668,0.41889352224726234,0.076686558918257611,-0.56906846850597381,0.62690746053496338,0.21323211073840678,-0.1475357414961356,0.44756283052251122,0.43906674376652111,0.41079054081874361,0.3443201270500455,0.27695882676879441,-0.03095585528836084,-0.15298133186995838,-0.19023550050619131,-0.34735348946025635,-0.10395863900979939,-0.63269817578413223,1.0844779826692563,0.60398099915249526,-0.5615542916016748,-0.20144241764953799,-0.23332767681160937,0.38998255916815894,-0.041684533235914624],"marker":{"color":"black","size":4,"symbol":"circle","opacity":0.59999999999999998,"line":{"color":"rgba(44,160,44,1)"}},"name":"Data Cloud","error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"blue","size":4,"symbol":"circle-open","opacity":0.59999999999999998,"line":{"color":"rgba(214,39,40,1)"}},"name":"Proj L(jn)","error_y":{"color":"rgba(214,39,40,1)"},"error_x":{"color":"rgba(214,39,40,1)"},"line":{"color":"rgba(214,39,40,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[4.1266592569973772,3.9857266223256484,3.9785647713543422,4.6843011420072287,3.8871145071703661,4.7582353022147696,3.2256235978848893,4.2923068748180349,4.0619271219223068,4.1079707843719859,4.1898197413799414,3.7488382734453487,3.8333963081652898,3.4907123084464557,3.4641043867622114,4.1517643207021289,4.2241048893147131,4.0265021133652521,4.4611337339398691,5.0250423428135722,3.7544844169717324,2.8454155621795936,4.5028692622311279,3.6453996187088036,3.655995691766321,4.5127856848483496,3.8576134964744955,3.3896411438727325,4.0906517398745752,3.9305543187804779,4.0028820929499433,4.1926402005631651,3.8146699841037952,4.3221882742594167,3.8897567190906246,4.1658909819578485,4.5484195065746738,4.217590745416901,3.8370342072343866,4.5744038092255472,4.4967519279810597,4.2741984797540349,4.1193658675557208,3.6860469619803142,4.6803262242650039,3.6998702064264366,5.0936664965082885,4.7663053130925945,3.8821498204497615,3.4867895498466099],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"green","size":4,"symbol":"circle-open","opacity":0.59999999999999998,"line":{"color":"rgba(148,103,189,1)"}},"name":"Proj L(Xc)","error_y":{"color":"rgba(148,103,189,1)"},"error_x":{"color":"rgba(148,103,189,1)"},"line":{"color":"rgba(148,103,189,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[-0.2802378232761063,-0.11508874474163999,0.77935415707456202,0.035254195712287995,0.064643867580473122,0.85753249344164062,0.2304581029946012,-0.63253061730326687,-0.34342642594676298,-0.22283098504997906,0.61204089871973089,0.17990691352868191,0.20038572529702606,0.055341357972559839,-0.27792056737703746,0.89345656840153909,0.24892523911461972,-0.9833085783148191,0.35067795078184272,-0.23639570386396702,-0.53391185299342259,-0.10898745732914752,-0.51300222415361985,-0.36444561464557002,-0.31251963392462845,-0.84334665537120668,0.41889352224726234,0.076686558918257611,-0.56906846850597381,0.62690746053496338,0.21323211073840678,-0.1475357414961356,0.44756283052251122,0.43906674376652111,0.41079054081874361,0.3443201270500455,0.27695882676879441,-0.03095585528836084,-0.15298133186995838,-0.19023550050619131,-0.34735348946025635,-0.10395863900979939,-0.63269817578413223,1.0844779826692563,0.60398099915249526,-0.5615542916016748,-0.20144241764953799,-0.23332767681160937,0.38998255916815894,-0.041684533235914624],"marker":{"color":"gold","size":4,"symbol":"circle-open","opacity":0.80000000000000004,"line":{"color":"rgba(140,86,75,1)"}},"name":"Error","error_y":{"color":"rgba(140,86,75,1)"},"error_x":{"color":"rgba(140,86,75,1)"},"line":{"color":"rgba(140,86,75,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[0,3],"y":[0,4],"z":[0,0],"line":{"color":"black","width":6},"name":"Mean Vector","marker":{"color":"rgba(227,119,194,1)","line":{"color":"rgba(227,119,194,1)"}},"error_y":{"color":"rgba(227,119,194,1)"},"error_x":{"color":"rgba(227,119,194,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[3,3],"y":[4,0],"z":[0,0],"line":{"color":"blue","width":4,"dash":"dash"},"name":"Link to X","marker":{"color":"rgba(127,127,127,1)","line":{"color":"rgba(127,127,127,1)"}},"error_y":{"color":"rgba(127,127,127,1)"},"error_x":{"color":"rgba(127,127,127,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[3,0],"y":[4,4],"z":[0,0],"line":{"color":"green","width":4,"dash":"dash"},"name":"Link to Y","marker":{"color":"rgba(188,189,34,1)","line":{"color":"rgba(188,189,34,1)"}},"error_y":{"color":"rgba(188,189,34,1)"},"error_x":{"color":"rgba(188,189,34,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Scenario 1: Significant regression effect (<span class="math inline">\(\beta_1
ot= 0\)</span>). The mean vector projects significantly onto the predictor space.</p>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-bbf49928d385f1dd9e5c" style="width:100%;height:576px;"></div>
<script type="application/json" data-for="htmlwidget-bbf49928d385f1dd9e5c">{"x":{"visdat":{"16cb03f008a0":["function () ","plotlyVisDat"],"16cb03c64265":["function () ","data"],"16cb04d30f6d2":["function () ","data"],"16cb0499c7c95":["function () ","data"],"16cb040b73ff4":["function () ","data"],"16cb03ec7cd5d":["function () ","data"]},"cur_data":"16cb03ec7cd5d","attrs":{"16cb03f008a0":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],"type":"surface","x":[0,0.36842105263157893,0.73684210526315785,1.1052631578947367,1.4736842105263157,1.8421052631578947,2.2105263157894735,2.5789473684210527,2.9473684210526314,3.3157894736842102,3.6842105263157894,4.0526315789473681,4.4210526315789469,4.7894736842105257,5.1578947368421053,5.5263157894736841,5.8947368421052628,6.2631578947368416,6.6315789473684204,7],"y":[-4,-3.3684210526315788,-2.736842105263158,-2.1052631578947372,-1.4736842105263159,-0.84210526315789469,-0.21052631578947389,0.4210526315789469,1.0526315789473681,1.6842105263157894,2.3157894736842106,2.947368421052631,3.5789473684210522,4.2105263157894726,4.8421052631578938,5.473684210526315,6.1052631578947363,6.7368421052631575,7.3684210526315788,8],"opacity":0.29999999999999999,"colorscale":[[0,1],["steelblue","steelblue"]],"showscale":false,"name":"Model Space","inherit":true},"16cb03c64265":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":{},"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"red","symbol":"diamond","opacity":0.80000000000000004},"name":"Proj on Floor","inherit":true},"16cb04d30f6d2":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":{},"z":{},"marker":{"size":4,"color":"black","symbol":"circle","opacity":0.59999999999999998},"name":"Data Cloud","inherit":true},"16cb0499c7c95":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":{},"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"blue","symbol":"circle-open","opacity":0.59999999999999998},"name":"Proj L(jn)","inherit":true},"16cb040b73ff4":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":{},"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"size":4,"color":"green","symbol":"circle-open","opacity":0.59999999999999998},"name":"Proj L(Xc)","inherit":true},"16cb03ec7cd5d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":{},"marker":{"size":4,"color":"gold","symbol":"circle-open","opacity":0.80000000000000004},"name":"Error","inherit":true},"16cb03ec7cd5d.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[0,3],"y":[0,0],"z":[0,0],"line":{"color":"black","width":6},"name":"Mean Vector","inherit":true},"16cb03ec7cd5d.2":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[3,3],"y":[0,0],"z":[0,0],"line":{"color":"blue","width":4,"dash":"dash"},"name":"Link to X","inherit":true},"16cb03ec7cd5d.3":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"lines","x":[3,0],"y":[0,0],"z":[0,0],"line":{"color":"green","width":4,"dash":"dash"},"name":"Link to Y","inherit":true}},"layout":{"margin":{"b":0,"l":0,"t":30,"r":0},"title":"Scenario B: No Effect","scene":{"xaxis":{"title":"L(j<sub>n<\/sub>)","range":[0,8]},"yaxis":{"title":"L(X<sub>c<\/sub>)","range":[-4,8]},"zaxis":{"title":"Col(X)<sup>&perp;<\/sup>","range":[-4,4]},"aspectmode":"cube","camera":{"eye":{"x":1.6000000000000001,"y":1.6000000000000001,"z":0.59999999999999998}}},"showlegend":false,"hovermode":"closest"},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"colorbar":{"title":"z<br />z","ticklen":2},"colorscale":[[0,"steelblue"],[1,"steelblue"]],"showscale":false,"z":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],"type":"surface","x":[0,0.36842105263157893,0.73684210526315785,1.1052631578947367,1.4736842105263157,1.8421052631578947,2.2105263157894735,2.5789473684210527,2.9473684210526314,3.3157894736842102,3.6842105263157894,4.0526315789473681,4.4210526315789469,4.7894736842105257,5.1578947368421053,5.5263157894736841,5.8947368421052628,6.2631578947368416,6.6315789473684204,7],"y":[-4,-3.3684210526315788,-2.736842105263158,-2.1052631578947372,-1.4736842105263159,-0.84210526315789469,-0.21052631578947389,0.4210526315789469,1.0526315789473681,1.6842105263157894,2.3157894736842106,2.947368421052631,3.5789473684210522,4.2105263157894726,4.8421052631578938,5.473684210526315,6.1052631578947363,6.7368421052631575,7.3684210526315788,8],"opacity":0.29999999999999999,"name":"Model Space","frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[0.12665925699737743,-0.014273377674351514,-0.021435228645658035,0.68430114200722891,-0.11288549282963381,0.75823530221476987,-0.77437640211511061,0.29230687481803452,0.061927121922306892,0.10797078437198633,0.18981974137994104,-0.25116172655465113,-0.16660369183471005,-0.50928769155354425,-0.53589561323778867,0.151764320702129,0.22410488931471309,0.026502113365252069,0.46113373393986878,1.0250423428135722,-0.24551558302826762,-1.1545844378204064,0.50286926223112838,-0.3546003812911962,-0.34400430823367895,0.51278568484834941,-0.14238650352550439,-0.6103588561272677,0.090651739874575116,-0.069445681219522312,0.0028820929499434669,0.19264020056316528,-0.18533001589620471,0.3221882742594166,-0.11024328090937531,0.16589098195784846,0.54841950657467398,0.21759074541690146,-0.1629657927656134,0.57440380922554701,0.49675192798105972,0.27419847975403489,0.11936586755572062,-0.31395303801968572,0.68032622426500367,-0.30012979357356334,1.0936664965082887,0.76630531309259464,-0.11785017955023847,-0.51321045015339029],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"red","size":4,"symbol":"diamond","opacity":0.80000000000000004,"line":{"color":"rgba(255,127,14,1)"}},"name":"Proj on Floor","error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[0.12665925699737743,-0.014273377674351514,-0.021435228645658035,0.68430114200722891,-0.11288549282963381,0.75823530221476987,-0.77437640211511061,0.29230687481803452,0.061927121922306892,0.10797078437198633,0.18981974137994104,-0.25116172655465113,-0.16660369183471005,-0.50928769155354425,-0.53589561323778867,0.151764320702129,0.22410488931471309,0.026502113365252069,0.46113373393986878,1.0250423428135722,-0.24551558302826762,-1.1545844378204064,0.50286926223112838,-0.3546003812911962,-0.34400430823367895,0.51278568484834941,-0.14238650352550439,-0.6103588561272677,0.090651739874575116,-0.069445681219522312,0.0028820929499434669,0.19264020056316528,-0.18533001589620471,0.3221882742594166,-0.11024328090937531,0.16589098195784846,0.54841950657467398,0.21759074541690146,-0.1629657927656134,0.57440380922554701,0.49675192798105972,0.27419847975403489,0.11936586755572062,-0.31395303801968572,0.68032622426500367,-0.30012979357356334,1.0936664965082887,0.76630531309259464,-0.11785017955023847,-0.51321045015339029],"z":[-0.2802378232761063,-0.11508874474163999,0.77935415707456202,0.035254195712287995,0.064643867580473122,0.85753249344164062,0.2304581029946012,-0.63253061730326687,-0.34342642594676298,-0.22283098504997906,0.61204089871973089,0.17990691352868191,0.20038572529702606,0.055341357972559839,-0.27792056737703746,0.89345656840153909,0.24892523911461972,-0.9833085783148191,0.35067795078184272,-0.23639570386396702,-0.53391185299342259,-0.10898745732914752,-0.51300222415361985,-0.36444561464557002,-0.31251963392462845,-0.84334665537120668,0.41889352224726234,0.076686558918257611,-0.56906846850597381,0.62690746053496338,0.21323211073840678,-0.1475357414961356,0.44756283052251122,0.43906674376652111,0.41079054081874361,0.3443201270500455,0.27695882676879441,-0.03095585528836084,-0.15298133186995838,-0.19023550050619131,-0.34735348946025635,-0.10395863900979939,-0.63269817578413223,1.0844779826692563,0.60398099915249526,-0.5615542916016748,-0.20144241764953799,-0.23332767681160937,0.38998255916815894,-0.041684533235914624],"marker":{"color":"black","size":4,"symbol":"circle","opacity":0.59999999999999998,"line":{"color":"rgba(44,160,44,1)"}},"name":"Data Cloud","error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[2.6447967181503493,3.1284418545782646,2.8766540607688134,2.8262287003011335,2.5241907163674924,2.9774861375955397,2.607547765271462,2.1660290317059316,2.8098867398561187,3.4594983045303831,2.7123265186958041,3.3039821611125166,2.191058645855418,2.9722190172377303,3.2597036019717311,3.1505766810833573,3.0528380970744715,2.6796469958473117,2.5751478269832089,2.4879356046975434,3.0588232985500627,2.5262626929075989,2.7547212781496659,2.8719539039008763,3.9219310026161036,2.674025049152271,3.1176932861424285,3.0389804247818555,2.5190716829349356,2.9643459569382005,3.7222754292116744,3.2257520265396074,3.0206164609964699,2.7887515838301877,1.9733763892297422,3.5656686067070877,2.2696799645375889,3.3699737554386675,3.9545517846087419,2.2780534195141002,3.3508921676873555,2.8689012552987658,2.2139279204272562,2.2426661731091242,2.1992319132127034,2.7345467389148483,2.2691222075020501,3.3439583864879139,4.050054470262836,2.3564847619824105],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"blue","size":4,"symbol":"circle-open","opacity":0.59999999999999998,"line":{"color":"rgba(214,39,40,1)"}},"name":"Proj L(jn)","error_y":{"color":"rgba(214,39,40,1)"},"error_x":{"color":"rgba(214,39,40,1)"},"line":{"color":"rgba(214,39,40,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[0.12665925699737743,-0.014273377674351514,-0.021435228645658035,0.68430114200722891,-0.11288549282963381,0.75823530221476987,-0.77437640211511061,0.29230687481803452,0.061927121922306892,0.10797078437198633,0.18981974137994104,-0.25116172655465113,-0.16660369183471005,-0.50928769155354425,-0.53589561323778867,0.151764320702129,0.22410488931471309,0.026502113365252069,0.46113373393986878,1.0250423428135722,-0.24551558302826762,-1.1545844378204064,0.50286926223112838,-0.3546003812911962,-0.34400430823367895,0.51278568484834941,-0.14238650352550439,-0.6103588561272677,0.090651739874575116,-0.069445681219522312,0.0028820929499434669,0.19264020056316528,-0.18533001589620471,0.3221882742594166,-0.11024328090937531,0.16589098195784846,0.54841950657467398,0.21759074541690146,-0.1629657927656134,0.57440380922554701,0.49675192798105972,0.27419847975403489,0.11936586755572062,-0.31395303801968572,0.68032622426500367,-0.30012979357356334,1.0936664965082887,0.76630531309259464,-0.11785017955023847,-0.51321045015339029],"z":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"marker":{"color":"green","size":4,"symbol":"circle-open","opacity":0.59999999999999998,"line":{"color":"rgba(148,103,189,1)"}},"name":"Proj L(Xc)","error_y":{"color":"rgba(148,103,189,1)"},"error_x":{"color":"rgba(148,103,189,1)"},"line":{"color":"rgba(148,103,189,1)"},"frame":null},{"type":"scatter3d","mode":"markers","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"z":[-0.2802378232761063,-0.11508874474163999,0.77935415707456202,0.035254195712287995,0.064643867580473122,0.85753249344164062,0.2304581029946012,-0.63253061730326687,-0.34342642594676298,-0.22283098504997906,0.61204089871973089,0.17990691352868191,0.20038572529702606,0.055341357972559839,-0.27792056737703746,0.89345656840153909,0.24892523911461972,-0.9833085783148191,0.35067795078184272,-0.23639570386396702,-0.53391185299342259,-0.10898745732914752,-0.51300222415361985,-0.36444561464557002,-0.31251963392462845,-0.84334665537120668,0.41889352224726234,0.076686558918257611,-0.56906846850597381,0.62690746053496338,0.21323211073840678,-0.1475357414961356,0.44756283052251122,0.43906674376652111,0.41079054081874361,0.3443201270500455,0.27695882676879441,-0.03095585528836084,-0.15298133186995838,-0.19023550050619131,-0.34735348946025635,-0.10395863900979939,-0.63269817578413223,1.0844779826692563,0.60398099915249526,-0.5615542916016748,-0.20144241764953799,-0.23332767681160937,0.38998255916815894,-0.041684533235914624],"marker":{"color":"gold","size":4,"symbol":"circle-open","opacity":0.80000000000000004,"line":{"color":"rgba(140,86,75,1)"}},"name":"Error","error_y":{"color":"rgba(140,86,75,1)"},"error_x":{"color":"rgba(140,86,75,1)"},"line":{"color":"rgba(140,86,75,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[0,3],"y":[0,0],"z":[0,0],"line":{"color":"black","width":6},"name":"Mean Vector","marker":{"color":"rgba(227,119,194,1)","line":{"color":"rgba(227,119,194,1)"}},"error_y":{"color":"rgba(227,119,194,1)"},"error_x":{"color":"rgba(227,119,194,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[3,3],"y":[0,0],"z":[0,0],"line":{"color":"blue","width":4,"dash":"dash"},"name":"Link to X","marker":{"color":"rgba(127,127,127,1)","line":{"color":"rgba(127,127,127,1)"}},"error_y":{"color":"rgba(127,127,127,1)"},"error_x":{"color":"rgba(127,127,127,1)"},"frame":null},{"type":"scatter3d","mode":"lines","x":[3,0],"y":[0,0],"z":[0,0],"line":{"color":"green","width":4,"dash":"dash"},"name":"Link to Y","marker":{"color":"rgba(188,189,34,1)","line":{"color":"rgba(188,189,34,1)"}},"error_y":{"color":"rgba(188,189,34,1)"},"error_x":{"color":"rgba(188,189,34,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Scenario 2: No regression effect (<span class="math inline">\(\beta_1 = 0\)</span>). The mean vector lies purely on the intercept axis.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="a-diagram-to-show-decomposition-of-sum-of-squares" class="level3" data-number="6.7.2">
<h3 data-number="6.7.2" class="anchored" data-anchor-id="a-diagram-to-show-decomposition-of-sum-of-squares"><span class="header-section-number">6.7.2</span> A Diagram to Show Decomposition of Sum of Squares</h3>
<p>The decomposition of the total variation is visualized below. The total deviation (Orange) is the vector sum of the regression deviation (Green) and the residual error (Red).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ss-decomposition-legend-v2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ss-decomposition-legend-v2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="lec5-est_files/figure-html/fig-ss-decomposition-legend-v2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ss-decomposition-legend-v2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.1: Geometric Decomposition: SST = SSR + SSE
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="distribution-of-sum-of-squares" class="level3" data-number="6.7.3">
<h3 data-number="6.7.3" class="anchored" data-anchor-id="distribution-of-sum-of-squares"><span class="header-section-number">6.7.3</span> Distribution of Sum of Squares</h3>
<p>We apply the general theory of projections to the specific components defined in <a href="#def-ss-components" class="quarto-xref">Definition&nbsp;<span>6.3</span></a>.</p>
<div id="thm-distribution-ss-v2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.9 (Distribution of Sum of Squares)</strong></span> Let <span class="math inline">\(y \sim N(\mu, \sigma^2 I_n)\)</span>, where <span class="math inline">\(\mu \in \text{Col}(X)\)</span>. Consider the decomposition defined by the projection matrices <span class="math inline">\(P_{X_c}\)</span> and <span class="math inline">\(M = I - H\)</span>.</p>
<ul>
<li><p><strong>Independence:</strong> The quadratic forms <span class="math inline">\(\text{SSR}\)</span> and <span class="math inline">\(\text{SSE}\)</span> are statistically independent because the subspaces <span class="math inline">\(L(X_c)\)</span> and <span class="math inline">\(\text{Col}(X)^\perp\)</span> are orthogonal.</p></li>
<li><p><strong>Distribution of SSE:</strong> The scaled sum of squared errors follows a central Chi-squared distribution: <span class="math display">\[ \frac{\text{SSE}}{\sigma^2} = \frac{\|(I - H)y\|^2}{\sigma^2} \sim \chi^2(n-k-1) \]</span> <strong>Mean:</strong> <span class="math display">\[ E[\text{SSE}] = \sigma^2(n-k-1) \]</span></p></li>
<li><p><strong>Distribution of SSR:</strong> The scaled regression sum of squares follows a <strong>non-central</strong> Chi-squared distribution: <span class="math display">\[ \frac{\text{SSR}}{\sigma^2} = \frac{\|P_{X_c}y\|^2}{\sigma^2} \sim \chi^2(k, \lambda) \]</span> <strong>Mean:</strong> <span class="math display">\[ E[\text{SSR}] = \sigma^2 k + \|P_{X_c}\mu\|^2 \]</span></p></li>
</ul>
<p><strong>Non-centrality Parameter (<span class="math inline">\(\lambda\)</span>):</strong> <span class="math display">\[ \lambda = \frac{1}{\sigma^2} \|P_{X_c} \mu\|^2 \]</span> where <span class="math display">\[\|P_{X_c} \mu\|^2 = \|X_c \beta_1\|^2 = (X_c \beta_1)' (X_c \beta_1) = \beta_1' X_c' X_c \beta_1\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We apply <a href="lec4-qf.html#thm-proj-dist" class="quarto-xref">Theorem&nbsp;<span>5.8</span></a> to the specific projection matrices identified in the definitions.</p>
<ul>
<li><p><strong>For SSE (Error Space):</strong> <span class="math inline">\(\text{SSE}\)</span> is defined by the projection matrix <span class="math inline">\(P_V = I - H\)</span>.</p>
<ul>
<li><strong>Dimension:</strong> The rank of <span class="math inline">\((I - H)\)</span> is <span class="math inline">\(n - \text{rank}(X) = n - (k+1) = n - k - 1\)</span>.</li>
<li><strong>Non-centrality:</strong> Since <span class="math inline">\(\mu \in \text{Col}(X)\)</span>, the projection onto the orthogonal complement is zero: <span class="math inline">\(\|(I - H)\mu\|^2 = 0\)</span>. Thus, <span class="math inline">\(\lambda = 0\)</span>.</li>
<li><strong>Expectation:</strong> Using Part 2 of <a href="lec4-qf.html#thm-proj-dist" class="quarto-xref">Theorem&nbsp;<span>5.8</span></a> (<span class="math inline">\(E(\|P_V y\|^2) = \sigma^2 \text{rank}(P_V) + \|P_V \mu\|^2\)</span>): <span class="math display">\[ E[\text{SSE}] = \sigma^2(n-k-1) + 0 = \sigma^2(n-k-1) \]</span></li>
</ul></li>
<li><p><strong>For SSR (Regression Space):</strong> <span class="math inline">\(\text{SSR}\)</span> is defined by the projection matrix <span class="math inline">\(P_V = P_{X_c}\)</span>.</p>
<ul>
<li><p><strong>Dimension:</strong> The rank of <span class="math inline">\(P_{X_c}\)</span> is <span class="math inline">\((k+1) - 1 = k\)</span>.</p></li>
<li><p><strong>Non-centrality:</strong> The projection of <span class="math inline">\(\mu\)</span> onto <span class="math inline">\(L(X_c)\)</span> is <span class="math inline">\(P_{X_c}\mu\)</span>. <span class="math display">\[ \lambda = \frac{1}{2\sigma^2} \|P_{X_c} \mu\|^2 \]</span></p></li>
<li><p><strong>Expectation:</strong> Using Part 2 of <a href="lec4-qf.html#thm-proj-dist" class="quarto-xref">Theorem&nbsp;<span>5.8</span></a>: <span class="math display">\[ E[\text{SSR}] = \sigma^2 k + \|P_{X_c}\mu\|^2 \]</span></p></li>
</ul>
<p>This shows that while <span class="math inline">\(E[\text{SSE}]\)</span> depends only on the noise variance and sample size, <span class="math inline">\(E[\text{SSR}]\)</span> is inflated by the magnitude of the true regression signal <span class="math inline">\(\|P_{X_c}\mu\|^2\)</span>.</p></li>
</ul>
</div>
</section>
</section>
<section id="f-test-for-testing-overall-regression-effect" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="f-test-for-testing-overall-regression-effect"><span class="header-section-number">6.8</span> F-test for Testing Overall Regression Effect</h2>
<p>We wish to test whether the regression model provides any explanatory power beyond the simple intercept-only model.</p>
<p><strong>Hypotheses:</strong></p>
<ul>
<li><p><strong>Null Hypothesis (<span class="math inline">\(H_0\)</span>):</strong> <span class="math inline">\(\beta_1 = \beta_2 = \dots = \beta_k = 0\)</span> (No regression effect). This implies <span class="math inline">\(\mu \in \text{span}(j_n)\)</span> and the true signal variance <span class="math inline">\(\|X_c\beta_1\|^2 = 0\)</span>.</p></li>
<li><p><strong>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>):</strong> At least one <span class="math inline">\(\beta_j \neq 0\)</span>.</p></li>
</ul>
<section id="the-f-statistic" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="the-f-statistic">The F-statistic</h3>
<p>We construct the test statistic using the ratio of the Mean Squares defined previously:</p>
<p><span class="math display">\[F = \frac{\text{MSR}}{\text{MSE}} = \frac{\text{SSR}/k}{\text{SSE}/(n-k-1)}\]</span></p>
</section>
<section id="understanding-f-via-expectations" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="understanding-f-via-expectations">Understanding <span class="math inline">\(F\)</span> via Expectations</h3>
<p>The logic of the F-test is transparent when we examine the expected values of the numerator and denominator:</p>
<p><span class="math display">\[
\begin{aligned}
E[\text{MSE}] &amp;= \sigma^2 \\
E[\text{MSR}] &amp;= \sigma^2 + \frac{\|X_c \beta_1\|^2}{k}
\end{aligned}
\]</span></p>
<ul>
<li><strong>If <span class="math inline">\(H_0\)</span> is true:</strong> The signal term is zero. Both Mean Squares estimate <span class="math inline">\(\sigma^2\)</span> unbiasedly. We expect <span class="math inline">\(F \approx 1\)</span>.</li>
<li><strong>If <span class="math inline">\(H_1\)</span> is true:</strong> The numerator includes the positive term <span class="math inline">\(\frac{\|X_c \beta_1\|^2}{k}\)</span>. We expect <span class="math inline">\(F &gt; 1\)</span>.</li>
</ul>
<p>Therefore, we reject <span class="math inline">\(H_0\)</span> for sufficiently large values of <span class="math inline">\(F\)</span>. Specifically, we reject at level <span class="math inline">\(\alpha\)</span> if <span class="math inline">\(F_{obs} &gt; F_{\alpha}(k, n-k-1)\)</span>.</p>
</section>
<section id="distributional-theory" class="level3" data-number="6.8.1">
<h3 data-number="6.8.1" class="anchored" data-anchor-id="distributional-theory"><span class="header-section-number">6.8.1</span> Distributional Theory</h3>
<p>To derive the exact sampling distribution, we rely on the independence of the sums of squares (from <a href="#thm-distribution-ss-v2" class="quarto-xref">Theorem&nbsp;<span>6.9</span></a>) and the definition of the non-central F-distribution given in <strong><a href="lec4-qf.html#def-noncentral-f" class="quarto-xref">Definition&nbsp;<span>5.3</span></a></strong>.</p>
<div id="thm-regression-f-dist" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.10 (Distribution of Regression F-Statistic)</strong></span> Under the assumption of normality, the regression F-statistic follows a <strong>non-central F-distribution</strong>:</p>
<p><span class="math display">\[ F \sim F(k, n-k-1, \lambda) \]</span></p>
<p>The non-centrality parameter <span class="math inline">\(\lambda\)</span> is determined by the ratio of the signal sum of squares to the error variance: <span class="math display">\[ \lambda = \frac{\|X_c \beta_1\|^2}{\sigma^2} \]</span></p>
<p><strong>Special Cases:</strong></p>
<ol type="1">
<li><strong>Under <span class="math inline">\(H_1\)</span> (Signal exists):</strong> <span class="math inline">\(\lambda &gt; 0\)</span>, so <span class="math inline">\(F\)</span> follows the non-central distribution.</li>
<li><strong>Under <span class="math inline">\(H_0\)</span> (No signal):</strong> <span class="math inline">\(\beta_1 = 0 \implies \lambda = 0\)</span>. The distribution collapses to the <strong>central F-distribution</strong>: <span class="math display">\[ F \sim F(k, n-k-1) \]</span></li>
</ol>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We identify the components from <a href="lec4-qf.html#def-noncentral-f" class="quarto-xref">Definition&nbsp;<span>5.3</span></a>:</p>
<ol type="1">
<li><strong>Numerator (<span class="math inline">\(X_1\)</span>):</strong> Let <span class="math inline">\(X_1 = \text{SSR}/\sigma^2\)</span>. From <a href="#thm-distribution-ss-v2" class="quarto-xref">Theorem&nbsp;<span>6.9</span></a>, <span class="math inline">\(X_1 \sim \chi^2(k, \lambda)\)</span>.</li>
<li><strong>Denominator (<span class="math inline">\(X_2\)</span>):</strong> Let <span class="math inline">\(X_2 = \text{SSE}/\sigma^2\)</span>. From <a href="#thm-distribution-ss-v2" class="quarto-xref">Theorem&nbsp;<span>6.9</span></a>, <span class="math inline">\(X_2 \sim \chi^2(n-k-1)\)</span>.</li>
<li><strong>Independence:</strong> <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent.</li>
</ol>
<p>Substituting these into the F-statistic: <span class="math display">\[
F = \frac{\text{MSR}}{\text{MSE}} = \frac{(\text{SSR}/\sigma^2)/k}{(\text{SSE}/\sigma^2)/(n-k-1)} = \frac{X_1/k}{X_2/(n-k-1)}
\]</span> By definition <a href="lec4-qf.html#def-noncentral-f" class="quarto-xref">Definition&nbsp;<span>5.3</span></a>, this ratio follows <span class="math inline">\(F(k, n-k-1, \lambda)\)</span>.</p>
</div>
</section>
<section id="visualization-of-the-rejection-region" class="level3" data-number="6.8.2">
<h3 data-number="6.8.2" class="anchored" data-anchor-id="visualization-of-the-rejection-region"><span class="header-section-number">6.8.2</span> Visualization of the Rejection Region</h3>
<p>The following plot illustrates the central F-distribution (valid under <span class="math inline">\(H_0\)</span>) for <span class="math inline">\(k=3\)</span> predictors and <span class="math inline">\(n=20\)</span> observations (<span class="math inline">\(df_1 = 3, df_2 = 16\)</span>). An observed statistic of <span class="math inline">\(F=2\)</span> is marked, with the p-value represented by the shaded tail area.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-f-dist-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-f-dist-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="lec5-est_files/figure-html/fig-f-dist-example-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-f-dist-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.2: Probability Density Function of F(3, 16) under H0. The shaded region represents the p-value.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="raw-coefficient-of-determination-r2" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="raw-coefficient-of-determination-r2"><span class="header-section-number">6.9</span> Raw Coefficient of Determination (<span class="math inline">\(R^2\)</span>)</h2>
<section id="definition" class="level3" data-number="6.9.1">
<h3 data-number="6.9.1" class="anchored" data-anchor-id="definition"><span class="header-section-number">6.9.1</span> Definition</h3>
<p>The <span class="math inline">\(R^2\)</span> statistic measures the proportion of total variation explained by the regression model.</p>
<div id="def-r2" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.4 (R-Squared)</strong></span> <span class="math display">\[R^2 = \frac{\text{SSR}}{\text{SST}} = 1 - \frac{\text{SSE}}{\text{SST}}\]</span> Since <span class="math inline">\(0 \le \text{SSE} \le \text{SST}\)</span>, it follows that <span class="math inline">\(0 \le R^2 \le 1\)</span>.</p>
</div>
</section>
<section id="expectation-and-bias" class="level3" data-number="6.9.2">
<h3 data-number="6.9.2" class="anchored" data-anchor-id="expectation-and-bias"><span class="header-section-number">6.9.2</span> Expectation and Bias</h3>
<p>To understand the bias in <span class="math inline">\(R^2\)</span>, it is more illuminating to analyze the expectation of the <strong>unexplained variance</strong> (<span class="math inline">\(1 - R^2\)</span>). This term represents the ratio of error sum of squares to the total sum of squares:</p>
<p><span class="math display">\[ E[1 - R^2] = E\left[ \frac{\text{SSE}}{\text{SST}} \right] \]</span></p>
<p>Using the first-order approximation <span class="math inline">\(E[X/Y] \approx E[X]/E[Y]\)</span>, we examine the numerator and denominator separately:</p>
<p><span class="math display">\[
\begin{aligned}
E[\text{SSE}] &amp;= \sigma^2(n-k-1) \\
E[\text{SST}] &amp;= \sigma^2(n-1) + \sigma^2\lambda = \sigma^2 \left( (n-1) + \frac{\|X_c \beta_1\|^2}{\sigma^2} \right)
\end{aligned}
\]</span></p>
<p>Substituting these back, we approximate the expected unexplained fraction:</p>
<p><span class="math display">\[ E[1 - R^2] \approx \frac{\sigma^2(n-k-1)}{\sigma^2 \left( (n-1) + \frac{\|X_c \beta_1\|^2}{\sigma^2} \right)} = \frac{n-k-1}{(n-1) + \frac{\|X_c \beta_1\|^2}{\sigma^2}} \]</span></p>
<p><strong>Behavior under Null Hypothesis (<span class="math inline">\(H_0\)</span>):</strong> When there is no true signal (<span class="math inline">\(\beta_1 = 0\)</span>), the term <span class="math inline">\(\frac{\|X_c \beta_1\|^2}{\sigma^2}\)</span> vanishes. The expected proportion of unexplained variance becomes:</p>
<p><span class="math display">\[ E[1 - R^2 | H_0] \approx \frac{n-k-1}{n-1} \]</span></p>
<p>This result reveals the source of the bias:</p>
<ol type="1">
<li>Ideally, if predictors are noise, the model should explain nothing, and <span class="math inline">\(E[1-R^2]\)</span> should be <span class="math inline">\(1\)</span>.</li>
<li>Instead, the expected error ratio is <strong>less than 1</strong>, specifically scaled by <span class="math inline">\(\frac{n-k-1}{n-1}\)</span>.</li>
<li>This scaling factor is exactly what the <strong>Adjusted R-squared (<span class="math inline">\(R^2_a\)</span>)</strong> attempts to correct by multiplying the observed ratio by the inverse <span class="math inline">\(\frac{n-1}{n-k-1}\)</span>.</li>
</ol>
</section>
<section id="exact-distribution" class="level3" data-number="6.9.3">
<h3 data-number="6.9.3" class="anchored" data-anchor-id="exact-distribution"><span class="header-section-number">6.9.3</span> Exact Distribution</h3>
<p>The <span class="math inline">\(R^2\)</span> statistic follows the Type I Non-central Beta distribution derived from the ratio of independent Chi-squared variables.</p>
<div id="thm-r2-dist" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.11 (Distribution of R-Squared)</strong></span> <span class="math display">\[ R^2 \sim \text{Beta}_1\left( \frac{k}{2}, \frac{n-k-1}{2}, \lambda \right) \]</span> where <span class="math inline">\(\text{df}_1 = k\)</span> and <span class="math inline">\(\text{df}_2 = n-k-1\)</span>.</p>
</div>
</section>
</section>
<section id="adjusted-r-squared-r2_a" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="adjusted-r-squared-r2_a"><span class="header-section-number">6.10</span> Adjusted R-squared (<span class="math inline">\(R^2_a\)</span>)</h2>
<p>To correct for the inflation of <span class="math inline">\(R^2\)</span> due to model complexity (<span class="math inline">\(k\)</span>), we introduce the Adjusted <span class="math inline">\(R^2\)</span>. This statistic penalizes the sum of squares by their degrees of freedom:</p>
<p><span class="math display">\[ R^2_a = 1 - \frac{\text{SSE}/(n-k-1)}{\text{SST}/(n-1)} = 1 - \frac{\text{MSE}}{\text{MST}} = 1 - (1 - R^2) \frac{n-1}{n-k-1} \]</span></p>
<p><strong>Expectation:</strong></p>
<p>Under <span class="math inline">\(H_0\)</span>, since <span class="math inline">\(E[\text{MSE}] = E[\text{MST}] = \sigma^2\)</span>, the estimator is asymptotically unbiased:</p>
<p><span class="math display">\[ E[R^2_a | H_0] \approx 0 \]</span></p>
<p><strong>Variance and Stability:</strong></p>
<p>While <span class="math inline">\(R^2_a\)</span> corrects the bias, it introduces instability. The variance of <span class="math inline">\(R^2_a\)</span> under <span class="math inline">\(H_0\)</span> can be derived from the variance of the Beta distribution:</p>
<p><span class="math display">\[ \text{Var}(R^2_a | H_0) = \left( \frac{n-1}{n-k-1} \right)^2 \text{Var}(R^2 | H_0) \]</span></p>
<p>Substituting <span class="math inline">\(\text{Var}(R^2 | H_0) = \frac{2k(n-k-1)}{(n-1)^2(n+1)}\)</span>, we obtain:</p>
<p><span class="math display">\[ \text{Var}(R^2_a | H_0) = \frac{2k}{(n-k-1)(n+1)} \]</span></p>
<p><strong>Key Insight:</strong></p>
<p>As the model complexity <span class="math inline">\(k\)</span> increases relative to <span class="math inline">\(n\)</span>:</p>
<ol type="1">
<li>The denominator <span class="math inline">\((n-k-1)\)</span> shrinks.</li>
<li>The variance <span class="math inline">\(\text{Var}(R^2_a)\)</span> explodes.</li>
</ol>
<p>This implies that for high-dimensional models (large <span class="math inline">\(k/n\)</span>), <span class="math inline">\(R^2_a\)</span> becomes an extremely noisy estimator, often yielding large negative values even for null models.</p>
</section>
<section id="population-proportion-of-signals-rho2" class="level2" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="population-proportion-of-signals-rho2"><span class="header-section-number">6.11</span> Population Proportion of Signals (<span class="math inline">\(\rho^2\)</span>)</h2>
<p>The formula for the expected Adjusted <span class="math inline">\(R^2\)</span> reveals a deep connection to the decomposition of variance in population quantities. Recall the Rao-Blackwell theorem (or Law of Total Variance), which decomposes the total variance of a single observation <span class="math inline">\(Y_i\)</span> into the expected conditional variance (noise) and the variance of the conditional expectation (signal). Let <span class="math inline">\(\sigma^2_\mu\)</span> denote the signal variance and <span class="math inline">\(\sigma^2\)</span> denote the noise variance:</p>
<p><span class="math display">\[ \text{Var}(Y_i) = E[\text{Var}(Y_i|x_{(i)})] + \text{Var}(E[Y_i|x_{(i)}]) \]</span> <span class="math display">\[ \sigma^2_Y = \sigma^2 + \sigma^2_\mu \]</span></p>
<p>In our derived expectation for <span class="math inline">\(R^2_a\)</span>: <span class="math display">\[ E[R^2_a] \approx \frac{\frac{\|X_c\beta_1\|^2}{n-1}}{\sigma^2 + \frac{\|X_c\beta_1\|^2}{n-1}} \]</span></p>
<p>The term in the numerator, <span class="math inline">\(\frac{\|X_c\beta_1\|^2}{n-1}\)</span>, is precisely the <strong>sample variance of the true means</strong> <span class="math inline">\(\mu_i\)</span>. Let <span class="math inline">\(\mu = X\beta\)</span>. We can expand the centered signal vector <span class="math inline">\(X_c\beta_1\)</span> to see this explicitly. Since <span class="math inline">\(\mu \in \text{Col}(X)\)</span>, we know <span class="math inline">\(H\mu = \mu\)</span>:</p>
<p><span class="math display">\[
X_c\beta_1 = P_{X_c} \mu = (H - P_{j_n})\mu = H\mu - P_{j_n}\mu = \mu - \bar{\mu}j_n =
\begin{pmatrix}
\mu_1 - \bar{\mu} \\
\mu_2 - \bar{\mu} \\
\vdots \\
\mu_n - \bar{\mu}
\end{pmatrix}
\]</span></p>
<p>This vector represents the deviation of each observation’s true mean from the grand mean. Consequently, the squared norm divided by degrees of freedom is: <span class="math display">\[ \frac{\|X_c\beta_1\|^2}{n-1} = \frac{\sum_{i=1}^n (\mu_i - \bar{\mu})^2}{n-1} = \sigma^2_\mu \]</span></p>
<p>Thus, <span class="math inline">\(R^2_a\)</span> is therefore an unbiased estimator for the <strong>proportion of variance explained by the signal</strong> in the population: <span class="math display">\[ E[R^2_a] \approx \frac{\sigma^2_\mu}{\sigma^2 + \sigma^2_\mu}\]</span></p>
<p>We will denote this ‘parameter’ by <span class="math inline">\(\rho^2\)</span>:</p>
<p><span class="math display">\[ \rho^2 = 1 - \frac{\sigma^2}{\sigma^2_Y} = \frac{\sigma^2_\mu}{\sigma^2_Y} \]</span></p>
<div class="proof remark">
<p><span class="proof-title"><em>Remark</em>. </span>In the fixed covariate framework, the ‘parameter’ <span class="math inline">\(\rho^2\)</span> is a function of the specific design matrix <span class="math inline">\(X\)</span>, the coefficients <span class="math inline">\(\beta\)</span>, and the sample size <span class="math inline">\(n\)</span>. If we assume the <span class="math inline">\(x_i\)</span> are random draws from a population, then as <span class="math inline">\(n \to \infty\)</span>, <span class="math inline">\(\sigma^2_\mu\)</span> converges to <span class="math inline">\(\text{Var}(x^T\beta)\)</span> (where <span class="math inline">\(x\)</span> is a random vector), and <span class="math inline">\(\rho^2\)</span> converges to the true population proportion of variance explained.</p>
</div>
<div class="callout callout-style-default callout-important callout-titled" title="MSR Is Not a Variance Estimator">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
MSR Is Not a Variance Estimator
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Observing that <span class="math inline">\(E[\text{MST}] \approx \sigma^2 + \sigma^2_\mu\)</span> and <span class="math inline">\(E[\text{MSE}] = \sigma^2\)</span>, we can see that the difference <span class="math inline">\(\text{MST} - \text{MSE}\)</span> provides a direct method-of-moments estimator for the variance of the signal itself (<span class="math inline">\(\sigma^2_\mu\)</span>).</p></li>
<li><p>It is important to recognize that the commonly used <strong>Mean Square Regression (MSR)</strong>, defined as <span class="math inline">\(\text{SSR}/k\)</span>, is <strong>not</strong> an estimator of the signal variance. Because <span class="math inline">\(E[\text{MSR}] = \sigma^2 + \frac{\|X_c\beta_1\|^2}{k}\)</span>, it scales with the sample size <span class="math inline">\(n\)</span> (via the squared norm) rather than converging to a population parameter. MSR is designed for hypothesis testing (detecting <em>existence</em> of signal), not for estimating the <em>magnitude</em> of the signal variance.</p></li>
</ul>
</div>
</div>
</section>
<section id="relationship-between-r2-and-f-test" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="relationship-between-r2-and-f-test"><span class="header-section-number">6.12</span> Relationship between <span class="math inline">\(R^2\)</span> and <span class="math inline">\(F\)</span> Test</h2>
<p>The <span class="math inline">\(F\)</span>-statistic for the overall regression effect is a monotonic function of the coefficient of determination. We can express <span class="math inline">\(F\)</span> directly in terms of both the standard <span class="math inline">\(R^2\)</span> and the adjusted <span class="math inline">\(R^2_a\)</span>, as well as relate its expected value to the population variance components.</p>
<ol type="1">
<li><p><strong>Expressing <span class="math inline">\(F\)</span> via Standard <span class="math inline">\(R^2\)</span>:</strong> Since <span class="math inline">\(R^2 = \text{SSR}/\text{SST}\)</span> and <span class="math inline">\(1 - R^2 = \text{SSE}/\text{SST}\)</span>, we can substitute these into the definition of <span class="math inline">\(F\)</span>: <span class="math display">\[
F = \frac{\text{SSR}/k}{\text{SSE}/(n-k-1)} = \frac{(R^2 \cdot \text{SST}) / k}{((1 - R^2) \cdot \text{SST}) / (n - k - 1)} = \frac{R^2}{1 - R^2} \cdot \frac{n - k - 1}{k}
\]</span></p></li>
<li><p><strong>Expressing <span class="math inline">\(F\)</span> via Adjusted <span class="math inline">\(R^2_a\)</span>:</strong> The relationship becomes structurally identical to the population expectation if we use the estimated Signal-to-Noise Ratio. Since <span class="math inline">\(\frac{R^2_a}{1 - R^2_a} = \frac{\hat{\sigma}^2_\mu}{\hat{\sigma}^2}\)</span>, we have: <span class="math display">\[
F = 1 + \frac{n-1}{k} \left( \frac{R^2_a}{1 - R^2_a} \right)
\]</span> This form highlights that <span class="math inline">\(F\)</span> starts at a baseline of 1 (pure noise) and increases proportional to the estimated signal strength.</p></li>
<li><p><strong>Expected Value of <span class="math inline">\(F\)</span> as a function of <span class="math inline">\(\sigma^2_\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>:</strong> Using the population signal variance <span class="math inline">\(\sigma^2_\mu\)</span> and noise variance <span class="math inline">\(\sigma^2\)</span>, the expected value of the <span class="math inline">\(F\)</span>-statistic (using the first-order approximation <span class="math inline">\(E[F] \approx E[\text{MSR}]/E[\text{MSE}]\)</span>) is: <span class="math display">\[
E[F] \approx 1 + \frac{n-1}{k} \left( \frac{\sigma^2_\mu}{\sigma^2} \right)
\]</span> The exact mean, derived from the non-central <span class="math inline">\(F\)</span> distribution, is: <span class="math display">\[
E[F] = \frac{n-k-1}{n-k-3} \left( 1 + \frac{n-1}{k} \frac{\sigma^2_\mu}{\sigma^2} \right), \quad \text{for } n-k-1 &gt; 3
\]</span></p></li>
</ol>
</section>
<section id="confidence-interval-of-population-rho2" class="level2" data-number="6.13">
<h2 data-number="6.13" class="anchored" data-anchor-id="confidence-interval-of-population-rho2"><span class="header-section-number">6.13</span> Confidence Interval of Population <span class="math inline">\(\rho^2\)</span></h2>
<p>While <span class="math inline">\(R^2_a\)</span> provides a point estimate, we can construct an exact confidence interval for <span class="math inline">\(\rho^2\)</span> by exploiting the distribution of the <span class="math inline">\(F\)</span>-statistic.</p>
<p><strong>1. The link between <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\rho^2\)</span>:</strong></p>
<p>Recall that the <span class="math inline">\(F\)</span>-statistic follows a non-central distribution <span class="math inline">\(F(k, n-k-1, \lambda)\)</span>. The non-centrality parameter <span class="math inline">\(\lambda\)</span> is directly related to the population <span class="math inline">\(\rho^2\)</span>. Using the variance decomposition derived above:</p>
<p><span class="math display">\[ \lambda = \frac{\|X_c \beta_1\|^2}{\sigma^2} = (n-1) \left( \frac{\sigma^2_\mu}{\sigma^2} \right) \]</span></p>
<p>Substituting the signal-to-noise ratio <span class="math inline">\(\frac{\sigma^2_\mu}{\sigma^2} = \frac{\rho^2}{1-\rho^2}\)</span>, we obtain a one-to-one mapping between <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\rho^2\)</span>:</p>
<p><span class="math display">\[ \lambda(\rho^2) = (n-1) \left( \frac{\rho^2}{1-\rho^2} \right) \]</span></p>
<p><strong>2. Inverting the Test Statistic:</strong></p>
<p>We find a confidence interval <span class="math inline">\([\lambda_L, \lambda_U]\)</span> for <span class="math inline">\(\lambda\)</span> by “inverting” the observed <span class="math inline">\(F\)</span>-statistic (<span class="math inline">\(F_{obs}\)</span>). We search for two specific non-central F-distributions: one where <span class="math inline">\(F_{obs}\)</span> cuts off the upper <span class="math inline">\(\alpha/2\)</span> tail, and one where it cuts off the lower <span class="math inline">\(\alpha/2\)</span> tail.</p>
<ul>
<li><strong>Lower Bound (<span class="math inline">\(\lambda_L\)</span>):</strong> The non-centrality parameter such that <span class="math inline">\(F_{obs}\)</span> is the <span class="math inline">\(1-\alpha/2\)</span> quantile.</li>
<li><strong>Upper Bound (<span class="math inline">\(\lambda_U\)</span>):</strong> The non-centrality parameter such that <span class="math inline">\(F_{obs}\)</span> is the <span class="math inline">\(\alpha/2\)</span> quantile.</li>
</ul>
<p>This concept is illustrated in the figure below.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ci-inversion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ci-inversion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="lec5-est_files/figure-html/fig-ci-inversion-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ci-inversion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.3: Illustration of constructing a confidence interval for the non-centrality parameter <span class="math inline">\(\lambda\)</span> by inverting the F-test. The observed <span class="math inline">\(F_{obs}\)</span> (dashed line) is the <span class="math inline">\(97.5^{th}\)</span> percentile of the distribution defined by the lower bound <span class="math inline">\(\lambda_L\)</span> (blue), and the <span class="math inline">\(2.5^{th}\)</span> percentile of the distribution defined by the upper bound <span class="math inline">\(\lambda_U\)</span> (red). The shaded areas each represent <span class="math inline">\(\alpha/2\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>3. The Interval for <span class="math inline">\(\rho^2\)</span>:</strong></p>
<p>Once <span class="math inline">\([\lambda_L, \lambda_U]\)</span> are found numerically, we map them back to the population <span class="math inline">\(R^2\)</span> scale using the inverse relationship:</p>
<p><span class="math display">\[ \rho^2 = \frac{\lambda}{\lambda + (n-1)} \]</span></p>
<p>This produces an exact confidence interval <span class="math inline">\([\rho^2_L, \rho^2_U]\)</span> for the proportion of variance explained by the model in the population.</p>
</section>
<section id="an-animation-for-illustrating-r2_a-under-h_0-and-h_1" class="level2" data-number="6.14">
<h2 data-number="6.14" class="anchored" data-anchor-id="an-animation-for-illustrating-r2_a-under-h_0-and-h_1"><span class="header-section-number">6.14</span> An Animation for Illustrating <span class="math inline">\(R^2_a\)</span> Under <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></h2>
<p>We simulate a dataset with <span class="math inline">\(n=30\)</span> observations and consider a sequence of nested models adding groups of predictors.</p>
<p><strong>Predictor Groups:</strong></p>
<ol type="1">
<li><strong>Group 1 (<span class="math inline">\(k=1\)</span>):</strong> Add <span class="math inline">\(x_1\)</span>. (Signal under <span class="math inline">\(H_1\)</span>).</li>
<li><strong>Group 2 (<span class="math inline">\(k=6\)</span>):</strong> Add <span class="math inline">\(x_2, \dots, x_6\)</span> (Noise).</li>
<li><strong>Group 3 (<span class="math inline">\(k=11\)</span>):</strong> Add <span class="math inline">\(x_7, \dots, x_{11}\)</span> (Noise).</li>
<li><strong>Group 4 (<span class="math inline">\(k=20\)</span>):</strong> Add <span class="math inline">\(x_{12}, \dots, x_{20}\)</span> (Noise).</li>
</ol>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Null Hypothesis (<span class="math inline">\(H_0\)</span>)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Alternative Hypothesis (<span class="math inline">\(H_1\)</span>)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Under <span class="math inline">\(H_0\)</span>, the true coefficient for <span class="math inline">\(x_1\)</span> is <span class="math inline">\(\beta_1 = 0\)</span>. All predictors are noise.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<video controls="controls" width="100%">
<source src="figs/rss-h0-v6.mp4" type="video/mp4">
</video>
<p>Simulation under H0: As predictors are added (pure noise), standard R-squared increases while Adjusted R-squared and MSE remain stable.</p>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>Under <span class="math inline">\(H_1\)</span>, <span class="math inline">\(x_1\)</span> is a true predictor (<span class="math inline">\(\beta_1 = 2\)</span>). The subsequent groups (<span class="math inline">\(x_2 \dots x_{20}\)</span>) remain noise.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<video controls="controls" width="100%">
<source src="figs/rss-h1-v6.mp4" type="video/mp4">
</video>
<p>Simulation under H1: Adjusted R-squared correctly identifies the signal at k=1, then penalizes the subsequent noise predictors.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="a-data-example-with-house-price-valuation" class="level2" data-number="6.15">
<h2 data-number="6.15" class="anchored" data-anchor-id="a-data-example-with-house-price-valuation"><span class="header-section-number">6.15</span> A Data Example with House Price Valuation</h2>
<p>A real estate agency wants to refine their pricing model. They regress the selling price of houses (<span class="math inline">\(y\)</span>) on five predictors (<span class="math inline">\(X\)</span>): Size, Age, Bedrooms, Garage Capacity, and Lawn Size.</p>
<p>We assume the data has been collected and saved to <code>house_prices_5pred.csv</code>.</p>
<section id="visualize-the-data" class="level3" data-number="6.15.1">
<h3 data-number="6.15.1" class="anchored" data-anchor-id="visualize-the-data"><span class="header-section-number">6.15.1</span> Visualize the Data</h3>
<p>First, we load the dataset. We display the first 10 rows for PDF output, or a full paged table for HTML.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Data</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"house_prices_5pred.csv"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Conditional Display</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (knitr<span class="sc">::</span><span class="fu">is_html_output</span>()) {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  rmarkdown<span class="sc">::</span><span class="fu">paged_table</span>(df)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">head</span>(df, <span class="dv">10</span>), <span class="at">caption =</span> <span class="st">"First 10 rows of House Prices"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Price"],"name":[1],"type":["int"],"align":["right"]},{"label":["Size"],"name":[2],"type":["int"],"align":["right"]},{"label":["Age"],"name":[3],"type":["int"],"align":["right"]},{"label":["Beds"],"name":[4],"type":["int"],"align":["right"]},{"label":["Garage"],"name":[5],"type":["int"],"align":["right"]},{"label":["Lawn"],"name":[6],"type":["int"],"align":["right"]}],"data":[{"1":"497808","2":"3092","3":"4","4":"3","5":"2","6":"426"},{"1":"364297","2":"1802","3":"26","4":"5","5":"0","6":"88"},{"1":"610217","2":"2701","3":"22","4":"4","5":"1","6":"403"},{"1":"536122","2":"2745","3":"38","4":"4","5":"0","6":"437"},{"1":"347259","2":"2143","3":"18","4":"2","5":"1","6":"141"},{"1":"343784","2":"2754","3":"49","4":"5","5":"1","6":"186"},{"1":"379522","2":"2039","3":"53","4":"4","5":"0","6":"451"},{"1":"341432","2":"1758","3":"43","4":"5","5":"1","6":"832"},{"1":"515913","2":"3191","3":"19","4":"4","5":"0","6":"276"},{"1":"292732","2":"1298","3":"17","4":"2","5":"2","6":"804"},{"1":"646447","2":"3255","3":"39","4":"5","5":"0","6":"536"},{"1":"583891","2":"3383","3":"12","4":"4","5":"0","6":"185"},{"1":"485637","2":"2759","3":"38","4":"4","5":"1","6":"184"},{"1":"496960","2":"2289","3":"27","4":"4","5":"0","6":"533"},{"1":"353135","2":"2124","3":"19","4":"2","5":"0","6":"181"},{"1":"533796","2":"3106","3":"43","4":"5","5":"3","6":"443"},{"1":"326891","2":"1276","3":"17","4":"5","5":"2","6":"320"},{"1":"504254","2":"3158","3":"2","4":"4","5":"3","6":"333"},{"1":"350065","2":"1328","3":"40","4":"3","5":"3","6":"713"},{"1":"457862","2":"1739","3":"13","4":"3","5":"1","6":"53"},{"1":"219294","2":"1118","3":"11","4":"2","5":"0","6":"208"},{"1":"333496","2":"1280","3":"15","4":"4","5":"0","6":"109"},{"1":"454666","2":"2701","3":"30","4":"3","5":"2","6":"575"},{"1":"587078","2":"3125","3":"1","4":"4","5":"2","6":"735"},{"1":"496126","2":"2993","3":"41","4":"2","5":"0","6":"295"},{"1":"386942","2":"1731","3":"29","4":"2","5":"2","6":"603"},{"1":"500227","2":"2538","3":"59","4":"4","5":"1","6":"539"},{"1":"554355","2":"3039","3":"18","4":"3","5":"3","6":"235"},{"1":"335301","2":"1001","3":"7","4":"5","5":"3","6":"957"},{"1":"191900","2":"1053","3":"52","4":"3","5":"0","6":"989"},{"1":"452794","2":"2103","3":"33","4":"4","5":"3","6":"240"},{"1":"335370","2":"1726","3":"55","4":"3","5":"2","6":"127"},{"1":"339842","2":"1441","3":"38","4":"3","5":"3","6":"159"},{"1":"535777","2":"3433","3":"2","4":"2","5":"0","6":"104"},{"1":"471557","2":"2688","3":"45","4":"4","5":"3","6":"716"},{"1":"512092","2":"2702","3":"11","4":"3","5":"0","6":"492"},{"1":"308528","2":"1135","3":"44","4":"3","5":"3","6":"646"},{"1":"566085","2":"3415","3":"30","4":"4","5":"1","6":"163"},{"1":"217797","2":"1055","3":"58","4":"4","5":"3","6":"413"},{"1":"483245","2":"2618","3":"34","4":"2","5":"3","6":"989"},{"1":"527446","2":"3182","3":"17","4":"3","5":"2","6":"724"},{"1":"509378","2":"3276","3":"40","4":"3","5":"3","6":"608"},{"1":"485767","2":"2560","3":"13","4":"2","5":"2","6":"151"},{"1":"409876","2":"1980","3":"32","4":"3","5":"0","6":"586"},{"1":"609642","2":"3129","3":"16","4":"4","5":"0","6":"252"},{"1":"376774","2":"2120","3":"49","4":"2","5":"0","6":"397"},{"1":"441467","2":"2039","3":"9","4":"2","5":"1","6":"961"},{"1":"363941","2":"1698","3":"4","4":"3","5":"0","6":"987"},{"1":"561867","2":"2636","3":"15","4":"2","5":"0","6":"816"},{"1":"403582","2":"2626","3":"48","4":"5","5":"3","6":"86"},{"1":"257529","2":"1153","3":"5","4":"2","5":"1","6":"779"},{"1":"528588","2":"2853","3":"37","4":"3","5":"3","6":"865"},{"1":"330393","2":"2132","3":"49","4":"2","5":"2","6":"961"},{"1":"467629","2":"2224","3":"5","4":"4","5":"3","6":"749"},{"1":"570547","2":"2883","3":"24","4":"5","5":"0","6":"577"},{"1":"386896","2":"2790","3":"54","4":"2","5":"0","6":"414"},{"1":"214403","2":"1050","3":"50","4":"5","5":"1","6":"818"},{"1":"341410","2":"1480","3":"10","4":"5","5":"0","6":"752"},{"1":"435568","2":"2141","3":"29","4":"3","5":"1","6":"861"},{"1":"411208","2":"1696","3":"16","4":"5","5":"3","6":"229"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
</section>
<section id="fit-the-model" class="level3" data-number="6.15.2">
<h3 data-number="6.15.2" class="anchored" data-anchor-id="fit-the-model"><span class="header-section-number">6.15.2</span> Fit the Model</h3>
<p>We will solve for the coefficients <span class="math inline">\(\hat{\beta}\)</span> using three distinct methods.</p>
<section id="method-1-naive-matrix-formula" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="method-1-naive-matrix-formula">Method 1: Naive Matrix Formula</h4>
<p>This method solves the normal equations directly on the raw data: <span class="math inline">\(\hat{\beta} = (X^{\prime}X)^{-1}X^{\prime}y\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define Y and X (add Column of 1s for Intercept)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(df<span class="sc">$</span>Price)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: "lawn" Is Included Here, Even Though It Is Irrelevant</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X_naive <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(<span class="at">Intercept =</span> <span class="dv">1</span>, </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                           df[, <span class="fu">c</span>(<span class="st">"Size"</span>, <span class="st">"Age"</span>, <span class="st">"Beds"</span>, <span class="st">"Garage"</span>, <span class="st">"Lawn"</span>)]))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compute Intermediate Matrices</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>XtX <span class="ot">&lt;-</span> <span class="fu">t</span>(X_naive) <span class="sc">%*%</span> X_naive</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>Xty <span class="ot">&lt;-</span> <span class="fu">t</span>(X_naive) <span class="sc">%*%</span> y</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Intermediate Steps</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Matrix X'X (Cross-products of predictors):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Matrix X'X (Cross-products of predictors):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(XtX, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Intercept      Size     Age   Beds Garage     Lawn
Intercept        60    136483    1674    206     80    29392
Size         136483 343078981 3738402 469757 177877 63939128
Age            1674   3738402   63528   5874   2353   827130
Beds            206    469757    5874    776    281    98738
Garage           80    177877    2353    281    196    41915
Lawn          29392  63939128  827130  98738  41915 19306096</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Matrix X'y (Cross-products with response):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Matrix X'y (Cross-products with response):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(Xty, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                 [,1]
Intercept    25884407
Size      63115001244
Age         694594579
Beds         89683035
Garage       34067413
Lawn      12402228016</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Solve Beta</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>beta_naive <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX) <span class="sc">%*%</span> Xty</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Result</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Solved Coefficients (Beta):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Solved Coefficients (Beta):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">t</span>(beta_naive))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     Intercept     Size       Age     Beds   Garage    Lawn
[1,]    113186 129.3434 -1218.352 12664.16 875.1155 27.2443</code></pre>
</div>
</div>
</section>
<section id="method-2-centralized-formula" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="method-2-centralized-formula">Method 2: Centralized Formula</h4>
<p>This method reduces multicollinearity issues. Formula: <span class="math inline">\(\hat{\beta}_{\text{slope}} = (X_c^{\prime}X_c)^{-1}X_c^{\prime}y_c\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Center the Data</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>y_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>X_raw <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(df[, <span class="fu">c</span>(<span class="st">"Size"</span>, <span class="st">"Age"</span>, <span class="st">"Beds"</span>, <span class="st">"Garage"</span>, <span class="st">"Lawn"</span>)])</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>X_means <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(X_raw)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>y_c <span class="ot">&lt;-</span> y <span class="sc">-</span> y_bar</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>X_c <span class="ot">&lt;-</span> <span class="fu">sweep</span>(X_raw, <span class="dv">2</span>, X_means) </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compute Intermediate Matrices</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>XctXc <span class="ot">&lt;-</span> <span class="fu">t</span>(X_c) <span class="sc">%*%</span> X_c</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>Xctyc <span class="ot">&lt;-</span> <span class="fu">t</span>(X_c) <span class="sc">%*%</span> y_c</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Intermediate Steps</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Matrix X_c'X_c (Centered Sum of Squares):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Matrix X_c'X_c (Centered Sum of Squares):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(XctXc, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>           Size    Age  Beds Garage     Lawn
Size   32618826 -69474  1165  -4100 -2919344
Age      -69474  16823   127    121     7093
Beds       1165    127    69      6    -2175
Garage    -4100    121     6     89     2726
Lawn   -2919344   7093 -2175   2726  4907935</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Matrix X_c'y_c (Centered Cross-products):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Matrix X_c'y_c (Centered Cross-products):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(Xctyc, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>             [,1]
Size   4235309234
Age     -27580376
Beds       813238
Garage    -445130
Lawn   -277680160</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Solve for Slope Coefficients</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>beta_slope <span class="ot">&lt;-</span> <span class="fu">solve</span>(XctXc) <span class="sc">%*%</span> Xctyc</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Recover Intercept</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> y_bar <span class="sc">-</span> <span class="fu">sum</span>(X_means <span class="sc">*</span> beta_slope)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>beta_central <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="at">Intercept =</span> beta_0, beta_slope)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Result</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Solved Coefficients (Beta):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Solved Coefficients (Beta):</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">t</span>(beta_central))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     Intercept     Size       Age     Beds   Garage    Lawn
[1,]    113186 129.3434 -1218.352 12664.16 875.1155 27.2443</code></pre>
</div>
</div>
</section>
<section id="method-3-using-rs-lm-function" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="method-3-using-rs-lm-function">Method 3: Using R’s <code>lm</code> Function</h4>
<p>This is the standard approach for practitioners.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price <span class="sc">~</span> ., <span class="at">data =</span> df)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>y_hat_lm <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model_lm)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract Coefficients</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(model_lm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Price ~ ., data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-135178  -36006    1710   26401  111967 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 113185.971  35675.435   3.173  0.00249 ** 
Size           129.343      8.927  14.490  &lt; 2e-16 ***
Age          -1218.352    386.414  -3.153  0.00264 ** 
Beds         12664.157   6064.435   2.088  0.04150 *  
Garage         875.115   5316.490   0.165  0.86987    
Lawn            27.244     23.243   1.172  0.24629    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 49360 on 54 degrees of freedom
Multiple R-squared:  0.8161,    Adjusted R-squared:  0.799 
F-statistic: 47.92 on 5 and 54 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section>
</section>
<section id="visualization-of-fitted-values-vs-mean" class="level3" data-number="6.15.3">
<h3 data-number="6.15.3" class="anchored" data-anchor-id="visualization-of-fitted-values-vs-mean"><span class="header-section-number">6.15.3</span> Visualization of Fitted Values vs Mean</h3>
<p>We define <span class="math inline">\(\hat{y}_0\)</span> as the vector of the mean of <span class="math inline">\(y\)</span> (<span class="math inline">\(\bar{y}\)</span>). We plot the actual <span class="math inline">\(y\)</span> against our fitted model <span class="math inline">\(\hat{y}\)</span>, using a green line to represent the “Null Model” (<span class="math inline">\(\hat{y}_0\)</span>).</p>
<p><em>Note: Axes have been set so that X = Predicted Value and Y = Actual Value.</em></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define y_hat_0 (The Null Model) - for conceptual clarity</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y_hat_0 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(y), <span class="fu">length</span>(y))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot (Axes reversed: x=fitted, y=actual)</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y_hat_lm, y,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Actual vs Fitted Prices"</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Fitted Price (y_hat)"</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Actual Price (y)"</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add 1:1 line (Perfect fit area, remains y=x)</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">"gray"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add Mean line representing the null model</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Since y-axis is 'actual y', a horizontal line at mean(y) represents y_bar</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span> (y), <span class="at">h =</span> <span class="fu">mean</span>(y), <span class="at">col =</span> <span class="st">"green"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"Data"</span>, <span class="st">"Mean (y_bar)"</span>),</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"green"</span>), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">19</span>, <span class="cn">NA</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lec5-est_files/figure-html/plot-y-vs-yhat-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p><strong>Question:</strong></p>
<p><span class="math display">\[ \bar y = \bar{\hat{y}} ?\]</span></p>
</section>
<section id="computing-sums-of-squares-sse-sst-ssr" class="level3" data-number="6.15.4">
<h3 data-number="6.15.4" class="anchored" data-anchor-id="computing-sums-of-squares-sse-sst-ssr"><span class="header-section-number">6.15.4</span> Computing Sums of Squares (SSE, SST, SSR)</h3>
<p>We compare different methods to calculate the sources of variation.</p>
<section id="naive-sum-of-squared-errors" class="level4" data-number="6.15.4.1">
<h4 data-number="6.15.4.1" class="anchored" data-anchor-id="naive-sum-of-squared-errors"><span class="header-section-number">6.15.4.1</span> 1. Naive Sum of Squared Errors</h4>
<p>This uses the standard summation definitions: <span class="math inline">\(\sum (Difference)^2\)</span>.</p>
<ul>
<li><strong>SST (Total):</strong> Variation of <span class="math inline">\(y\)</span> around <span class="math inline">\(\hat{y}_0\)</span> (Mean).</li>
<li><strong>SSR (Regression):</strong> Variation of <span class="math inline">\(\hat{y}\)</span> around <span class="math inline">\(\hat{y}_0\)</span> (Mean).</li>
<li><strong>SSE (Error):</strong> Variation of <span class="math inline">\(y\)</span> around <span class="math inline">\(\hat{y}\)</span> (Model).</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectors</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>y_vec <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(y)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(y_hat_lm)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>y_bar_vec <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(y), <span class="fu">length</span>(y))</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculations</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>SST_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_vec <span class="sc">-</span> y_bar_vec)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>SSR_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_hat <span class="sc">-</span> y_bar_vec)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>SSE_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_vec <span class="sc">-</span> y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Naive Calculation:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Naive Calculation:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"SST:"</span>, SST_naive, <span class="st">" SSR:"</span>, SSR_naive, <span class="st">" SSE:"</span>, SSE_naive, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SST: 715333529746  SSR: 583756306788  SSE: 131577222958 </code></pre>
</div>
</div>
</section>
<section id="pythagorean-shortcut-vector-lengths" class="level4" data-number="6.15.4.2">
<h4 data-number="6.15.4.2" class="anchored" data-anchor-id="pythagorean-shortcut-vector-lengths"><span class="header-section-number">6.15.4.2</span> 2. Pythagorean Shortcut (Vector Lengths)</h4>
<p>Based on the geometry of least squares, we can treat the variables as vectors. Because the vectors are orthogonal, we can use squared lengths (dot products with themselves).</p>
<p>Formula: <span class="math inline">\(SSR = ||\hat{y}||^2 - ||\hat{y}_0||^2\)</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function for squared Euclidean norm (length squared)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>len_sq <span class="ot">&lt;-</span> <span class="cf">function</span>(v) <span class="fu">sum</span>(v<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SST = ||y||^2 - ||y_0||^2</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>SST_pyth <span class="ot">&lt;-</span> <span class="fu">len_sq</span>(y_vec) <span class="sc">-</span> <span class="fu">len_sq</span>(y_bar_vec)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># SSR = ||y_hat||^2 - ||y_0||^2</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>SSR_pyth <span class="ot">&lt;-</span> <span class="fu">len_sq</span>(y_hat) <span class="sc">-</span> <span class="fu">len_sq</span>(y_bar_vec)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE = ||y||^2 - ||y_hat||^2</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>SSE_pyth <span class="ot">&lt;-</span> <span class="fu">len_sq</span>(y_vec) <span class="sc">-</span> <span class="fu">len_sq</span>(y_hat)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Pythagorean Calculation:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Pythagorean Calculation:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"SST:"</span>, SST_pyth, <span class="st">" SSR:"</span>, SSR_pyth, <span class="st">" SSE:"</span>, SSE_pyth, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SST: 715333529746  SSR: 583756306788  SSE: 131577222958 </code></pre>
</div>
</div>
</section>
<section id="matrix-algebra-shortcuts" class="level4" data-number="6.15.4.3">
<h4 data-number="6.15.4.3" class="anchored" data-anchor-id="matrix-algebra-shortcuts"><span class="header-section-number">6.15.4.3</span> Matrix Algebra Shortcuts</h4>
<p>These formulas use the <span class="math inline">\(\beta\)</span> and <span class="math inline">\(X\)</span> matrices directly. This is computationally efficient for large datasets.</p>
<ul>
<li>Formula A (Centered with <span class="math inline">\(y_c\)</span>): <span class="math inline">\(SSR = \hat{\beta}_c^{\prime} X_c^{\prime} y_c\)</span></li>
<li>Formula B (Alternative with <span class="math inline">\(y\)</span>): <span class="math inline">\(SSR = \hat{\beta}_c^{\prime} X_c^{\prime} y\)</span></li>
<li>Formula C (Uncentered): <span class="math inline">\(SSR = \hat{\beta}^{\prime} X^{\prime} y - n\bar{y}^2\)</span></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>term_correction <span class="ot">&lt;-</span> n <span class="sc">*</span> <span class="fu">mean</span>(y)<span class="sc">^</span><span class="dv">2</span> </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># --- SSR Calculations ---</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. SSR Formula A (Centered, using y_c)</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>SSR_centered_yc <span class="ot">&lt;-</span> <span class="fu">t</span>(beta_slope) <span class="sc">%*%</span> <span class="fu">t</span>(X_c) <span class="sc">%*%</span> y_c</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. SSR Formula A (Alternative, using raw y)</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Since X_c is centered, X_c' * 1 = 0, so X_c'y_c is equivalent to X_c'y</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>SSR_centered_y <span class="ot">&lt;-</span> <span class="fu">t</span>(beta_slope) <span class="sc">%*%</span> <span class="fu">t</span>(X_c) <span class="sc">%*%</span> y</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. SSR Formula B (Uncentered Matrix)</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_naive includes intercept, X_naive includes column of 1s</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>term_beta_X_y <span class="ot">&lt;-</span> <span class="fu">t</span>(beta_naive) <span class="sc">%*%</span> <span class="fu">t</span>(X_naive) <span class="sc">%*%</span> y</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>SSR_uncentered <span class="ot">&lt;-</span> term_beta_X_y <span class="sc">-</span> term_correction</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Equivalence Check Table ---</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>results_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">Metric =</span> <span class="fu">c</span>(<span class="st">"SSR (Centered $X_c,y_c$)"</span>, </span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>             <span class="st">"SSR (Centered $X_c$)"</span>, </span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>             <span class="st">"SSR (Uncentered)"</span>),</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">Formula =</span> <span class="fu">c</span>(<span class="st">"$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_c' X_c' y_c$"</span>, </span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>              <span class="st">"$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}_c' X_c' y$"</span>, </span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>              <span class="st">"$</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">beta}' X' y - n</span><span class="sc">\\</span><span class="st">bar{y}^2$"</span>),</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">Value =</span> <span class="fu">c</span>(<span class="fu">as.numeric</span>(SSR_centered_yc), </span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>            <span class="fu">as.numeric</span>(SSR_centered_y), </span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>            <span class="fu">as.numeric</span>(SSR_uncentered))</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Render the table</span></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(results_table, </span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>             <span class="at">digits =</span> <span class="dv">4</span>, </span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">"Demonstration of SSR Formula Equivalence"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Demonstration of SSR Formula Equivalence</caption>
<colgroup>
<col style="width: 35%">
<col style="width: 46%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: left;">Formula</th>
<th style="text-align: right;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">SSR (Centered <span class="math inline">\(X_c,y_c\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(\hat{\beta}_c' X_c' y_c\)</span></td>
<td style="text-align: right;">583756306788</td>
</tr>
<tr class="even">
<td style="text-align: left;">SSR (Centered <span class="math inline">\(X_c\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(\hat{\beta}_c' X_c' y\)</span></td>
<td style="text-align: right;">583756306788</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SSR (Uncentered)</td>
<td style="text-align: left;"><span class="math inline">\(\hat{\beta}' X' y - n\bar{y}^2\)</span></td>
<td style="text-align: right;">583756306788</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="analysis-of-variance-anova" class="level3" data-number="6.15.5">
<h3 data-number="6.15.5" class="anchored" data-anchor-id="analysis-of-variance-anova"><span class="header-section-number">6.15.5</span> Analysis of Variance (ANOVA)</h3>
<p>We now evaluate the sources of variation to test the overall model significance.</p>
<section id="computing-sums-of-squares" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="computing-sums-of-squares">1. Computing Sums of Squares</h4>
<p>We calculate the following components:</p>
<ul>
<li>Total Sum of Squares: <span class="math inline">\(\text{SST} = \sum (y_i - \bar{y})^2\)</span></li>
<li>Regression Sum of Squares: <span class="math inline">\(\text{SSR} = \sum (\hat{y}_i - \bar{y})^2\)</span></li>
<li>Sum of Squared Errors: <span class="math inline">\(\text{SSE} = \sum (y_i - \hat{y}_i)^2\)</span></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectors</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>y_vec <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(y)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(y_hat_lm)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>y_bar_vec <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">mean</span>(y), <span class="fu">length</span>(y))</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculations</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>SST_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_vec <span class="sc">-</span> y_bar_vec)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>SSR_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_hat <span class="sc">-</span> y_bar_vec)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>SSE_naive <span class="ot">&lt;-</span> <span class="fu">sum</span>((y_vec <span class="sc">-</span> y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"SST:"</span>, SST_naive, <span class="st">" SSR:"</span>, SSR_naive, <span class="st">" SSE:"</span>, SSE_naive, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SST: 715333529746  SSR: 583756306788  SSE: 131577222958 </code></pre>
</div>
</div>
</section>
<section id="manual-anova-construction" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="manual-anova-construction">2. Manual ANOVA Construction</h4>
<p>We build the table manually using the sums of squares and degrees of freedom. We calculate the Mean Squares and the F-statistic:</p>
<ul>
<li><span class="math inline">\(\text{MSR} = \text{SSR} / k\)</span></li>
<li><span class="math inline">\(\text{MSE} = \text{SSE} / (n - k - 1)\)</span></li>
<li><span class="math inline">\(\text{MST} = \text{SST} / (n - 1)\)</span></li>
<li><span class="math inline">\(F = \text{MSR} / \text{MSE}\)</span></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">5</span>             <span class="co"># Predictors</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>df_e <span class="ot">&lt;-</span> n <span class="sc">-</span> k <span class="sc">-</span> <span class="dv">1</span>  <span class="co"># Error DF</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>df_t <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">1</span>      <span class="co"># Total DF</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean Squares</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>MSR <span class="ot">&lt;-</span> SSR_naive <span class="sc">/</span> k</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> SSE_naive <span class="sc">/</span> df_e</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>MST <span class="ot">&lt;-</span> SST_naive <span class="sc">/</span> df_t <span class="co"># Mean Square Total (Variance of Y)</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># F-statistic</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>F_stat <span class="ot">&lt;-</span> MSR <span class="sc">/</span> MSE</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># P-value</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>p_val <span class="ot">&lt;-</span> <span class="fu">pf</span>(F_stat, k, df_e, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Assemble Table</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>anova_manual <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">Source =</span> <span class="fu">c</span>(<span class="st">"Regression (Model)"</span>, <span class="st">"Error (Residual)"</span>, <span class="st">"Total"</span>),</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">DF =</span> <span class="fu">c</span>(k, df_e, df_t),</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">SS =</span> <span class="fu">c</span>(SSR_naive, SSE_naive, SST_naive),</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">MS =</span> <span class="fu">c</span>(MSR, MSE, MST), <span class="co"># Included MST here</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">F_Statistic =</span> <span class="fu">c</span>(F_stat, <span class="cn">NA</span>, <span class="cn">NA</span>),</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">P_Value =</span> <span class="fu">c</span>(p_val, <span class="cn">NA</span>, <span class="cn">NA</span>)</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(anova_manual, <span class="at">digits =</span> <span class="dv">4</span>, <span class="at">caption =</span> <span class="st">"Manual ANOVA Table"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Manual ANOVA Table</caption>
<colgroup>
<col style="width: 27%">
<col style="width: 4%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 17%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Source</th>
<th style="text-align: right;">DF</th>
<th style="text-align: right;">SS</th>
<th style="text-align: right;">MS</th>
<th style="text-align: right;">F_Statistic</th>
<th style="text-align: right;">P_Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Regression (Model)</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">583756306788</td>
<td style="text-align: right;">116751261358</td>
<td style="text-align: right;">47.9153</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">Error (Residual)</td>
<td style="text-align: right;">54</td>
<td style="text-align: right;">131577222958</td>
<td style="text-align: right;">2436615240</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">715333529746</td>
<td style="text-align: right;">12124297114</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="standard-r-output-anova" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standard-r-output-anova">3. Standard R Output (<code>anova</code>)</h4>
<p>We display the standard <code>summary()</code> which provides the coefficients, t-tests, and the overall F-statistic found at the bottom. We also show <code>anova()</code> which gives the sequential sum of squares.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit an intercept-only (null) model and compare to the fitted model</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>model_null <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> df)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">ANOVA comparing intercept-only model to fitted model:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
ANOVA comparing intercept-only model to fitted model:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">anova</span>(model_null, model_lm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: Price ~ 1
Model 2: Price ~ Size + Age + Beds + Garage + Lawn
  Res.Df        RSS Df  Sum of Sq      F    Pr(&gt;F)    
1     59 7.1533e+11                                   
2     54 1.3158e+11  5 5.8376e+11 47.915 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One can call anova directly to model_lm</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">anova</span>(model_lm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: Price
          Df     Sum Sq    Mean Sq  F value    Pr(&gt;F)    
Size       1 5.4992e+11 5.4992e+11 225.6914 &lt; 2.2e-16 ***
Age        1 2.0657e+10 2.0657e+10   8.4777  0.005216 ** 
Beds       1 9.5872e+09 9.5872e+09   3.9346  0.052396 .  
Garage     1 2.4151e+08 2.4151e+08   0.0991  0.754107    
Lawn       1 3.3476e+09 3.3476e+09   1.3739  0.246291    
Residuals 54 1.3158e+11 2.4366e+09                       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
</section>
<section id="coefficient-of-determination-and-variance-decomposition" class="level3" data-number="6.15.6">
<h3 data-number="6.15.6" class="anchored" data-anchor-id="coefficient-of-determination-and-variance-decomposition"><span class="header-section-number">6.15.6</span> Coefficient of Determination and Variance Decomposition</h3>
<p>We calculate <span class="math inline">\(R^2\)</span> and Adjusted <span class="math inline">\(R^2\)</span>, and then present them in a <strong>Variance Decomposition Table</strong>.</p>
<section id="calculation" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculation">1. Calculation</h4>
<p>We calculate the coefficients of determination:</p>
<ul>
<li>Standard <span class="math inline">\(R^2 = 1 - \frac{\text{SSE}}{\text{SST}}\)</span></li>
<li>Adjusted <span class="math inline">\(R^2_a = 1 - \frac{\text{MSE}}{\text{MST}}\)</span></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard R-squared</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (SSE_naive <span class="sc">/</span> SST_naive)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjusted R-squared</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Formula: 1 - (MSE / MST)</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>R2_adj <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (MSE <span class="sc">/</span> MST)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Standard R^2:  "</span>, <span class="fu">round</span>(R2, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Standard R^2:   0.8161 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Adjusted R^2:  "</span>, <span class="fu">round</span>(R2_adj, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Adjusted R^2:   0.799 </code></pre>
</div>
</div>
</section>
<section id="variance-decomposition-table" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="variance-decomposition-table">2. Variance Decomposition Table</h4>
<p>This table extends standard ANOVA. While ANOVA focuses on <strong>Mean Squares (MS)</strong> for hypothesis testing (is <span class="math inline">\(MSR &gt; MSE\)</span>?), this table focuses on <strong>Variance Components (<span class="math inline">\(\hat{\sigma}^2\)</span>)</strong> for estimation (how much variance is Signal vs.&nbsp;Noise?). We estimate the variance components as follows:</p>
<ul>
<li><p>Signal Variance: <span class="math inline">\(\hat{\sigma}^2_\mu = \text{MST} - \text{MSE}\)</span></p></li>
<li><p>Noise Variance: <span class="math inline">\(\hat{\sigma}^2 = \text{MSE}\)</span></p></li>
<li><p>Total Variance: <span class="math inline">\(\hat{\sigma}^2_Y = \text{MST}\)</span></p></li>
<li><p><strong>Signal Variance (<span class="math inline">\(\hat{\sigma}^2_\mu\)</span>):</strong> Estimated by <span class="math inline">\(MST - MSE\)</span>. (Note: <span class="math inline">\(MSR\)</span> is biased and overestimates signal).</p></li>
<li><p><strong>Noise Variance (<span class="math inline">\(\hat{\sigma}^2\)</span>):</strong> Estimated by <span class="math inline">\(MSE\)</span>.</p></li>
<li><p><strong>Total Variance (<span class="math inline">\(\hat{\sigma}^2_Y\)</span>):</strong> Estimated by <span class="math inline">\(MST\)</span>.</p></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance Component Estimators (Method of Moments)</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>sigma2_noise_est  <span class="ot">&lt;-</span> MSE</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>sigma2_total_est  <span class="ot">&lt;-</span> MST</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>sigma2_signal_est <span class="ot">&lt;-</span> MST <span class="sc">-</span> MSE</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportions</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>prop_signal <span class="ot">&lt;-</span> sigma2_signal_est <span class="sc">/</span> sigma2_total_est <span class="co"># Equals R^2_adj</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>prop_noise  <span class="ot">&lt;-</span> sigma2_noise_est <span class="sc">/</span> sigma2_total_est  <span class="co"># Equals 1 - R^2_adj</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Assemble Table</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>decomp_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">Component =</span> <span class="fu">c</span>(<span class="st">"Signal (Model)"</span>, <span class="st">"Noise (Error)"</span>, <span class="st">"Total (Y)"</span>),</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">DF =</span> <span class="fu">c</span>(k, df_e, df_t),</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">SS =</span> <span class="fu">c</span>(SSR_naive, SSE_naive, SST_naive),</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">MS =</span> <span class="fu">c</span>(<span class="cn">NA</span>, MSE, MST),</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">Estimator_Sigma2 =</span> <span class="fu">c</span>(sigma2_signal_est, sigma2_noise_est, sigma2_total_est),</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">Proportion =</span> <span class="fu">c</span>(prop_signal, prop_noise, <span class="fl">1.0</span>)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Display</span></span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(decomp_table, </span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>             <span class="at">digits =</span> <span class="dv">4</span>, </span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>             <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Component"</span>, <span class="st">"DF"</span>, <span class="st">"SS"</span>, <span class="st">"MS"</span>, <span class="st">"Value ($</span><span class="sc">\\</span><span class="st">hat{</span><span class="sc">\\</span><span class="st">sigma}^2$)"</span>, <span class="st">"Proportion"</span>),</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">"Variance Decomposition Table: Estimating Signal vs. Noise"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Variance Decomposition Table: Estimating Signal vs.&nbsp;Noise</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 3%">
<col style="width: 16%">
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Component</th>
<th style="text-align: right;">DF</th>
<th style="text-align: right;">SS</th>
<th style="text-align: right;">MS</th>
<th style="text-align: right;">Value (<span class="math inline">\(\hat{\sigma}^2\)</span>)</th>
<th style="text-align: right;">Proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Signal (Model)</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">583756306788</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">9687681874</td>
<td style="text-align: right;">0.799</td>
</tr>
<tr class="even">
<td style="text-align: left;">Noise (Error)</td>
<td style="text-align: right;">54</td>
<td style="text-align: right;">131577222958</td>
<td style="text-align: right;">2436615240</td>
<td style="text-align: right;">2436615240</td>
<td style="text-align: right;">0.201</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total (Y)</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">715333529746</td>
<td style="text-align: right;">12124297114</td>
<td style="text-align: right;">12124297114</td>
<td style="text-align: right;">1.000</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="confidence-interval-for-population-r2-rho2" class="level3" data-number="6.15.7">
<h3 data-number="6.15.7" class="anchored" data-anchor-id="confidence-interval-for-population-r2-rho2"><span class="header-section-number">6.15.7</span> Confidence Interval for Population <span class="math inline">\(R^2\)</span> (<span class="math inline">\(\rho^2\)</span>)</h3>
<p>We construct a 95% confidence interval for the population proportion of variance explained (<span class="math inline">\(\rho^2\)</span>).</p>
<section id="manual-inversion-method" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="manual-inversion-method">1. Manual Inversion Method</h4>
<p>We solve for the non-centrality parameters <span class="math inline">\(\lambda_L\)</span> and <span class="math inline">\(\lambda_U\)</span> such that our observed <span class="math inline">\(F_{obs}\)</span> corresponds to the appropriate quantiles.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define Helper Function to Find Lambda</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We want to find lambda such that: pf(F_stat, df1, df2, ncp = lambda) = target_prob</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>get_lambda <span class="ot">&lt;-</span> <span class="cf">function</span>(target_prob, F_val, df1, df2) {</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  f_root <span class="ot">&lt;-</span> <span class="cf">function</span>(lam) {</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pf</span>(F_val, df1, df2, <span class="at">ncp =</span> lam) <span class="sc">-</span> target_prob</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tryCatch</span>({</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(f_root, <span class="at">interval =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1000</span>))<span class="sc">$</span>root</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(res)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">error =</span> <span class="cf">function</span>(e) <span class="fu">return</span>(<span class="cn">NA</span>))</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate Lambda Bounds (95% CI -&gt; alpha = 0.05)</span></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Lower Bound Lambda: F_obs is the (1 - alpha/2) quantile</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>lambda_Lower <span class="ot">&lt;-</span> <span class="fu">get_lambda</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>, F_stat, k, df_e)</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Upper Bound Lambda: F_obs is the (alpha/2) quantile</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>lambda_Upper <span class="ot">&lt;-</span> <span class="fu">get_lambda</span>(alpha<span class="sc">/</span><span class="dv">2</span>, F_stat, k, df_e)</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">is.na</span>(lambda_Lower)) lambda_Lower <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Convert Lambda to Rho^2</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Formula for Fixed Predictors: rho^2 = lambda / (lambda + n)</span></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>rho2_Lower <span class="ot">&lt;-</span> lambda_Lower <span class="sc">/</span> (lambda_Lower <span class="sc">+</span> n)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>rho2_Upper <span class="ot">&lt;-</span> lambda_Upper <span class="sc">/</span> (lambda_Upper <span class="sc">+</span> n)</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Manual Calculation:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Manual Calculation:</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"95% CI for Population Rho^2: ["</span>, <span class="fu">round</span>(rho2_Lower, <span class="dv">4</span>), <span class="st">", "</span>, <span class="fu">round</span>(rho2_Upper, <span class="dv">4</span>), <span class="st">"]</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>95% CI for Population Rho^2: [ 0.6982 ,  0.8556 ]</code></pre>
</div>
</div>
</section>
<section id="using-r-package-mbess" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="using-r-package-mbess">2. Using R Package <code>MBESS</code></h4>
<p>The <code>MBESS</code> package automates this procedure. We use <code>Random.Predictors = FALSE</code> to match the fixed-predictor assumption used in our manual calculation.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"MBESS"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use N (sample size) and p (number of predictors) </span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># instead of df.1/df.2 to avoid the redundancy error.</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>  ci_res <span class="ot">&lt;-</span> MBESS<span class="sc">::</span><span class="fu">ci.R2</span>(<span class="at">F.value =</span> F_stat, </span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">p =</span> k,      <span class="co"># Number of predictors</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>                         <span class="at">N =</span> n,      <span class="co"># Sample size</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">conf.level =</span> <span class="fl">0.95</span>,</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Random.Predictors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(ci_res)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Package 'MBESS' is not installed."</span>)</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>$Lower.Conf.Limit.R2
[1] 0.6982442

$Prob.Less.Lower
[1] 0.025

$Upper.Conf.Limit.R2
[1] 0.8555948

$Prob.Greater.Upper
[1] 0.025</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="underfitting-and-overfitting" class="level2" data-number="6.16">
<h2 data-number="6.16" class="anchored" data-anchor-id="underfitting-and-overfitting"><span class="header-section-number">6.16</span> Underfitting and Overfitting</h2>
<p>We compare the properties of two competing estimators for the mean response vector <span class="math inline">\(\mu = E[y]\)</span>.</p>
<section id="notation-and-setup" class="level3" data-number="6.16.1">
<h3 data-number="6.16.1" class="anchored" data-anchor-id="notation-and-setup"><span class="header-section-number">6.16.1</span> Notation and Setup</h3>
<p>Consider the data partition <span class="math inline">\(X = [X_1 \ X_2]\)</span>. We define two competing models:</p>
<p><strong>1. Reduced Model (<span class="math inline">\(M_0\)</span>)</strong></p>
<p>Assumes <span class="math inline">\(y = X_1\beta_1 + e\)</span>. <span class="math display">\[
\begin{aligned}
P_0 &amp;= X_1(X_1^T X_1)^{-1}X_1^T &amp; (\text{Projection for } M_0) \\
\hat{y}_0 &amp;= P_0 y &amp; (\text{Estimator for } M_0)
\end{aligned}
\]</span></p>
<p><strong>2. Full Model (<span class="math inline">\(M_1\)</span>)</strong></p>
<p>Assumes <span class="math inline">\(y = X_1\beta_1 + X_2\beta_2 + e\)</span>. <span class="math display">\[
\begin{aligned}
P_1 &amp;= X(X^T X)^{-1}X^T &amp; (\text{Projection for } M_1) \\
\hat{y}_1 &amp;= P_1 y &amp; (\text{Estimator for } M_1)
\end{aligned}
\]</span></p>
<p><strong>Key Geometric Property:</strong> Since the column space of <span class="math inline">\(X_1\)</span> is a subspace of <span class="math inline">\(X\)</span> (<span class="math inline">\(\mathcal{C}(X_1) \subset \mathcal{C}(X)\)</span>), we have the nesting property: <span class="math display">\[
P_1 P_0 = P_0 \quad \text{and} \quad P_1 - P_0 \text{ is a projection matrix.}
\]</span></p>
</section>
<section id="case-1-underfitting" class="level3" data-number="6.16.2">
<h3 data-number="6.16.2" class="anchored" data-anchor-id="case-1-underfitting"><span class="header-section-number">6.16.2</span> Case 1: Underfitting</h3>
<p><strong>The Truth:</strong> The Full Model (<span class="math inline">\(M_1\)</span>) is correct. <span class="math display">\[
y = X_1\beta_1 + X_2\beta_2 + e, \quad \beta_2 \neq 0
\]</span> The true mean is <span class="math inline">\(\mu = X_1\beta_1 + X_2\beta_2\)</span>.</p>
<p>We analyze the properties of the <strong>Reduced Estimator</strong> <span class="math inline">\(\hat{y}_0\)</span> (from <span class="math inline">\(M_0\)</span>) compared to the correct Full Estimator <span class="math inline">\(\hat{y}_1\)</span> (from <span class="math inline">\(M_1\)</span>).</p>
<div id="thm-underfitting" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.12 (Bias-Variance Tradeoff in Underfitting)</strong></span> When <span class="math inline">\(M_1\)</span> is true:</p>
<ol type="1">
<li><strong>Bias:</strong> The estimator <span class="math inline">\(\hat{y}_0\)</span> is <strong>biased</strong>, while <span class="math inline">\(\hat{y}_1\)</span> is unbiased. <span class="math display">\[ \text{Bias}(\hat{y}_0) = -(I - P_0) X_2 \beta_2 \]</span></li>
<li><strong>Variance:</strong> The estimator <span class="math inline">\(\hat{y}_0\)</span> has <strong>smaller variance</strong> (matrix difference is positive semidefinite). <span class="math display">\[ \text{Var}(\hat{y}_1) - \text{Var}(\hat{y}_0) = \sigma^2 (P_1 - P_0) \ge 0 \]</span></li>
</ol>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><strong>Part 1 (Bias):</strong> <span class="math display">\[
\begin{aligned}
E[\hat{y}_0] &amp;= P_0 E[y] = P_0(X_1\beta_1 + X_2\beta_2) \\
&amp;= X_1\beta_1 + P_0 X_2 \beta_2 \quad (\text{Since } P_0 X_1 = X_1)
\end{aligned}
\]</span> The bias is: <span class="math display">\[
\text{Bias} = E[\hat{y}_0] - \mu = (X_1\beta_1 + P_0 X_2 \beta_2) - (X_1\beta_1 + X_2\beta_2) = -(I - P_0)X_2\beta_2
\]</span></p>
<p><strong>Part 2 (Variance):</strong> <span class="math display">\[
\text{Var}(\hat{y}_1) = \sigma^2 P_1, \quad \text{Var}(\hat{y}_0) = \sigma^2 P_0
\]</span> The difference is <span class="math inline">\(\sigma^2(P_1 - P_0)\)</span>. Since <span class="math inline">\(\mathcal{C}(X_1) \subset \mathcal{C}(X)\)</span>, the difference <span class="math inline">\(P_1 - P_0\)</span> projects onto the orthogonal complement of <span class="math inline">\(\mathcal{C}(X_1)\)</span> within <span class="math inline">\(\mathcal{C}(X)\)</span>. It is idempotent and positive semidefinite.</p>
</div>
<p><strong>Remark: Scalar Variance and Coefficients</strong></p>
<p>From the matrix inequality above, we can state that for any arbitrary vector <span class="math inline">\(a\)</span>, the scalar variance of the linear combination <span class="math inline">\(a^T \hat{y}\)</span> is always smaller in the reduced model: <span class="math display">\[
\text{Var}(a^T \hat{y}_0) \le \text{Var}(a^T \hat{y}_1)
\]</span></p>
<p>We can extend this property to the regression coefficients <span class="math inline">\(\hat{\beta}\)</span>. Since <span class="math inline">\(\hat{y} = X\hat{\beta}\)</span>, we can recover the coefficients from the fitted values using the left pseudo-inverse:</p>
<p><span class="math display">\[
\begin{aligned}
(X^T X)^{-1}X^T (X\hat{\beta}) &amp;= (X^T X)^{-1}X^T \hat{y} \\
\underbrace{(X^T X)^{-1}(X^T X)}_{I} \hat{\beta} &amp;= (X^T X)^{-1}X^T \hat{y}
\end{aligned}
\]</span></p>
<div id="cor-beta-variance" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 6.3 (Variance of Coefficients)</strong></span> Because <span class="math inline">\(\hat{\beta}\)</span> is a linear transformation of <span class="math inline">\(\hat{y}\)</span>, the variance reduction in <span class="math inline">\(\hat{y}_0\)</span> propagates to the coefficients.</p>
<p>For any specific coefficient <span class="math inline">\(\beta_j\)</span> included in the reduced model (i.e., <span class="math inline">\(\beta_j \in \beta_1\)</span>), the variance of the estimator is smaller in the reduced model than in the full model: <span class="math display">\[ \text{Var}(\hat{\beta}_{j, reduced}) \le \text{Var}(\hat{\beta}_{j, full}) \]</span></p>
</div>
<p><strong>Conclusion:</strong> Using <span class="math inline">\(M_0\)</span> when <span class="math inline">\(M_1\)</span> is true introduces bias but reduces variance for both the fitted values and the estimated coefficients.</p>
</section>
<section id="case-2-overfitting" class="level3" data-number="6.16.3">
<h3 data-number="6.16.3" class="anchored" data-anchor-id="case-2-overfitting"><span class="header-section-number">6.16.3</span> Case 2: Overfitting</h3>
<p><strong>The Truth:</strong> The Reduced Model (<span class="math inline">\(M_0\)</span>) is correct. <span class="math display">\[
y = X_1\beta_1 + e \quad (\text{i.e., } \beta_2 = 0)
\]</span> The true mean is <span class="math inline">\(\mu = X_1\beta_1\)</span>.</p>
<p>We analyze the properties of the <strong>Full Estimator</strong> <span class="math inline">\(\hat{y}_1\)</span> (from <span class="math inline">\(M_1\)</span>) compared to the correct Reduced Estimator <span class="math inline">\(\hat{y}_0\)</span> (from <span class="math inline">\(M_0\)</span>).</p>
<div id="thm-overfitting" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.13 (Variance Inflation in Overfitting)</strong></span> When <span class="math inline">\(M_0\)</span> is true:</p>
<ol type="1">
<li><strong>Bias:</strong> Both estimators are <strong>unbiased</strong>. <span class="math display">\[ E[\hat{y}_1] = \mu \quad \text{and} \quad E[\hat{y}_0] = \mu \]</span></li>
<li><strong>Variance:</strong> The estimator <span class="math inline">\(\hat{y}_1\)</span> has <strong>unnecessarily higher variance</strong>. <span class="math display">\[ \text{Var}(\hat{y}_1) \ge \text{Var}(\hat{y}_0) \]</span></li>
</ol>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><strong>Part 1 (Bias):</strong> Since <span class="math inline">\(\mu = X_1\beta_1\)</span>: <span class="math display">\[
E[\hat{y}_1] = P_1 X_1\beta_1 = X_1\beta_1 = \mu \quad (\text{Since } X_1 \in \mathcal{C}(X))
\]</span> <span class="math display">\[
E[\hat{y}_0] = P_0 X_1\beta_1 = X_1\beta_1 = \mu \quad (\text{Since } X_1 \in \mathcal{C}(X_1))
\]</span></p>
<p><strong>Part 2 (Variance):</strong> As shown in Case 1, the difference is <span class="math inline">\(\sigma^2(P_1 - P_0)\)</span>. The cost of overfitting is purely variance inflation. The total variance (trace) increases by the number of unnecessary parameters (<span class="math inline">\(p_2\)</span>): <span class="math display">\[
\text{tr}(\text{Var}(\hat{y}_1)) - \text{tr}(\text{Var}(\hat{y}_0)) = \sigma^2 (\text{tr}(P_1) - \text{tr}(P_0)) = \sigma^2 (p_{full} - p_{reduced}) = \sigma^2 p_2
\]</span></p>
</div>
<p><strong>Conclusion:</strong> Using <span class="math inline">\(M_1\)</span> when <span class="math inline">\(M_0\)</span> is true offers no benefit in bias but strictly increases estimation variance.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="./lec4-qf.html" class="pagination-link" aria-label="Distribution of Quadratic Forms">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Distribution of Quadratic Forms</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ginv.html" class="pagination-link" aria-label="Generalized Inverses">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Generalized Inverses</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>