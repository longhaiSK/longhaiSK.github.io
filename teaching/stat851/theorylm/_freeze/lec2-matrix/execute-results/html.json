{
  "hash": "d8556ff65824dc4469372b4ac754f8a9",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  html: default\n  pdf: default\n---\n\n# Matrix Algebra\n\n\n\nThis chapter covers a review of matrix algebra concepts essential for linear models, including eigenvalues, spectral decomposition, singular value decomposition.\n\n\n\n## Eigenvalues and Eigenvectors\n\n::: {#def-eigen name=\"Eigenvalues and Eigenvectors\"}\n\nFor a square matrix $A$ ($n \\times n$), a scalar $\\lambda$ is an **eigenvalue** and a non-zero vector $x$ is the corresponding **eigenvector** if:\n\n$$\nAx = \\lambda x \\iff (A - \\lambda I_n)x = 0\n$$\n\nThe eigenvalues are found by solving the characteristic equation:\n$$\n|A - \\lambda I_n| = 0\n$$\n:::\n\n## Spectral Theory for Symmetric Matrices\n\n\n### Spectral Decomposition\n\nFor symmetric matrices, we have a powerful decomposition theorem.\n\n::: {#thm-spectral}\n### Spectral Decomposition\n\nIf $A$ is a symmetric $n \\times n$ matrix, all its eigenvalues $\\lambda_1, \\dots, \\lambda_n$ are real. Furthermore, there exists an orthogonal matrix $Q$ such that:\n\n$$\nA = Q \\Lambda Q' = \\sum_{i=1}^n \\lambda_i q_i q_i'\n$$\n\nwhere:\n\n* $\\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$ contains the eigenvalues.\n* $Q = (q_1, \\dots, q_n)$ contains the corresponding orthonormal eigenvectors ($q_i'q_j = \\delta_{ij}$).\n:::\n\n**Explantion**: \nThis allows us to view the transformation $Ax$ as a rotation ($Q'$), a scaling ($\\Lambda$), and a rotation back ($Q$). For a symmetric matrix $A$, we can write the spectral decomposition as a product of the eigenvector matrix $Q$ and eigenvalue matrix $\\Lambda$:\n\n$$\n\\begin{aligned}\nA &= Q \\Lambda Q' \\\\\n  &= \\begin{pmatrix} q_1 & q_2 & \\cdots & q_n \\end{pmatrix} \n     \\begin{pmatrix} \\lambda_1 & 0 & \\cdots & 0 \\\\ 0 & \\lambda_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & \\lambda_n \\end{pmatrix} \n     \\begin{pmatrix} q_1' \\\\ q_2' \\\\ \\vdots \\\\ q_n' \\end{pmatrix} \\\\\n  &= \\begin{pmatrix} \\lambda_1 q_1 & \\lambda_2 q_2 & \\cdots & \\lambda_n q_n \\end{pmatrix} \n     \\begin{pmatrix} q_1' \\\\ q_2' \\\\ \\vdots \\\\ q_n' \\end{pmatrix} \\\\\n  &= \\lambda_1 q_1 q_1' + \\lambda_2 q_2 q_2' + \\cdots + \\lambda_n q_n q_n' \\\\\n  &= \\sum_{i=1}^n \\lambda_i q_i q_i'\n\\end{aligned}\n$$\n\nwhere the eigenvectors $q_i$ satisfy the orthogonality conditions:\n$$\nq_i' q_j = \\begin{cases} 1 & \\text{if } i=j \\\\ 0 & \\text{if } i \\ne j \\end{cases}\n$$\nAnd $Q$ is an orthogonal matrix: $Q'Q = Q Q' = I_n$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# --- 1. MATRIX SETUP ---\n# Symmetric Matrix where eigenvectors are tilted\nA <- matrix(c(1.5, 0.8, 0.8, 1.5), nrow = 2)\n\n# Decomposition A = QDQ'\neig <- eigen(A)\nQ <- eig$vectors\nD_mat <- diag(eig$values)\n\n# --- 2. DEFINE THE 6 VECTORS ---\n\n# 1 & 2: Standard Axes (We will label these x1, x2)\nv1 <- c(1, 0)\nv2 <- c(0, 1)\n# 3 & 4: Eigenvectors\nv3 <- Q[,1]\nv4 <- Q[,2]\n# 5 & 6: Filler vectors at random angles\nv5 <- c(cos(pi/3), sin(pi/3))\nv6 <- c(cos(4*pi/3), sin(4*pi/3))\n\n# Combine into starting matrix V_start\nV_start <- cbind(v1, v2, v3, v4, v5, v6)\n\n# Define 6 Distinct Colors\nmy_colors <- c(\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#984EA3\", \"#FF7F00\", \"#A65628\")\nnames(my_colors) <- 1:6\n\n# Background Circle Points used for reference path in all plots\ntheta_c <- seq(0, 2*pi, length.out = 150)\nC_start <- rbind(cos(theta_c), sin(theta_c))\n\n# --- 3. DATA PROCESSING HELPER FUNCTION ---\n\n# This function prepares the data frames for ggplot for a given stage\nprepare_data <- function(V_mat, C_mat, stage_title, label_text_pair) {\n  # Prepare Vectors data frame\n  df_v <- data.frame(t(V_mat))\n  colnames(df_v) <- c(\"x\", \"y\")\n  df_v$vec_id <- factor(1:6) # Unique ID for coloring\n  \n  # Add labels only for vector 1 and 2\n  df_v$label <- \"\"\n  df_v$label[1] <- label_text_pair[1]\n  df_v$label[2] <- label_text_pair[2]\n  \n  # Calculate nudge for labels based on vector direction so they don't overlap arrow tip\n  df_v$nudge_x <- sign(df_v$x) * 0.25\n  df_v$nudge_y <- sign(df_v$y) * 0.25\n  # Don't nudge unlabelled vectors\n  df_v$nudge_x[3:6] <- 0\n  df_v$nudge_y[3:6] <- 0\n\n  # Prepare Background Path data frame\n  df_c <- data.frame(t(C_mat))\n  colnames(df_c) <- c(\"px\", \"py\")\n  \n  list(vecs = df_v, path = df_c, title = stage_title)\n}\n\n\n# --- 4. PERFORM TRANSFORMATIONS ---\n\n# Stage 1: Start (x)\nd1 <- prepare_data(V_start, C_start, \n                   \"1. Start (x)\", c(\"x[1]\", \"x[2]\"))\n\n# Stage 2: Rotate (Q'x)\nV2 <- t(Q) %*% V_start\nC2 <- t(Q) %*% C_start\nd2 <- prepare_data(V2, C2, \n                   \"2. Rotate (Q'x)\", c(\"z[1]\", \"z[2]\"))\n\n# Stage 3: Stretch (DQ'x)\nV3 <- D_mat %*% V2\nC3 <- D_mat %*% C2\nd3 <- prepare_data(V3, C3, \n                   \"3. Stretch (DQ'x)\", c(\"y[1]\", \"y[2]\"))\n\n# Stage 4: Rotate Back (QDQ'x)\nV4 <- Q %*% V3\nC4 <- Q %*% C3\nd4 <- prepare_data(V4, C4, \n                   \"4. Final (QDQ'x)\", c(\"w[1]\", \"w[2]\"))\n\n\n# --- 5. PLOTTING FUNCTION ---\n\nplot_stage_final <- function(data_list) {\n  ggplot() +\n    # Background path (gray dashed)\n    geom_path(data = data_list$path, aes(x=px, y=py), \n              color=\"gray70\", linetype=\"dashed\") +\n    # The 6 vectors\n    geom_segment(data = data_list$vecs, aes(x=0, y=0, xend=x, yend=y, color=vec_id), \n                 arrow = arrow(length = unit(0.3, \"cm\")), size=1.1) +\n    # The labels for v1 and v2 using parsed expressions for subscripts\n    geom_text(data = data_list$vecs, aes(x=x, y=y, label=label, color=vec_id),\n              parse = TRUE, fontface=\"bold\", size=5,\n              nudge_x = data_list$vecs$nudge_x,\n              nudge_y = data_list$vecs$nudge_y) +\n    scale_color_manual(values = my_colors) +\n    # Fixed coordinates to ensure realistic rotation/stretching view\n    coord_fixed(xlim = c(-2.5, 2.5), ylim = c(-2.5, 2.5)) +\n    theme_bw() +\n    theme(legend.position = \"none\",\n          panel.grid.minor = element_blank(),\n          plot.title = element_text(face=\"bold\", hjust=0.5),\n          axis.title = element_blank()) +\n    labs(title = data_list$title)\n}\n\n# Generate the 4 plots\np1 <- plot_stage_final(d1)\np2 <- plot_stage_final(d2)\np3 <- plot_stage_final(d3)\np4 <- plot_stage_final(d4)\n\n# Arrange them in a grid\ngrid.arrange(p1, p2, p3, p4, nrow = 2)\n```\n\n::: {.cell-output-display}\n![](lec2-matrix_files/figure-html/unnamed-chunk-1-1.png){width=576}\n:::\n:::\n\n### Quadratic Form\n:::{#def-quadratic-form}\n\nA **quadratic form** in $n$ variables $x_1, x_2, \\dots, x_n$ is a scalar function defined by a symmetric matrix $A$:\n$$\nQ(x) = x'Ax = \\sum_{i=1}^n \\sum_{j=1}^n a_{ij} x_i x_j\n$$\n:::\n\n### Positive and Non-Negative Definite Matrices\n\n:::{#def-pos-def name=\"Positive and Non-Negative Definite Matrices\"}\n\nA symmetric matrix $A$ is **positive definite (p.d.)** if:\n$$\nx'Ax > 0 \\quad \\forall x \\ne 0\n$$\nIt is **non-negative definite (n.n.d.)** if:\n$$\nx'Ax \\ge 0 \\quad \\forall x\n$$\n:::\n\n:::{#thm-nnd-properties name=\"Properties of Definite Matrices\"}\n\nLet $A$ be a symmetric $n \\times n$ matrix with eigenvalues $\\lambda_1, \\dots, \\lambda_n$.\n\n1.  **Eigenvalue Characterization:**\n    * $A$ is p.d. $\\iff$ all $\\lambda_i > 0$.\n    * $A$ is n.n.d. $\\iff$ all $\\lambda_i \\ge 0$.\n\n2.  **Determinant and Inverse:**\n    * If $A$ is p.d., then $|A| > 0$ and $A^{-1}$ exists.\n    * If $A$ is n.n.d. and singular, then $|A| = 0$ (at least one $\\lambda_i = 0$).\n\n3.  **Gram Matrices ($B'B$):**\n    Let $B$ be an $n \\times p$ matrix.\n\n    * If $\\text{rank}(B) = p$, then $B'B$ is p.d.\n    * If $\\text{rank}(B) < p$, then $B'B$ is n.n.d.\n:::\n\n### Properties of Symmetric Matrices\n:::{#thm-symmetric-properties name=\"Properties of Symmetric Matrices\"}\nLet $A$ be a symmetric matrix with spectral decomposition $A = Q \\Lambda Q'$. The following properties hold:\n\n1.  **Trace:** $\\text{tr}(A) = \\sum \\lambda_i$.\n2.  **Determinant:** $|A| = \\prod \\lambda_i$.\n3.  **Singularity:** $A$ is singular if and only if at least one $\\lambda_i = 0$.\n4.  **Inverse:** If $A$ is non-singular ($\\lambda_i \\ne 0$), then $A^{-1} = Q \\Lambda^{-1} Q'$.\n5.  **Powers:** $A^k = Q \\Lambda^k Q'$.\n    * *Square Root:* $A^{1/2} = Q \\Lambda^{1/2} Q'$ (if $\\lambda_i \\ge 0$).\n6.  **Spectral Representation of Quadratic Forms:** The quadratic form $x'Ax$ can be diagonalized using the eigenvectors of $A$:\n    $$\n    x'Ax = x' Q \\Lambda Q' x = y' \\Lambda y = \\sum_{i=1}^n \\lambda_i y_i^2\n    $$\n    where $y = Q'x$ represents a rotation of the coordinate system.\n:::\n\n### Spectral Representation of Projection Matrices \n\nWe revisit projection matrices in the context of eigenvalues.\n\n::: {#thm-proj-eigen name=\"Eigenvalues of Projection Matrices\"}\n\nA symmetric matrix $P$ is a projection matrix (idempotent, $P^2=P$) if and only if its eigenvalues are either 0 or 1.\n\n$$\nP^2 x = \\lambda^2 x \\quad \\text{and} \\quad Px = \\lambda x \\implies \\lambda^2 = \\lambda \\implies \\lambda \\in \\{0, 1\\}\n$$\n:::\n\nFor a projection matrix $P$:\n\n* If $x \\in \\text{Col}(P)$, $Px = x$ (Eigenvalue 1).\n* If $x \\perp \\text{Col}(P)$, $Px = 0$ (Eigenvalue 0).\n* $\\text{rank}(P) = \\text{tr}(P) = \\sum \\lambda_i$ (Count of 1s).\n\n::: {#exm-trace-P}\nFor $P = \\frac{1}{n} J_n J_n'$, the rank is $\\text{tr}(P) = 1$.\n:::\n\n\n## Singular Value Decomposition (SVD)\n\n:::{#thm-svd name=\"Singular Value Decomposition (SVD)\"}\n\nLet $X$ be an $n \\times p$ matrix with rank $r \\le \\min(n, p)$. $X$ can be decomposed into the product of three matrices:\n\n$$\nX = U \\mathbf{D} V'\n$$\n\n**1. Partitioned Matrix Form**\n\n$$\nX = \\underset{n \\times n}{(U_1, U_2)}\n\\begin{pmatrix}\n\\Lambda_r & O_{r \\times (p-r)} \\\\\nO_{(n-r) \\times r} & O_{(n-r) \\times (p-r)}\n\\end{pmatrix}\n\\underset{p \\times p}{\n\\begin{pmatrix}\nV_1' \\\\\nV_2'\n\\end{pmatrix}\n}\n$$\n\n**2. Detailed Matrix Form**\n\nExpanding the diagonal matrix explicitly:\n\n$$\nX = \\underset{n \\times n}{(u_1, \\dots, u_n)}\n\\left(\n\\begin{array}{cccc|c}\n\\lambda_1 & 0 & \\dots & 0 &  \\\\\n0 & \\lambda_2 & \\dots & 0 & O_{12} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots &  \\\\\n0 & 0 & \\dots & \\lambda_r &  \\\\\n\\hline\n & O_{21} & & & O_{22}\n\\end{array}\n\\right)\n\\underset{p \\times p}{\n\\begin{pmatrix}\nv_1' \\\\\n\\vdots \\\\\nv_p'\n\\end{pmatrix}\n}\n$$\n\n**3. Reduced Form**\n\n$$\nX = U_1 \\Lambda_r V_1' = \\sum_{i=1}^r \\lambda_i u_i v_i'\n$$\n\n**Properties:**\n\n1.  **Singular Values ($\\Lambda_r$):** $\\Lambda_r = \\text{diag}(\\lambda_1, \\dots, \\lambda_r)$ contains the singular values ($\\lambda_i > 0$), which are the square roots of the non-zero eigenvalues of $X'X$.\n2.  **Orthogonality:**\n    * $U$ is $n \\times n$ orthogonal ($U'U = I_n$).\n    * $V$ is $p \\times p$ orthogonal ($V'V = I_p$).\n:::\n\n#### Connection to Gram Matrices\n\nThe matrices $U$ and $V$ provide the basis vectors (eigenvectors) for the Gram matrices of $X$.\n\n1.  **Right Singular Vectors ($V$):**\n    The columns of $V$ are the eigenvectors of the Gram matrix $X'X$.\n    $$\n    X'X = (U \\Lambda V')' (U \\Lambda V') = V \\Lambda U' U \\Lambda V' = V \\Lambda^2 V'\n    $$\n\n    * The eigenvalues of $X'X$ are the squared singular values $\\lambda_i^2$.\n\n2.  **Left Singular Vectors ($U$):**\n    The columns of $U$ are the eigenvectors of the Gram matrix $XX'$.\n    $$\n    XX' = (U \\Lambda V') (U \\Lambda V')' = U \\Lambda V' V \\Lambda U' = U \\Lambda^2 U'\n    $$\n\n    * The eigenvalues of $XX'$ are also $\\lambda_i^2$ (for non-zero values).\n\n#### Numerical Example\n\nConsider the matrix $X = \\begin{pmatrix} 1 & 1 \\\\ 2 & 2 \\end{pmatrix}$.\n\n1.  **Compute $X'X$ and find $V$:**\n    $$\n    X'X = \\begin{pmatrix} 1 & 2 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 2 & 2 \\end{pmatrix} = \\begin{pmatrix} 5 & 5 \\\\ 5 & 5 \\end{pmatrix}\n    $$\n\n    * Eigenvalues of $X'X$: Trace is 10, Determinant is 0. Thus, $\\mu_1 = 10, \\mu_2 = 0$.\n    * **Singular Values:** $\\lambda_1 = \\sqrt{10}, \\lambda_2 = 0$.\n    * Eigenvector for $\\mu_1=10$: Normalized $v_1 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n    * Eigenvector for $\\mu_2=0$: Normalized $v_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$.\n    * Therefore, $V = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}$.\n\n2.  **Compute $XX'$ and find $U$:**\n    $$\n    XX' = \\begin{pmatrix} 1 & 1 \\\\ 2 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 2 \\\\ 1 & 2 \\end{pmatrix} = \\begin{pmatrix} 2 & 4 \\\\ 4 & 8 \\end{pmatrix}\n    $$\n\n    * Eigenvalues are again 10 and 0.\n    * Eigenvector for $\\mu_1=10$: Normalized $u_1 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n    * Eigenvector for $\\mu_2=0$: Normalized $u_2 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$.\n    * Therefore, $U = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix}$.\n\n3.  **Verification:**\n    $$\n    X = \\sqrt{10} u_1 v_1' = \\sqrt{10} \\begin{pmatrix} \\frac{1}{\\sqrt{5}} \\\\ \\frac{2}{\\sqrt{5}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 2 & 2 \\end{pmatrix}\n    $$\n\n## Cholesky Decomposition\n\nA symmetric matrix $A$ has a Cholesky decomposition if and only if it is **non-negative definite** (i.e., $x'Ax \\ge 0$ for all $x$).\n\n$$\nA = B'B\n$$\n\nwhere $B$ is an **upper triangular** matrix with non-negative diagonal entries.\n\n### Matrix Representation of the Algorithm\n\nTo derive the algorithm, we equate the elements of $A$ with the product of the lower triangular matrix $B'$ and the upper triangular matrix $B$.\n\nFor a $3 \\times 3$ matrix, this looks like:\n\n$$\n\\underbrace{\\begin{pmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{pmatrix}}_{A}\n=\n\\underbrace{\\begin{pmatrix}\nb_{11} & 0 & 0 \\\\\nb_{12} & b_{22} & 0 \\\\\nb_{13} & b_{23} & b_{33}\n\\end{pmatrix}}_{B'}\n\\underbrace{\\begin{pmatrix}\nb_{11} & b_{12} & b_{13} \\\\\n0 & b_{22} & b_{23} \\\\\n0 & 0 & b_{33}\n\\end{pmatrix}}_{B}\n$$\n\nMultiplying the matrices on the right yields the system of equations:\n\n$$\nA = \\begin{pmatrix}\n\\mathbf{b_{11}^2} & b_{11}b_{12} & b_{11}b_{13} \\\\\nb_{12}b_{11} & \\mathbf{b_{12}^2 + b_{22}^2} & b_{12}b_{13} + b_{22}b_{23} \\\\\nb_{13}b_{11} & b_{13}b_{12} + b_{23}b_{22} & \\mathbf{b_{13}^2 + b_{23}^2 + b_{33}^2}\n\\end{pmatrix}\n$$\n\nBy solving for the bolded diagonal terms and substituting known values from previous rows, we get the recursive algorithm.\n\n### The Algorithm\n\n1.  **Row 1:** Solve for $b_{11}$ using $a_{11}$, then solve the rest of the row ($b_{1j}$) by division.\n    * $b_{11} = \\sqrt{a_{11}}$\n    * $b_{1j} = a_{1j}/b_{11}$\n\n2.  **Row 2:** Solve for $b_{22}$ using $a_{22}$ and the known $b_{12}$, then solve $b_{2j}$.\n    * $b_{22} = \\sqrt{a_{22} - b_{12}^2}$\n    * $b_{2j} = (a_{2j} - b_{12}b_{1j}) / b_{22}$\n\n3.  **Row 3:** Solve for $b_{33}$ using $a_{33}$ and the known $b_{13}, b_{23}$.\n    * $b_{33} = \\sqrt{a_{33} - b_{13}^2 - b_{23}^2}$\n\n### Numerical Example\n\nConsider the positive definite matrix $A$:\n$$\nA = \\begin{pmatrix}\n4 & 2 & -2 \\\\\n2 & 10 & 2 \\\\\n-2 & 2 & 6\n\\end{pmatrix}\n$$\n\nWe find $B$ such that $A = B'B$:\n\n1.  **First Row of B ($b_{11}, b_{12}, b_{13}$):**\n    * $b_{11} = \\sqrt{4} = 2$\n    * $b_{12} = 2 / 2 = 1$\n    * $b_{13} = -2 / 2 = -1$\n\n2.  **Second Row of B ($b_{22}, b_{23}$):**\n    * $b_{22} = \\sqrt{10 - (1)^2} = \\sqrt{9} = 3$\n    * $b_{23} = (2 - (1)(-1)) / 3 = 3/3 = 1$\n\n3.  **Third Row of B ($b_{33}$):**\n    * $b_{33} = \\sqrt{6 - (-1)^2 - (1)^2} = \\sqrt{4} = 2$\n\n**Result:**\n$$\nB = \\begin{pmatrix}\n2 & 1 & -1 \\\\\n0 & 3 & 1 \\\\\n0 & 0 & 2\n\\end{pmatrix}\n$$\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}