---
title: "Logistic Regression"
author:
  - name: "Longhai Li"
    url: "https://longhaisk.github.io/"
date: today
from: markdown+tex_math_single_backslash+tex_math_dollars
format:
  # make sure these files get copied alongside the page
  html:
    theme: cosmo            # (Rmd `theme: null`)
    embed-resources: false # (Rmd `self_contained: false`)
    toc: false
    page-layout: full
    #css: mystyles.css
    code-fold: true
    number-sections: true
    df-print: paged        # (Rmd `df_print: paged`)
    highlight-style: tango # (Rmd `highlight: tango`)
    include-in-header:
      text: |
        <link rel="stylesheet" href="/resources/mystyles.css?v=2">
        <script src="/resources/rendernav.js" defer></script>
        <script src="/resources/loadtoc.js" defer></script>
    resources:
      - mystyles.css
      - rendernav.js
editor: source
execute:
  echo: true
  warning: false
  message: false
  cache: true
  fig-width: 9
  fig-height: 6
    
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: false
jit <- 0.05
```

# Odds as a Function of Probability

For an event with probability \(p\), the odds is 
\[\mathrm{odds}(p)=\frac{p}{1-p}\] 
and the log-odds (logit) is 
\[\mathrm{logit}(p)=\log\left(\frac{p}{1-p}\right)\]. 



```{r}
#| label: plot-odds-colored
#| echo: true
# Plot odds(p) with a right-hand axis for log(odds(p)),
# using different line colors for the two curves.
# Defaults: p in [0.01, 0.99].
# Args:
#   p_min, p_max : endpoints for p-grid (0<p_min<p_max<1)
#   n            : number of grid points
#   annotate     : add reference lines/labels if TRUE
#   odds_col     : color for odds(p)
#   logit_col    : color for log(odds(p))
#   lwd1, lwd2   : line widths for the two curves
plot_odds <- function(p_min = 0.01, p_max = 0.99, n = 400,
                      annotate = TRUE,
                      odds_col = "steelblue",
                      logit_col = "firebrick",
                      lwd1 = 2, lwd2 = 2) {
  stopifnot(p_min > 0, p_max < 1, p_min < p_max, n >= 10)
  p <- seq(p_min, p_max, length.out = n)
  odds <- p / (1 - p)
  logit <- log(odds)

  # Left y-axis: odds(p)
  plot(p, odds, type = "l", lwd = lwd1, col = odds_col,
       xlab = "Probability p",
       ylab = "odds(p) = p / (1 - p)")
  if (annotate) {
    abline(h = 1, v = 0.5, lty = 2)
    text(0.52, 1.05, "p = 0.5 → odds = 1", adj = 0)
  }

  # Right y-axis: logit(p) = log(odds)
  op <- par(new = TRUE)
  on.exit(par(op), add = TRUE)
  plot(p, logit, type = "l", lwd = lwd2, col = logit_col,
       axes = FALSE, xlab = "", ylab = "")
  axis(4)
  mtext("log{odds(p)} = log{p/(1 - p)}", side = 4, line = 3)

  if (annotate) {
    abline(v = 0.5, lty = 2)
    # logit(0.5) = 0 reference (horizontal) on the right-axis scale
    usr <- par("usr")
    segments(x0 = usr[1], y0 = 0, x1 = 0.5, y1 = 0, lty = 3)
  }

  legend("topleft",
         legend = c("odds(p)", "log{odds(p)}"),
         col = c(odds_col, logit_col),
         lwd = c(lwd1, lwd2), bty = "n")

  invisible(list(p = p, odds = odds, logit = logit))
}

# Example usage:
# plot_odds()  # defaults: steelblue for odds, firebrick for log-odds (right axis)
plot_odds(odds_col = "#1f77b4", logit_col = "#d62728", n = 600)
```

Logistic regression models **log-odds** linearly in predictors, which both keeps fitted probabilities in \((0,1)\) and turns multiplicative effects on odds into **additive** effects on the linear predictor.


---

# Simulate and Plot a One-Predictor Logistic Model

We simulate data from a logistic model where the **logit** is a linear function of $x$:

$$
\operatorname{logit}{p(x)}
=
\log\left(\frac{p(x)}{1-p(x)}\right)
=
\beta_0 + \beta_1 x,
$$

so that

$$
p(x)
=
\operatorname{logit}^{-1}(\beta_0+\beta_1 x)
=
\frac{1}{1+\exp{-(\beta_0+\beta_1 x)}}.
$$

We then display the observed $y_i$ (binary outcomes) and the true probability curve $p(x)$ in red.


```{r}
#| label: simulate-logistic-1x
#| echo: true
set.seed(123)

# -- Truth (edit as desired) --
n     <- 200
beta0 <- -0.5
beta1 <-  3

# -- Simulate --
x   <- runif(n, -1, 1)                  # predictor
eta <- beta0 + beta1 * x
p   <- plogis(eta)                      # true p(x)
y   <- rbinom(n, size = 1, prob = p)    # outcomes

dat <- data.frame(x = x, y = y, p = p)

# -- Optional: fit a model to the simulated data --
fit <- glm(y ~ x, data = dat, family = binomial())
p_fit <- predict(fit, newdata = data.frame(x = x), type = "response")

# -- Plot: points for y_i (jittered), red line for true p(x) --
# jitter to separate 0/1 visually
yj <- jitter(dat$y, amount = jit)

plot(dat$x, yj,
     pch = 16, col = rgb(0, 0, 0, 0.45),
     xlab = "x",
     ylab = "Observed y (points) & p(x) (curves)",
     ylim = c(-0.1, 1.1))

# True probability curve (red)
xg <- seq(min(x), max(x), length.out = 500)
lines(xg, plogis(beta0 + beta1 * xg), col = "red", lwd = 2)

# Optional: add fitted probability curve (dashed dark red)
lines(xg, predict(fit, newdata = data.frame(x = xg), type = "response"),
      col = "darkred", lwd = 2, lty = 2)

legend("topleft",
       legend = c("y (jittered points)", "true p(x)", "fitted p(x)"),
       pch    = c(16, NA, NA),
       lty    = c(NA, 1, 2),
       col    = c(rgb(0,0,0,0.45), "red", "darkred"),
       lwd    = c(NA, 2, 2),
       bty    = "n")


```

# Example of Coronary Heart Disease Data

## Load a dataset
This dataset is about a follow-up study to determine the development of coronary heart disease (CHD) over 9 years of follow-up of 609 white males from Evans County, Georgia.

**Variable meanings (as provided):**

* `chd`: 1 if a person has the disease, 0 otherwise.
* `smk`: 1 if smoker, 0 if not.
* `cat`: 1 if catecholamine level is high, 0 if low.
* `sbp`: systolic blood pressure (continuous).
* `age`: age in years (continuous).
* `chl`: cholesterol level (continuous).
* `ecg`: 1 if electrocardiogram is abnormal, 0 if normal.
* `hpt`: 1 if high blood pressure, 0 if normal.

```{r}
#| label: setup
# Adjust the path if needed. The default is your original V: drive path.
data_path <- "evans.dat"

# Read data (expects a header row)
CHD.data <- read.table(data_path, header = TRUE)

CHD.data

colnames(CHD.data)

```


## Fit Logistic Regression Model for a Single Variable

```{r}
#| label: chd-univariate-2x2-jitter-fixedlogit
#| echo: true

vars <- c("smk", "sbp", "age", "chl")
#jit  <- 0.01  # global jitter amount for y

# par(mfrow = c(2, 2), mar = c(4, 4, 2, 4) + 0.1)  # extra right margin for axis(4)

for (v in vars) {
  # Univariate logistic regression using ORIGINAL variable name in the formula
  fit <- glm(
    formula = reformulate(v, response = "chd"),
    data    = CHD.data,
    family  = binomial()
  )
  print(summary(fit))

  # Base scatter of chd with small jitter (left axis: probability scale)
  plot(
    CHD.data[[v]],
    jitter(CHD.data$chd, amount = jit),
    pch  = 16, col = rgb(0, 0, 0, 0.45),
    xlab = v, ylab = "chd (jittered)",
    main = paste("chd vs", v),
    ylim = c(-0.1, 1.1)
  )

  # Fitted π(x) in red (left axis)
  if (length(unique(CHD.data[[v]])) == 2) {
    # binary predictor
    xcat <- sort(unique(CHD.data[[v]]))
    nd   <- setNames(data.frame(xcat), v)
    pcat <- predict(fit, newdata = nd, type = "response")
    points(xcat, pcat, pch = 19, col = "red")
    lines(xcat, pcat, col = "red", lwd = 2)

    # Right-axis: logit{π(x)} with fixed y-limits
    logit_p <- log(pcat / (1 - pcat))
    par(new = TRUE)
    plot(
      xcat, logit_p, type = "l", lwd = 2, col = "blue",
      axes = FALSE, xlab = "", ylab = "",
      xlim = range(CHD.data[[v]]), ylim = c(-2.5, 0)
    )
    axis(4)
    mtext("logit(p(x))", side = 4, line = 3)
    par(new = FALSE)

  } else {
    # continuous predictor
    xg <- seq(min(CHD.data[[v]]), max(CHD.data[[v]]), length.out = 400)
    nd <- setNames(data.frame(xg), v)
    pg <- predict(fit, newdata = nd, type = "response")
    lines(xg, pg, col = "red", lwd = 2)

    # Right-axis: logit{π(x)} with fixed y-limits
    logit_pg <- log(pg / (1 - pg))
    par(new = TRUE)
    plot(
      xg, logit_pg, type = "l", lwd = 2, col = "blue",
      axes = FALSE, xlab = "", ylab = "",
      xlim = range(xg), ylim = c(-2.5, 0)
    )
    axis(4)
    mtext("logit(p(x))", side = 4, line = 3)
    par(new = FALSE)
  }
}

```



## Fit Logistic Regression Model with all variables

We fit a logistic regression with a logit link:

```{r}
#| label: fit-logit
fit1 <- glm(
  chd ~ smk + cat + sbp + age + chl + ecg + hpt,
  data = CHD.data,
  family = binomial(link = "logit")
)
summary(fit1)
```

**Notes for interpretation:**

* Positive coefficients increase the log-odds of CHD; negative coefficients decrease it.
* For indicator variables (e.g., `smk`), `exp(beta)` is the adjusted odds ratio comparing the group with value 1 versus 0, holding others fixed.
* For continuous predictors (e.g., `sbp`, `age`), `exp(beta)` is the multiplicative change in the odds for a one‑unit increase. For a *d*-unit increase, the OR is `exp(d * beta)`.

## Inference: Confidence Intervals and Covariance Matrix

We extract profile‑likelihood CIs and the covariance matrix to confirm standard errors.

```{r}
#| label: ci-cov
ci_95 <- confint(fit1, level = 0.95)     # profile-likelihood CI
vcov_mat <- vcov(fit1)                    # covariance matrix of coefficients
se_vec   <- sqrt(diag(vcov_mat))          # standard errors

ci_95
vcov_mat
se_vec  # should match the SE column in summary(fit1)
```

## Adjusted Odds Ratios for Individual Predictors


### Interpretation of Odds Ratios in Logistic Regression

A multiple logistic regression model expresses the log-odds (logit) of an event as a linear function of predictors:

$$
\log\left(\frac{p}{1-p}\right)
= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k.
$$

Here,

* $p = \Pr(Y = 1 \mid x_1, x_2, \ldots, x_k)$ is the probability of the event,
* $\beta_0$ is the intercept, and
* each $\beta_j$ represents the **change in the log-odds** of the event per one-unit increase in $x_j$, *holding all other variables constant*.

Exponentiating both sides gives the model in odds form:

$$
\frac{p}{1-p}
= \exp(\beta_0)
\times \exp(\beta_1 x_1)
\times \exp(\beta_2 x_2)
\times \cdots
\times \exp(\beta_k x_k).
$$

---

### Odds Ratios Without Interactions

If the model includes only **main effects** (no interaction terms), then the **odds ratio** associated with a one-unit increase in $x_j$ is constant:

$$
\text{OR}_{x_j} = \exp(\beta_j).
$$

This means that, after adjusting for all other variables, the odds of the outcome are multiplied by $\exp(\beta_j)$ for each one-unit increase in $x_j$.
The OR is **independent of the values** of the other covariates — the relationship between $x_j$ and the outcome is the same for everyone.

---

### Odds Ratios With Interactions

If interaction terms are included, such as between $x_1$ and $x_2$:

$$
\log\left(\frac{p}{1-p}\right)
= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{1,2}(x_1 \times x_2),
$$

then the effect of $x_1$ **depends on** the value of $x_2$.
The conditional log-odds change for a one-unit increase in $x_1$ is:

$$
\Delta \log\left(\frac{p}{1-p}\right)
= \beta_1 + \beta_{1,2} x_2,
$$

and the corresponding **odds ratio** is:

$$
\text{OR}_{x_2}(x_1)
= \exp\big(\beta_1 + \beta_{1,2} x_2\big).
$$

Thus, when interactions are present, the OR varies with the interacting variable(s), and interpretation must be **conditional** on their specified values.



*Summary*

* In models **without interactions**, each $\exp(\beta_j)$ gives a constant, adjusted odds ratio.
* In models **with interactions**, the odds ratio changes with other predictors and must be interpreted conditionally.
* In all cases, odds ratios describe **multiplicative effects on odds**, while coefficients describe **additive effects on log-odds**.


### Smoking (`smk`)

```{r}
#| label: or-smk
OR_smk <- exp(coef(fit1)["smk"])  # adjusted OR for smokers vs non-smokers
CI_OR_smk <- exp(ci_95["smk", ])  # 95% CI for the OR
OR_smk
CI_OR_smk

```

**How to read this:**

* `OR_smk > 1` suggests higher odds of CHD among smokers (adjusted for other variables). If the 95% CI excludes 1, the association is statistically significant at the 5% level.

### Systolic Blood Pressure (`sbp`): Comparing 160 vs 120

We compute the adjusted OR for a 40‑unit increase in `sbp` (from 120 to 160):

```{r}
#| label: or-sbp-160-120
step_sbp <- 160 - 120
A_sbp <- step_sbp * coef(fit1)["sbp"]
OR_sbp_160_vs_120 <- exp(A_sbp)

# Delta-method CI using the model-based variance
var_A_sbp <- step_sbp^2 * vcov_mat["sbp", "sbp"]
alpha <- 0.05
z <- qnorm(1 - alpha/2)
ci_lin <- c(A_sbp - z * sqrt(var_A_sbp), A_sbp + z * sqrt(var_A_sbp))
CI_OR_sbp_160_vs_120 <- exp(ci_lin)

OR_sbp_160_vs_120
CI_OR_sbp_160_vs_120
```

**Tip:** Replace `step_sbp` with any clinically meaningful increment (e.g., 10 mmHg) to report interpretable ORs.

## Combined Effects: Smoking with an Age Difference

Suppose we compare two groups that differ in **smoking status** and **age**:

* **Group A:** `smk = 1`, `age = 50` (all other covariates equal)
* **Group B:** `smk = 0`, `age = 30`

The log‑odds contrast is (A = \beta_{smk} + 20,\beta_{age}), so the OR is (\exp(A)).

```{r}
#| label: combined-smk-age
age_diff <- 50 - 30
A_smk_age <- coef(fit1)["smk"] + age_diff * coef(fit1)["age"]
OR_smk_age <- exp(A_smk_age)

# Variance of the linear combo: Var(b1 + a*b_age) = Var(b1) + a^2 Var(b_age) + 2a Cov(b1, b_age)
var_A_smk_age <- vcov_mat["smk", "smk"] +
  age_diff^2 * vcov_mat["age", "age"] +
  2 * age_diff * vcov_mat["smk", "age"]

CI_OR_smk_age <- exp(c(A_smk_age - z * sqrt(var_A_smk_age),
                       A_smk_age + z * sqrt(var_A_smk_age)))

OR_smk_age
CI_OR_smk_age
```

*Question$

What if the age difference is 10 or 5? Just set `age_diff <- 10` (or `5`) and re‑run the chunk.



