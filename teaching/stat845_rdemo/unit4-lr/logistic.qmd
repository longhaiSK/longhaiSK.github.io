---
title: "Logistic Regression"
author:
  - name: "Longhai Li"
    url: "https://longhaisk.github.io/"
date: today
format:
  # make sure these files get copied alongside the page
  html:
    theme: cosmo            # (Rmd `theme: null`)
    embed-resources: false # (Rmd `self_contained: false`)
    toc: false
    page-layout: full
    #css: mystyles.css
    code-fold: true
    number-sections: true
    df-print: paged        # (Rmd `df_print: paged`)
    highlight-style: tango # (Rmd `highlight: tango`)
    include-in-header:
      text: |
        <link rel="stylesheet" href="/resources/mystyles.css?v=2">
        <script src="/resources/rendernav.js" defer></script>
        <script src="/resources/loadtoc.js" defer></script>
    resources:
      - mystyles.css
      - rendernav.js
editor: source
execute:
  echo: true
  warning: false
  message: false
  cache: true
  fig-width: 9
  fig-height: 6
    
editor_options: 
  chunk_output_type: console
---

# Understanding ODD VS Probability $P(Y=1)$


The odds of an event with probability \(p\) is
\[
\mathrm{odds}(p) \;=\; \frac{p}{1-p}, \qquad 0<p<1.
\]
Odds map probabilities in \((0,1)\) to \((0,\infty)\), while the log-odds (logit) \(\log\{p/(1-p)\}\) map to \((-\infty,\infty)\). Logistic regression models the **log-odds** as a linear function of predictors, which keeps fitted probabilities in \((0,1)\) and turns multiplicative changes in odds into additive coefficient effects. In practice we often interpret coefficients via **odds ratios** \(\exp(\beta)\) and then communicate absolute risk with predicted probabilities.

```{r}
#| label: odds-plotter
#| echo: true
# A small utility to plot odds(p) = p/(1-p) over p in (0,1).
# Arguments:
#   p_min, p_max: endpoints for the p-grid (open interval).
#   n: number of grid points.
#   annotate: add helpful reference lines/labels.
#   add_logit: also draw the logit(p) on a secondary plot for context.
plot_odds <- function(p_min = 0.001, p_max = 0.9, n = 400,
                      annotate = TRUE, add_logit = FALSE) {
  stopifnot(p_min > 0, p_max < 1, p_min < p_max, n >= 10)
  p <- seq(p_min, p_max, length.out = n)
  odds <- p / (1 - p)

  # Main odds plot
  plot(p, odds, type = "l", lwd = 2,
       xlab = "Probability p",
       ylab = "odds(p) = p / (1 - p)")
  if (annotate) {
    abline(h = 1, v = 0.5, lty = 2)
    usr <- par("usr")
    text(0.52, 1.05, "p = 0.5 → odds = 1", adj = 0)
    # Mark a few reference probabilities
    ref_p <- c(0.1, 0.2, 0.8, 0.9)
    points(ref_p, ref_p/(1-ref_p), pch = 19, cex = 0.7)
  }

  if (add_logit) {
    readline(prompt = "Press <Enter> to view logit(p) plot...")
    logit <- log(p / (1 - p))
    plot(p, logit, type = "l", lwd = 2,
         xlab = "Probability p",
         ylab = "logit(p) = log{p/(1-p)}")
    if (annotate) {
      abline(h = 0, v = 0.5, lty = 2)
      text(0.52, 0.1, "p = 0.5 → logit = 0", adj = 0)
    }
  }

  invisible(list(p = p, odds = odds))
}

plot_odds(add_logit=FALSE)
```


# Load a dataset

```{r}
#| label: setup
# Adjust the path if needed. The default is your original V: drive path.
data_path <- "evans.dat"

# Read data (expects a header row)
CHD.data <- read.table(data_path, header = TRUE)

CHD.data


```

**Variable meanings (as provided):**

* `chd`: 1 if a person has the disease, 0 otherwise.
* `smk`: 1 if smoker, 0 if not.
* `cat`: 1 if catecholamine level is high, 0 if low.
* `sbp`: systolic blood pressure (continuous).
* `age`: age in years (continuous).
* `chl`: cholesterol level (continuous).
* `ecg`: 1 if electrocardiogram is abnormal, 0 if normal.
* `hpt`: 1 if high blood pressure, 0 if normal.

**Summary Statistics of the Data**
```{r}
#| label: summarize_data
summary(CHD.data)
```

# Fit the Logistic Regression Model

We fit a logistic regression with a logit link:

```{r}
#| label: fit-logit
fit1 <- glm(
  chd ~ smk + cat + sbp + age + chl + ecg + hpt,
  data = CHD.data,
  family = binomial(link = "logit")
)
summary(fit1)
```

**Notes for interpretation:**

* Positive coefficients increase the log-odds of CHD; negative coefficients decrease it.
* For indicator variables (e.g., `smk`), `exp(beta)` is the adjusted odds ratio comparing the group with value 1 versus 0, holding others fixed.
* For continuous predictors (e.g., `sbp`, `age`), `exp(beta)` is the multiplicative change in the odds for a one‑unit increase. For a *d*-unit increase, the OR is `exp(d * beta)`.

# Inference: Confidence Intervals and Covariance Matrix

We extract profile‑likelihood CIs and the covariance matrix to confirm standard errors.

```{r}
#| label: ci-cov
ci_95 <- confint(fit1, level = 0.95)     # profile-likelihood CI
vcov_mat <- vcov(fit1)                    # covariance matrix of coefficients
se_vec   <- sqrt(diag(vcov_mat))          # standard errors

ci_95
vcov_mat
se_vec  # should match the SE column in summary(fit1)
```

# Adjusted Odds Ratios for Individual Predictors

## Smoking (`smk`)

```{r}
#| label: or-smk
OR_smk <- exp(coef(fit1)["smk"])  # adjusted OR for smokers vs non-smokers
CI_OR_smk <- exp(ci_95["smk", ])  # 95% CI for the OR
OR_smk
CI_OR_smk
```

**How to read this:**

* `OR_smk > 1` suggests higher odds of CHD among smokers (adjusted for other variables). If the 95% CI excludes 1, the association is statistically significant at the 5% level.

## Systolic Blood Pressure (`sbp`): Comparing 160 vs 120

We compute the adjusted OR for a 40‑unit increase in `sbp` (from 120 to 160):

```{r}
#| label: or-sbp-160-120
step_sbp <- 160 - 120
A_sbp <- step_sbp * coef(fit1)["sbp"]
OR_sbp_160_vs_120 <- exp(A_sbp)

# Delta-method CI using the model-based variance
var_A_sbp <- step_sbp^2 * vcov_mat["sbp", "sbp"]
alpha <- 0.05
z <- qnorm(1 - alpha/2)
ci_lin <- c(A_sbp - z * sqrt(var_A_sbp), A_sbp + z * sqrt(var_A_sbp))
CI_OR_sbp_160_vs_120 <- exp(ci_lin)

OR_sbp_160_vs_120
CI_OR_sbp_160_vs_120
```

**Tip:** Replace `step_sbp` with any clinically meaningful increment (e.g., 10 mmHg) to report interpretable ORs.

# Combined Effects: Smoking with an Age Difference

Suppose we compare two groups that differ in **smoking status** and **age**:

* **Group A:** `smk = 1`, `age = 50` (all other covariates equal)
* **Group B:** `smk = 0`, `age = 30`

The log‑odds contrast is (A = \beta_{smk} + 20,\beta_{age}), so the OR is (\exp(A)).

```{r}
#| label: combined-smk-age
age_diff <- 50 - 30
A_smk_age <- coef(fit1)["smk"] + age_diff * coef(fit1)["age"]
OR_smk_age <- exp(A_smk_age)

# Variance of the linear combo: Var(b1 + a*b_age) = Var(b1) + a^2 Var(b_age) + 2a Cov(b1, b_age)
var_A_smk_age <- vcov_mat["smk", "smk"] +
  age_diff^2 * vcov_mat["age", "age"] +
  2 * age_diff * vcov_mat["smk", "age"]

CI_OR_smk_age <- exp(c(A_smk_age - z * sqrt(var_A_smk_age),
                       A_smk_age + z * sqrt(var_A_smk_age)))

OR_smk_age
CI_OR_smk_age
```

**What if the age difference is 10 or 5?** Just set `age_diff <- 10` (or `5`) and re‑run the chunk.

# Helper Functions (Optional)

To streamline custom contrasts and CIs, you can use small helpers.

```{r}
#| label: helpers
# Compute OR and 95% CI for a linear combination c' * beta
or_ci_linear_combo <- function(coef_vec, vcov_mat, cvec, level = 0.95) {
  stopifnot(length(coef_vec) == length(cvec))
  A <- sum(cvec * coef_vec)
  varA <- as.numeric(t(cvec) %*% vcov_mat %*% cvec)
  alpha <- 1 - level
  z <- qnorm(1 - alpha/2)
  ci_lin <- c(A - z * sqrt(varA), A + z * sqrt(varA))
  list(OR = exp(A), CI = exp(ci_lin))
}

# Example: OR for sbp increase of d units
OR_CI_sbp_delta <- function(fit, d, level = 0.95) {
  b <- coef(fit)
  V <- vcov(fit)
  # build cvec aligned to coef order
  nm <- names(b)
  cvec <- rep(0, length(b))
  cvec[which(nm == "sbp")] <- d
  or_ci_linear_combo(b, V, cvec, level)
}

# Example usage: 40‑unit increase in sbp
OR_CI_sbp_delta(fit1, 40)
```

# Model Diagnostics (Quick Checks)

Basic checks for influential points and linearity for continuous predictors can be informative.

```{r}
#| label: diagnostics
par(mfrow = c(2, 2))
plot(fit1)  # default diagnostic plots; interpret with care for GLMs
par(mfrow = c(1, 1))

# Leverage and residuals
hatvals <- hatvalues(fit1)
pearson_res <- residuals(fit1, type = "pearson")
plot(hatvals, abs(pearson_res), pch = 19, xlab = "Leverage", ylab = "|Pearson residual|")
abline(h = 2, lty = 2)
```

> For GLMs, specialized diagnostics (e.g., partial residual plots, nonlinearity checks via splines, calibration plots, and ROC/AUC) may be preferable. Consider `rms` or `pROC` packages if you want richer diagnostics.

# Reporting Key Findings

When writing up results, report both effect sizes and uncertainty, e.g.:

* **Smoking**: adjusted OR `r signif(OR_smk, 3)` with 95% CI `r paste(signif(CI_OR_smk, 3), collapse = " to ")`.
* **SBP (160 vs 120)**: adjusted OR `r signif(OR_sbp_160_vs_120, 3)` with 95% CI `r paste(signif(CI_OR_sbp_160_vs_120, 3), collapse = " to ")`.
* **Smoking + Age (50 vs 30)**: adjusted OR `r signif(OR_smk_age, 3)` with 95% CI `r paste(signif(CI_OR_smk_age, 3), collapse = " to ")`.

Interpretation should connect to clinical or substantive context, noting any variables whose CIs exclude 1 (suggesting statistical significance at the chosen level).

# Template: Space Shuttle O‑ring Analysis

Below is a minimal template for analyzing O‑ring failures vs. launch temperature (logistic regression). Replace the `...` with the actual counts or binary outcomes and temperatures.

```{r}
#| label: oring-template
# Example template for O‑ring data
# y: number of failures (or 0/1 for any failure), x: temperature
# If y is a count with n trials, use cbind(y, n - y) as the response.

# Binary example (0/1):
# y <- c(...)
# x <- c(...)
# dat <- data.frame(y = y, x = x)
# fit_o <- glm(y ~ x, data = dat, family = binomial(link = "logit"))
# summary(fit_o)
# exp(coef(fit_o))       # OR per 1-degree change
# exp(confint(fit_o))    # 95% CI for ORs

# Binomial (failures out of n):
# failures <- c(...)
# total    <- c(...)
# x        <- c(...)
# dat2 <- data.frame(failures = failures, total = total, x = x)
# fit_o2 <- glm(cbind(failures, total - failures) ~ x,
#               data = dat2, family = binomial(link = "logit"))
# summary(fit_o2)
# exp(coef(fit_o2))
# exp(confint(fit_o2))
```

**Guidance for conclusions:**

* Check whether lower temperatures are associated with higher failure odds (OR per degree < 1 implies increasing temperature reduces odds; equivalently, OR per degree drop > 1 increases odds).
* Visualize the fitted curve against observed data; consider predicting failure probability at key temperatures.

```{r}
#| label: oring-plot-template
# Example plotting (uncomment and adapt):
# plot(x, y, xlab = "Temperature", ylab = "Failure (0/1)")
# xseq <- seq(min(x), max(x), length.out = 200)
# p_hat <- predict(fit_o, newdata = data.frame(x = xseq), type = "response")
# lines(xseq, p_hat)
```

# Reproducibility Notes

* This document uses **base R** functions to mirror your original script.
* Profile‑likelihood CIs via `confint()` may differ slightly from Wald CIs (based on SEs). The profile approach is typically more reliable for non‑linear models and small samples.
* Set a seed for any random components if you extend the analysis with resampling or simulation.



