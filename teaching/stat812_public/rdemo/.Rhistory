max_log_x <- max(log_x)
max_log_x + log( sum(exp(log_x - max_log_x) ))
}
log_like_obs <- function(theta,Y)
{
log_jointlike <- cbind(log( theta[1]) + dnorm(Y,theta[2],1,log = TRUE),
log(1 - theta[1]) + dnorm(Y,theta[3],1, log = TRUE))
sum(apply(log_jointlike,1,log_sum_exp))
}
em_mixnorm <- function(theta0,Y,no_iters)
{   col_weigh <- cm.colors(100)
result <- matrix(0,no_iters + 1,4)
colnames(result) <- c("p","mu1","mu0","log_lik")
result[1,1:3] <- theta0
result[1,4] <- log_like_obs(theta0,Y)
for(i in 1:no_iters + 1) {
log_like1 <- dnorm(Y,result[i-1,2],1,log = TRUE) + log(result[i-1,1])
log_like0 <- dnorm(Y,result[i-1,3],1,log = TRUE) + log(1-result[i-1,1])
log_like_average <- apply(cbind(log_like1, log_like0),1,log_sum_exp)
weighs <-   exp(log_like1 - log_like_average)
## making plots showing steps
xlim <- range (Y, result[i-1,2:3])+c(-2,2)
plot(function(x) dnorm(x, result[i-1,2])*result[i-1,1], ylim=c(0,0.4),
xlim[1], xlim[2], col=col_weigh[100])
title(main = sprintf("Step %g: p=%4.2f, mu1=%5.2f, mu0=%5.2f",
i-1, result[i-1,1],result[i-1,2],result[i-1,3]))
plot(function(x) dnorm(x, result[i-1,3])*(1-result[i-1,1]),
xlim[1], xlim[2], col=col_weigh[1], add=TRUE)
points(Y, rep(0, length(Y)), col=col_weigh[ceiling(weighs*100)] )
#update p
result[i,1] <- mean(weighs)
#update u1
result[i,2] <- sum(Y*weighs)/sum(weighs)
result[i,3] <- sum(Y*(1-weighs))/sum(1-weighs)
result[i,4] <- log_like_obs(result[i,1:3],Y)
#plot the change of mu
arrows(result[i-1,2], 0.01,result[i,2],0.01,
length = 0.05*abs(result[i,2]-result[i-1,2]),col=col_weigh[100])
arrows(result[i-1,3], 0.01,result[i,3],0.01,
length = 0.05*abs(result[i,3]-result[i-1,3]),col=col_weigh[1])
}
invisible(result)
}
# Chunk 2
gen_mixnorm <- function(theta,n)
{
Z <- 1*(runif(n) < theta[1])
Y <- rep(0,n)
for(i in 1:n){
if(Z[i]==1) Y[i] <- rnorm(1,theta[2],1)
else Y[i] <- rnorm(1,theta[3],1)
}
col_weigh <- cm.colors(2)
plot (Y, Z, col = col_weigh[Z+1])
Y
}
# Chunk 3
data <- gen_mixnorm(c(0.3,0,3),200)
em_mixnorm(c(0.5,-10,5),data,4)
# Chunk 1
log_sum_exp <- function(log_x)
{
max_log_x <- max(log_x)
max_log_x + log( sum(exp(log_x - max_log_x) ))
}
log_like_obs <- function(theta,Y)
{
log_jointlike <- cbind(log( theta[1]) + dnorm(Y,theta[2],1,log = TRUE),
log(1 - theta[1]) + dnorm(Y,theta[3],1, log = TRUE))
sum(apply(log_jointlike,1,log_sum_exp))
}
em_mixnorm <- function(theta0,Y,no_iters)
{   col_weigh <- cm.colors(100)
result <- matrix(0,no_iters + 1,4)
colnames(result) <- c("p","mu1","mu0","log_lik")
result[1,1:3] <- theta0
result[1,4] <- log_like_obs(theta0,Y)
for(i in 1:no_iters + 1) {
log_like1 <- dnorm(Y,result[i-1,2],1,log = TRUE) + log(result[i-1,1])
log_like0 <- dnorm(Y,result[i-1,3],1,log = TRUE) + log(1-result[i-1,1])
log_like_average <- apply(cbind(log_like1, log_like0),1,log_sum_exp)
weighs <-   exp(log_like1 - log_like_average)
## making plots showing steps
xlim <- range (Y, result[i-1,2:3])+c(-2,2)
plot(function(x) dnorm(x, result[i-1,2])*result[i-1,1], ylim=c(0,0.4),
xlim[1], xlim[2], col=col_weigh[100])
title(main = sprintf("Step %g: p=%4.2f, mu1=%5.2f, mu0=%5.2f",
i-1, result[i-1,1],result[i-1,2],result[i-1,3]))
plot(function(x) dnorm(x, result[i-1,3])*(1-result[i-1,1]),
xlim[1], xlim[2], col=col_weigh[1], add=TRUE)
points(Y, rep(0, length(Y)), col=col_weigh[ceiling(weighs*100)] )
#update p
result[i,1] <- mean(weighs)
#update u1
result[i,2] <- sum(Y*weighs)/sum(weighs)
result[i,3] <- sum(Y*(1-weighs))/sum(1-weighs)
result[i,4] <- log_like_obs(result[i,1:3],Y)
#plot the change of mu
arrows(result[i-1,2], 0.01,result[i,2],0.01,
length = 0.1*abs(result[i,2]-result[i-1,2]),col=col_weigh[100])
arrows(result[i-1,3], 0.01,result[i,3],0.01,
length = 0.1*abs(result[i,3]-result[i-1,3]),col=col_weigh[1])
}
invisible(result)
}
# Chunk 2
gen_mixnorm <- function(theta,n)
{
Z <- 1*(runif(n) < theta[1])
Y <- rep(0,n)
for(i in 1:n){
if(Z[i]==1) Y[i] <- rnorm(1,theta[2],1)
else Y[i] <- rnorm(1,theta[3],1)
}
col_weigh <- cm.colors(2)
plot (Y, Z, col = col_weigh[Z+1])
Y
}
# Chunk 3
data <- gen_mixnorm(c(0.3,0,3),200)
em_mixnorm(c(0.5,-10,5),data,10)
# Chunk 1
log_sum_exp <- function(log_x)
{
max_log_x <- max(log_x)
max_log_x + log( sum(exp(log_x - max_log_x) ))
}
log_like_obs <- function(theta,Y)
{
log_jointlike <- cbind(log( theta[1]) + dnorm(Y,theta[2],1,log = TRUE),
log(1 - theta[1]) + dnorm(Y,theta[3],1, log = TRUE))
sum(apply(log_jointlike,1,log_sum_exp))
}
em_mixnorm <- function(theta0,Y,no_iters)
{   col_weigh <- cm.colors(100)
result <- matrix(0,no_iters + 1,4)
colnames(result) <- c("p","mu1","mu0","log_lik")
result[1,1:3] <- theta0
result[1,4] <- log_like_obs(theta0,Y)
for(i in 1:no_iters + 1) {
log_like1 <- dnorm(Y,result[i-1,2],1,log = TRUE) + log(result[i-1,1])
log_like0 <- dnorm(Y,result[i-1,3],1,log = TRUE) + log(1-result[i-1,1])
log_like_average <- apply(cbind(log_like1, log_like0),1,log_sum_exp)
weighs <-   exp(log_like1 - log_like_average)
## making plots showing steps
xlim <- range (Y, result[i-1,2:3])+c(-2,2)
plot(function(x) dnorm(x, result[i-1,2])*result[i-1,1], ylim=c(0,0.4),
xlim[1], xlim[2], col=col_weigh[100])
title(main = sprintf("Step %g: p=%4.2f, mu1=%5.2f, mu0=%5.2f",
i-1, result[i-1,1],result[i-1,2],result[i-1,3]))
plot(function(x) dnorm(x, result[i-1,3])*(1-result[i-1,1]),
xlim[1], xlim[2], col=col_weigh[1], add=TRUE)
points(Y, rep(0, length(Y)), col=col_weigh[ceiling(weighs*100)] )
#update p
result[i,1] <- mean(weighs)
#update u1
result[i,2] <- sum(Y*weighs)/sum(weighs)
result[i,3] <- sum(Y*(1-weighs))/sum(1-weighs)
result[i,4] <- log_like_obs(result[i,1:3],Y)
#plot the change of mu
arrows(result[i-1,2], 0.01,result[i,2],0.01,
length = 0.1,col=col_weigh[100])
arrows(result[i-1,3], 0.01,result[i,3],0.01,
length = 0.1,col=col_weigh[1])
}
invisible(result)
}
# Chunk 2
gen_mixnorm <- function(theta,n)
{
Z <- 1*(runif(n) < theta[1])
Y <- rep(0,n)
for(i in 1:n){
if(Z[i]==1) Y[i] <- rnorm(1,theta[2],1)
else Y[i] <- rnorm(1,theta[3],1)
}
col_weigh <- cm.colors(2)
plot (Y, Z, col = col_weigh[Z+1])
Y
}
# Chunk 3
data <- gen_mixnorm(c(0.3,0,3),200)
em_mixnorm(c(0.5,-10,5),data,10)
install.packages("PRROC")
library("bayesplot")
?mcmc_intervals
a <- matrix(rnorm (1000),10,100)
a
boxplot(a)
q()
library("dlstat")
library("crandl")
library("dlstats")
library("ggplot2")
library("dlstats")
x <- cran_stats(c("HTLR"))
if (!is.null(x)) {
head(x)
ggplot(x, aes(end, downloads, group=package, color=package)) +
geom_line() + geom_point(aes(shape=package))
}
source('~/.active-rstudio-document', echo=TRUE)
x
source('~/.active-rstudio-document', echo=TRUE)
a <- rnorm(20,1:20,1)
a
b <- a + 0.5
A <- data.frame(x=c(a,b),b=rep(1:20,2),tr=rep(1:2,each=20))
A
A$b <- as.factor(A$b)
A$tr <- as.factor(A$tr)
anova(lm(x~b+tr))
anova(lm(x~b+tr,data=A))
b <- a + rnorm(20,0.5,1)
A <- data.frame(x=c(a,b),b=rep(1:20,2),tr=rep(1:2,each=20))
A$tr <- as.factor(A$tr)
A$b <- as.factor(A$b)
anova(lm(x~b+tr,data=A))
t.test(a,b,paired = T)
summary(lm(x~b+tr,data=A))
confint(lm(x~b+tr,data=A))
t.test(a,b,paired = T)
15*35*4
15*35*4/60
15*35*4/60*15
a <- list.files("unit.*\\.pdf")
a
a <- list.files("unit.*\\..*")
a
a <- list.files(pattern="unit.*")
a
a <- list.files(pattern="unit.*\\.")
a
a <- list.files(pattern="unit[0-9].*\\.")
a
install.packages ("metRopogy")
install.packages ("metRology")
library ("metRology")
# Chunk 1
library ("metRology")
# Chunk 2
## the function for computing log likelihood of normal data
log_lik <- function(x,mu,w,df=Inf)
{   sum(dt.scaled(x,df,mu,exp(w),log=TRUE))
}
## the function for computing log prior
log_prior <- function(mu,w, mu_0,sigma_mu,w_0,sigma_w)
{   dnorm(mu,mu_0,sigma_mu,log=TRUE) + dnorm(w,w_0,sigma_w,log=TRUE)
}
## the function for computing the unormalized log posterior
## given transformed mu and w
log_post_tran <- function(x, mu_t, w_t, mu_0,sigma_mu,w_0,sigma_w, df=Inf)
{
#log likelihood
log_lik(x,logi(mu_t), logi(w_t),df) +
#log prior
log_prior(logi(mu_t), logi(w_t), mu_0,sigma_mu,w_0,sigma_w) +
#log derivative of transformation
log_der_logi(mu_t) + log_der_logi(w_t)
}
## the logistic function for transforming (0,1) value to (-inf,+inf)
logi <- function(x)
{  log(x) - log(1-x)
}
## the log derivative of logistic function
log_der_logi <- function(x)
{  -log(x) - log(1-x)
}
## the generic function for approximating 1-D integral with midpoint rule
## the logarithms of the function values are passed in
## the log of the integral result is returned
## log_f  --- a function computing the logarithm of the integrant function
## range  --- the range of integral varaible, a vector of two elements
## n      --- the number of points at which the integrant is evaluated
## ...    --- other parameters needed by log_f
log_int_mid <- function(log_f, range, n,...)
{   if(range[1] >= range[2])
stop("Wrong ranges")
h <- (range[2]-range[1]) / n
v_log_f <- sapply(range[1] + (1:n - 0.5) * h, log_f,...)
log_sum_exp(v_log_f) + log(h)
}
## a function computing the sum of numbers represented with logarithm
## lx     --- a vector of numbers, which are the log of another vector x.
## the log of sum of x is returned
log_sum_exp <- function(lx)
{   mlx <- max(lx)
mlx + log(sum(exp(lx-mlx)))
}
## a function computing the normalization constant
log_marlik_mid <- function(x,mu_0,sigma_mu,w_0,sigma_w, df=Inf, n)
{
## function computing the normalization constant of with mu_t fixed
log_int_gaussian_mu <- function(mu_t)
{   log_int_mid(log_f=log_post_tran,range=c(0,1),n=n,
x=x,mu_t=mu_t,mu_0=mu_0,sigma_mu=sigma_mu,
w_0=w_0,sigma_w=sigma_w, df=df)
}
log_int_mid(log_f=log_int_gaussian_mu,range=c(0,1), n=n)
}
## we use Monte Carlo method to debug the above function
log_marlik_mc <- function(x,mu_0,sigma_mu,w_0,sigma_w, df=Inf,iters_mc)
{
## draw samples from the priors
mus <- rnorm(iters_mc,mu_0,sigma_mu)
ws <- rnorm(iters_mc,w_0,sigma_w)
one_log_lik <- function(i)
{  log_lik(x,mus[i],ws[i], df)
}
v_log_lik <- sapply(1:iters_mc,one_log_lik)
log_sum_exp(v_log_lik) - log(iters_mc)
}
# Chunk 1
library ("metRology")
# Chunk 2
## the function for computing log likelihood of normal data
log_lik <- function(x,mu,w,df=Inf)
{   sum(dt.scaled(x,df,mu,exp(w),log=TRUE))
}
## the function for computing log prior
log_prior <- function(mu,w, mu_0,sigma_mu,w_0,sigma_w)
{   dnorm(mu,mu_0,sigma_mu,log=TRUE) + dnorm(w,w_0,sigma_w,log=TRUE)
}
## the function for computing the unormalized log posterior
## given transformed mu and w
log_post_tran <- function(x, mu_t, w_t, mu_0,sigma_mu,w_0,sigma_w, df=Inf)
{
#log likelihood
log_lik(x,logi(mu_t), logi(w_t),df) +
#log prior
log_prior(logi(mu_t), logi(w_t), mu_0,sigma_mu,w_0,sigma_w) +
#log derivative of transformation
log_der_logi(mu_t) + log_der_logi(w_t)
}
## the logistic function for transforming (0,1) value to (-inf,+inf)
logi <- function(x)
{  log(x) - log(1-x)
}
## the log derivative of logistic function
log_der_logi <- function(x)
{  -log(x) - log(1-x)
}
## the generic function for approximating 1-D integral with midpoint rule
## the logarithms of the function values are passed in
## the log of the integral result is returned
## log_f  --- a function computing the logarithm of the integrant function
## range  --- the range of integral varaible, a vector of two elements
## n      --- the number of points at which the integrant is evaluated
## ...    --- other parameters needed by log_f
log_int_mid <- function(log_f, range, n,...)
{   if(range[1] >= range[2])
stop("Wrong ranges")
h <- (range[2]-range[1]) / n
v_log_f <- sapply(range[1] + (1:n - 0.5) * h, log_f,...)
log_sum_exp(v_log_f) + log(h)
}
## a function computing the sum of numbers represented with logarithm
## lx     --- a vector of numbers, which are the log of another vector x.
## the log of sum of x is returned
log_sum_exp <- function(lx)
{   mlx <- max(lx)
mlx + log(sum(exp(lx-mlx)))
}
## a function computing the normalization constant
log_marlik_mid <- function(x,mu_0,sigma_mu,w_0,sigma_w, n, df=Inf)
{
## function computing the normalization constant of with mu_t fixed
log_int_gaussian_mu <- function(mu_t)
{   log_int_mid(log_f=log_post_tran,range=c(0,1),n=n,
x=x,mu_t=mu_t,mu_0=mu_0,sigma_mu=sigma_mu,
w_0=w_0,sigma_w=sigma_w, df=df)
}
log_int_mid(log_f=log_int_gaussian_mu,range=c(0,1), n=n)
}
## we use Monte Carlo method to debug the above function
log_marlik_mc <- function(x,mu_0,sigma_mu,w_0,sigma_w,iters_mc, df=Inf)
{
## draw samples from the priors
mus <- rnorm(iters_mc,mu_0,sigma_mu)
ws <- rnorm(iters_mc,w_0,sigma_w)
one_log_lik <- function(i)
{  log_lik(x,mus[i],ws[i], df)
}
v_log_lik <- sapply(1:iters_mc,one_log_lik)
log_sum_exp(v_log_lik) - log(iters_mc)
}
x <- rnorm(50)
log_marlik_mid(x,0,1,0,1,100)
log_marlik_mc(x,0,1,0,1,100000)
x <- rnorm(50)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
x <- rt.scaled(50, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
x <- rt.scaled(50, mean=2, sd = 2, df=2)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
x <- rt.scaled(100, mean=2, sd = 2, df=2)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
## looking at the convergence
x <- rnorm(100)
for(i in seq(10,90,by=10))
{ cat("n = ",i,",")
cat(" Estimated Log Marginal Likelihood =",
log_marlik_mid(x,0,1,0,1,i),"\n")
}
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
## looking at the convergence
x <- rnorm(100)
for(i in seq(10,90,by=10))
{ cat("n = ",i,",")
cat(" Estimated Log Marginal Likelihood =",
log_marlik_mid(x,0,1,0,1,i),"\n")
}
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100)
log_marlik_mc(x,0,10,0,10,100000)
## looking at the convergence
for(i in seq(10,90,by=10))
{ cat("n = ",i,",")
cat(" Estimated Log Marginal Likelihood =",
log_marlik_mid(x,0,10,0,10,i),"\n")
}
x <- rnorm(100)
log_marlik_mid(x,mu_0=0,sigma_mu=1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=0.1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=0.01,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-2,sigma_mu=0.1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=10,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=100,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=1000000,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=10,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=1,w_0=0,sigma_w=1,100)
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
##data from normal
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
##data from normal
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is wrongly specified
log_marlik_mid(x,0,1000,0,10,1000, df = Inf) # if prior is wrongly specified
##data from normal
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is wrongly specified
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is wrongly specified
##data from normal
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is too narrow
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is too diffuse
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is too narrow
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is too diffuse
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is too narrow
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is too diffuse
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is too narrow
log_marlik_mid(x,0,100,0,100,100, df = Inf) # if prior is too diffuse
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is too diffuse
x <- rt.scaled(100, mean=2, sd = 2, df=2)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,0.1,0,10,100, df =2) # if prior is too narrow
log_marlik_mid(x,0,100,0,100,100, df = 2) # if prior is too diffuse
log_marlik_mid(x,0,1000,0,1000,100, df = 2) # if prior is too diffuse
x <- rt.scaled(100, mean=50, sd = 2, df=2)
log_marlik_mid(x,0,100,0,100,100, df = 2)
log_marlik_mc(x,0,100,0,100,10000, df = 2)
x <- rt.scaled(100, mean=50, sd = 2, df=Inf)
log_marlik_mid(x,0,100,0,100,100, df = Inf)
log_marlik_mc(x,0,100,0,100,10000, df = Inf)
x <- rnorm(100)
log_marlik_mid(x,mu_0=0,sigma_mu=0.1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=0.01,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=10,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=100,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=0,sigma_mu=1000,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=0.1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=1,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=10,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=100,w_0=0,sigma_w=1,100)
log_marlik_mid(x,mu_0=-5,sigma_mu=1000,w_0=0,sigma_w=1,100)
x <- rt.scaled(100, mean=2, sd = 2, df=Inf)
log_marlik_mid(x,0,10,0,10,100, df = Inf)
log_marlik_mid(x,0,10,0,10,100, df = 2)
log_marlik_mid(x,0,10,0,10,100, df = 1)
log_marlik_mid(x,0,10,0,10,100, df = 0.5)
log_marlik_mid(x,0,0.1,0,10,100, df = Inf) # if prior is too narrow
log_marlik_mid(x,0,100,0,100,100, df = Inf) # if prior is too diffuse
log_marlik_mid(x,0,1000,0,1000,100, df = Inf) # if prior is too diffuse
?integrate
